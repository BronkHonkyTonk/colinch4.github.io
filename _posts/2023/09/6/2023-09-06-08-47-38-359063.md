---
layout: post
title: "[파이썬] statsmodels 모델 비교"
description: " "
date: 2023-09-06
tags: [statsmodels]
comments: true
share: true
---

When it comes to building statistical models in Python, the `statsmodels` library provides a comprehensive toolkit. With `statsmodels`, you can easily compare different models to determine which one best fits your data.

In this blog post, we will explore how to compare models using `statsmodels` and discuss the various metrics and techniques that can be used for comparison.

## Installing statsmodels

Before you start, make sure you have `statsmodels` installed on your system. You can install it using pip:

```python
pip install statsmodels
```

## Importing Data

To begin, let's import the necessary libraries and load some example data. We will use the popular `iris` dataset for this demonstration.

```python
import pandas as pd

# Load Iris dataset
url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'
df = pd.read_csv(url)

# Display the first few rows of the dataset
print(df.head())
```

## Building and Comparing Models

Now that we have our data, we can start building and comparing different models. We will focus on linear regression models for this example.

```python
import statsmodels.api as sm

# Define the dependent and independent variables
X = df[['sepal_length', 'sepal_width', 'petal_length']]
y = df['petal_width']

# Add a constant term to the independent variables
X = sm.add_constant(X)

# Fit the model
model = sm.OLS(y, X).fit()

# Print the model summary
print(model.summary())
```

This code snippet demonstrates how to build a linear regression model using `statsmodels`. We first specify the dependent variable `y` and the independent variables `X`. Then, we add a constant term to `X` using `sm.add_constant()`. Finally, we fit the model using `sm.OLS()` and obtain a summary of the model using `model.summary()`.

## Model Comparison Metrics

Once we have built multiple models, we can compare them using different metrics. Here are a few commonly used metrics for comparing models:

- **R-squared**: This metric indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R-squared indicates a better fit.
- **Adjusted R-squared**: Similar to R-squared, but it takes into account the number of independent variables used in the model. It penalizes the addition of irrelevant variables.
- **Akaike Information Criterion (AIC)**: This metric provides an estimate of the relative quality of a statistical model. It balances the goodness of fit with the complexity of the model. A lower AIC indicates a better model.
- **Bayesian Information Criterion (BIC)**: Similar to AIC, but it penalizes models with more parameters more strongly. It emphasizes parsimony. A lower BIC indicates a better model.

To compare models using these metrics, you can simply access the respective properties from the model object. Here's an example:

```python
# Build another model
model2 = sm.OLS(y, X[['const', 'sepal_length', 'sepal_width']]).fit()

# Compare models using metrics
print(f"Model 1 R-squared: {model.rsquared:.4f}")
print(f"Model 2 R-squared: {model2.rsquared:.4f}")
print(f"Model 1 AIC: {model.aic:.4f}")
print(f"Model 2 AIC: {model2.aic:.4f}")
```

This code snippet compares two models based on their R-squared and AIC values. You can easily extend this approach to include more models and metrics as needed.

## Conclusion

In this blog post, we explored how to compare models using `statsmodels` in Python. We discussed how to build a model, obtain its summary, and compare models using various metrics like R-squared, AIC, and BIC.

`statsmodels` provides a powerful set of tools for model comparison, allowing you to identify the best-fitting model for your data. Have fun exploring different models and discovering the one that best fits your needs!