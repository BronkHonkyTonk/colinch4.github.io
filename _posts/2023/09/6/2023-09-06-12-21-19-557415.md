---
layout: post
title: "[파이썬] Scrapy의 코드 구조"
description: " "
date: 2023-09-06
tags: [Scrapy]
comments: true
share: true
---

Scrapy는 파이썬으로 작성된 웹 스크래핑 프레임워크로, 웹 페이지 데이터를 추출하기 위해 사용됩니다. Scrapy는 강력한 기능과 편리한 구조를 제공하여 웹 스크래핑 작업을 효율적으로 관리할 수 있도록 도와줍니다. 이번 포스트에서는 Scrapy의 코드 구조를 살펴보겠습니다.

## 프로젝트 구조

Scrapy 프로젝트는 다음과 같은 기본적인 디렉토리 구조를 갖추고 있습니다:

```plaintext
myproject/
    scrapy.cfg
    myproject/
        __init__.py
        items.py
        middlewares.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            myspider.py
```

- `scrapy.cfg`: Scrapy 프로젝트의 설정 파일입니다.
- `myproject/`: Scrapy 프로젝트의 최상위 디렉토리입니다.
- `__init__.py`: Python 모듈을 나타내는 파일입니다.
- `items.py`: 추출하려는 데이터를 정의하는 Scrapy Item 클래스를 포함합니다.
- `middlewares.py`: 스크래핑 중에 요청과 응답을 처리하는 미들웨어 클래스를 포함합니다.
- `pipelines.py`: 스크랩된 데이터를 처리하는 파이프라인 클래스를 포함합니다.
- `settings.py`: Scrapy 프로젝트의 설정을 포함하는 파일입니다.
- `spiders/`: 스크래퍼를 정의하는 스파이더 클래스를 포함하는 디렉토리입니다.
- `__init__.py`: Python 모듈을 나타내는 파일입니다.
- `myspider.py`: 스파이더 클래스로, 웹 페이지에 대한 요청을 생성하고 응답을 처리하여 데이터를 추출합니다.

## 스파이더 클래스

Scrapy의 핵심은 스파이더 클래스입니다. 스파이더 클래스는 웹 페이지에 대한 요청을 만들고, 응답을 처리하며, 데이터를 추출하는 로직을 포함합니다. 스파이더 클래스는 `scrapy.Spider`를 상속받아야 합니다.

다음은 간단한 스파이더 클래스의 예시입니다:

```python
import scrapy

class MySpider(scrapy.Spider):
    name = 'myspider'
    start_urls = ['http://example.com']

    def parse(self, response):
        # 웹 페이지 응답 처리 로직
        pass
```

위 예시에서 `name` 속성은 스파이더의 고유한 이름을 지정합니다. `start_urls` 속성은 스파이더가 시작하는 웹 페이지의 URL을 포함하는 리스트입니다. `parse` 메서드는 인자로 받은 웹 페이지 응답을 처리하는 로직을 구현해야 합니다.

## 아이템 클래스

Scrapy에서 데이터를 추출하기 위해 사용하는 클래스는 아이템 클래스입니다. 아이템 클래스는 추출하려는 데이터의 필드를 정의하는 역할을 합니다. 아이템 클래스는 `scrapy.Item` 클래스를 상속받아야 합니다.

다음은 간단한 아이템 클래스의 예시입니다:

```python
import scrapy

class MyItem(scrapy.Item):
    title = scrapy.Field()
    description = scrapy.Field()
    price = scrapy.Field()
```

위 예시에서 `title`, `description`, `price` 필드는 스파이더가 추출한 데이터의 속성을 나타냅니다. 각 필드는 `scrapy.Field` 클래스의 인스턴스입니다.

## 파이프라인 클래스

Scrapy의 파이프라인 클래스는 추출된 데이터를 처리하는 역할을 합니다. 파이프라인 클래스는 여러 개의 메서드를 가지며, 각 메서드는 추출된 데이터를 다른 서비스로 전송하거나 데이터를 저장하는 등의 작업을 수행합니다.

다음은 간단한 파이프라인 클래스의 예시입니다:

```python
class MyPipeline:
    def process_item(self, item, spider):
        # 추출된 데이터 처리 로직
        return item
```

위 예시에서 `process_item` 메서드는 추출된 데이터를 처리하는 로직을 구현해야 합니다. `item` 인자는 추출된 데이터를 담고 있는 아이템 객체를 의미하며, `spider` 인자는 관련된 스파이더 객체를 의미합니다.

Scrapy의 코드 구조를 이해하고 나면, 각각의 클래스를 수정하여 웹 스크래핑 로직을 효율적으로 구현할 수 있습니다. 이를 통해 웹 페이지 데이터를 쉽고 빠르게 추출할 수 있습니다.