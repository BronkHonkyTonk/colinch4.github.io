---
layout: post
title: "[파이썬] Scrapy PDF 및 다른 파일 형식 스크레이핑"
description: " "
date: 2023-09-06
tags: [python,Scrapy]
comments: true
share: true
---

![Scrapy](https://miro.medium.com/max/4400/1*bPjWRXzmGv-ILd-X_i12gw.png)

Scrapy는 파이썬 기반의 웹 스크레이핑 프레임워크로, 다양한 파일 형식의 데이터를 추출할 수 있는 강력한 기능을 제공합니다. PDF 파일은 종종 중요한 정보를 담고 있으며, 스크레이핑하려는 웹 사이트에서 PDF 파일을 가져와 데이터를 추출하는 작업이 필요할 수 있습니다.

이 블로그 포스트에서는 Scrapy를 사용하여 PDF 파일 및 다른 파일 형식을 스크레이핑하는 방법을 알아보겠습니다.

## 1. Scrapy에서 파일 다운로드 설정하기

Scrapy는 파일 다운로드를 기본적으로 지원하지만, 특정 파일 형식에 대한 처리를 추가 설정해야 합니다. 

먼저, `settings.py` 파일에서 다음과 같은 설정을 추가합니다:

```python
ITEM_PIPELINES = {
   'scrapy.pipelines.files.FilesPipeline': 1
}

FILES_STORE = '<파일 저장 경로>'
```

위 설정은 파일을 다운로드 및 저장할 경로를 설정하고, 파일 다운로드 파이프라인을 활성화합니다.

## 2. 파일 다운로드 링크 추출하기

파일을 다운로드하기 위해선, 해당 파일의 다운로드 링크를 추출해야 합니다. Scrapy는 HTML 페이지에서 링크를 추출하는데 편리한 도구인 `LinkExtractor`를 제공합니다.

다음은 PDF 파일 다운로드 링크를 추출하는 예제입니다:

```python
from scrapy.linkextractors import LinkExtractor

class MySpider(scrapy.Spider):
    # ...
    
    def parse(self, response):
        # PDF 파일 다운로드 링크 추출
        link_extractor = LinkExtractor(allow=r'\.pdf$')
        for link in link_extractor.extract_links(response):
            yield scrapy.Request(link.url, callback=self.parse_pdf)

    def parse_pdf(self, response):
        # PDF 파일 다운로드 후 처리
        file_path = response.url.split('/')[-1]
        yield {
            'file_urls': [response.url],
            'file_path': file_path
        }
```

위 예제에서는 `LinkExtractor`를 사용하여 `.pdf`로 끝나는 링크를 추출하고, 추출된 링크를 통해 파일을 다운로드하고 처리합니다. 파일 정보는 `file_urls` 및 `file_path`로 저장됩니다.

## 3. 파일 다운로드 처리하기

Scrapy의 파일 다운로드 파이프라인을 사용하여 다운로드한 파일을 처리할 수 있습니다. 다운로드된 파일은 `FILES_STORE`에서 설정한 경로에 저장됩니다.

파일 다운로드 파이프라인을 활성화하기 위해 `settings.py` 파일에서 다음과 같은 설정을 추가합니다:

```python
ITEM_PIPELINES = {
   'scrapy.pipelines.files.FilesPipeline': 1
}

FILES_STORE = '<파일 저장 경로>'
```

다음은 파일 다운로드 파이프라인을 처리하는 간단한 예제 코드입니다:

```python
import scrapy

class MyFilesPipeline(FilesPipeline):
    def file_path(self, request, response=None, info=None, *, item=None):
        return item['file_path']
```

위 예제에서는 `file_path` 메서드를 오버라이드하여 다운로드 파일의 저장 경로를 설정합니다.

## 4. 실행 및 결과 확인하기

위에서 작성한 스파이더를 실행하여 파일을 다운로드하고 추출한 데이터를 확인할 수 있습니다. 

Scrapy의 실행 명령어는 다음과 같습니다:

```
scrapy crawl <스파이더 이름>
```

실행 후, 다운로드한 파일은 `FILES_STORE`에 저장되고, 추출한 데이터는 로그 또는 지정한 출력 형식으로 확인할 수 있습니다.

Scrapy를 사용하여 PDF 파일 및 다른 파일 형식을 스크레이핑하는 방법에 대해 알아보았습니다. Scrapy는 다양한 파일 형식에 대한 스크레이핑을 지원하며, 다른 파일 형식에 대해서도 유사한 절차를 따를 수 있습니다.

더 많은 정보와 자세한 내용은 [Scrapy 공식 문서](https://docs.scrapy.org)를 참고해주세요.