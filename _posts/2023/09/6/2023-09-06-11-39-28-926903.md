---
layout: post
title: "[파이썬] Beautiful Soup 4 웹 로그인 및 인증 스크레이핑"
description: " "
date: 2023-09-06
tags: [python,Beautiful Soup]
comments: true
share: true
---

웹 스크레이핑은 매우 강력한 도구이지만, 때로는 우리가 스크레이핑하려는 웹사이트에 로그인 및 인증이 필요한 경우가 있습니다. 이를 위해 Beautiful Soup 4을 사용하여 웹사이트에 로그인하고 인증된 세션을 유지하는 방법을 알아보겠습니다.

## 로그인과 세션 유지

Beautiful Soup 4을 사용하여 특정 웹사이트에 로그인하려면, 일반적으로 다음 단계를 따릅니다:

1. **로그인 페이지 가져오기**: 웹사이트의 로그인 페이지에 접근하고 HTML을 가져옵니다.
2. **로그인 데이터 준비**: 사용자 이름과 비밀번호와 같은 로그인 정보를 준비합니다.
3. **세션 생성**: 로그인 정보를 사용하여 세션을 생성합니다.
4. **인증된 세션을 사용하여 웹페이지 스크랩**: 인증된 세션을 사용하여 웹페이지의 데이터를 스크랩합니다.

다음은 Python을 사용하여 Beautiful Soup 4를 이용해 웹사이트에 로그인하고 인증된 세션을 유지하는 예제 코드입니다.

```python
import requests
from bs4 import BeautifulSoup

# 세션 생성
session = requests.Session()

# 로그인 페이지 가져오기
login_url = 'https://example.com/login'
login_page = session.get(login_url)

# BeautifulSoup를 사용하여 로그인 페이지의 HTML 가져오기
soup = BeautifulSoup(login_page.text, 'html.parser')

# 로그인 데이터 준비
login_data = {
    'username': 'your_username',
    'password': 'your_password'
}

# 로그인 요청 전송
session.post(login_url, data=login_data)

# 인증된 세션을 사용하여 웹페이지 스크랩
scraping_url = 'https://example.com/scraping-page'
scraping_page = session.get(scraping_url)

soup = BeautifulSoup(scraping_page.text, 'html.parser')

# 스크랩한 데이터 출력
print(soup.prettify())
```

위의 예제 코드에서는 `requests` 모듈을 사용하여 웹페이지에 접근하고, `BeautifulSoup`를 사용하여 HTML을 파싱합니다. `requests.Session()`을 사용하여 세션을 생성하고, `.get()` 메서드를 사용하여 로그인 페이지와 웹페이지에 접근합니다. 로그인 데이터를 딕셔너리 형태로 `login_data`에 준비하고, `.post()` 메서드를 사용하여 로그인 요청을 전송합니다.

이후 인증된 세션을 사용하여 웹페이지를 스크랩하는데, 여기서는 다른 페이지의 URL(`scraping_url`)을 사용했습니다. 스크랩한 데이터를 다시 Beautiful Soup로 파싱하고, 필요한 작업을 수행할 수 있습니다.

이제 Beautiful Soup 4을 사용하여 웹사이트에 로그인하고 인증된 세션을 유지하는 방법에 대한 기초를 알게 되었습니다. 이를 응용하여 복잡한 웹사이트에서 데이터를 스크레이핑하고 사용자 정의 작업을 수행할 수 있습니다.