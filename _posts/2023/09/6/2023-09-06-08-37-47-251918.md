---
layout: post
title: "[파이썬] TensorFlow에서 Gradient Descent"
description: " "
date: 2023-09-06
tags: [python,statsmodels]
comments: true
share: true
---

TensorFlow는 머신 러닝과 딥 러닝에 널리 사용되는 인기있는 오픈 소스 프레임워크입니다. Gradient Descent는 TensorFlow에서 많이 사용되는 최적화 알고리즘 중 하나입니다. 이번 블로그에서는 TensorFlow에서 Gradient Descent를 구현하는 방법에 대해 알아보겠습니다.

## Gradient Descent란 무엇인가요?

Gradient Descent는 주어진 함수의 최솟값을 찾기 위해 경사 하강법을 사용하는 최적화 알고리즘입니다. 함수를 최적화하기 위해 파라미터를 반복적으로 수정하는 방식으로 동작합니다. 각 단계에서 경사(gradient)의 반대 방향으로 이동하여 학습 속도를 조절하면서 최적화를 수행합니다.

## TensorFlow에서 Gradient Descent 구현하기

TensorFlow는 TensorFlow Gradient Descent Optimizer를 통해 Gradient Descent 알고리즘을 구현할 수 있습니다. 다음은 TensorFlow에서 Gradient Descent를 구현하는 간단한 예제 코드입니다.

```python
import tensorflow as tf

# 입력 데이터
X = [1, 2, 3, 4]
Y = [2, 4, 6, 8]

# 모델 파라미터
W = tf.Variable(0.0)

# 예측 함수 정의
def predict(x):
    return W * x

# 손실 함수 정의
def loss_fn(x, y):
    y_pred = predict(x)
    return tf.square(y - y_pred)

# Gradient Descent Optimizer 정의
optimizer = tf.optimizers.SGD(learning_rate=0.01)

# 최적화 수행
for epoch in range(100):
    for x, y in zip(X, Y):
        with tf.GradientTape() as tape:
            loss = loss_fn(x, y)
        gradients = tape.gradient(loss, [W])
        optimizer.apply_gradients(zip(gradients, [W]))
    print(f'Epoch: {epoch + 1}, Loss: {loss.numpy()}')

# 결과 출력
print(f'W: {W.numpy()}')
```

위의 코드에서는 입력 데이터 `X`와 해당하는 레이블 `Y`를 정의하고, 모델 파라미터 `W`를 초기화합니다. 예측 함수 `predict`와 손실 함수 `loss_fn`도 정의합니다. 그리고 `tf.optimizers.SGD`를 사용하여 Gradient Descent Optimizer를 정의하고 최적화를 수행합니다.

`tf.GradientTape`를 사용하여 Gradient Descent를 계산하고, `tape.gradient`를 사용하여 기울기를 계산합니다. 그리고 `optimizer.apply_gradients`를 사용하여 기울기를 업데이트합니다.

위의 코드를 실행하면 100 번의 에포크를 거치면서 Gradient Descent를 수행하고, 최종적으로 파라미터 `W`가 업데이트됩니다.

## 결론

TensorFlow를 사용하면 Gradient Descent 알고리즘을 쉽게 구현할 수 있습니다. 예제 코드를 통해 TensorFlow에서 Gradient Descent를 구현하는 방법을 알아보았습니다. 이를 기반으로 머신 러닝 모델을 최적화하는 데 사용할 수 있습니다.