---
layout: post
title: "[파이썬] TensorFlow에서 TF Lite"
description: " "
date: 2023-09-06
tags: [python,statsmodels]
comments: true
share: true
---

TF Lite는 TensorFlow에서 모바일 기기나 임베디드 시스템에서 모델을 실행하기 위한 경량화된 버전입니다. TF Lite를 사용하면 모델의 크기가 줄어들고, 모바일 기기에서 효율적으로 실행될 수 있습니다. 이번 포스트에서는 TensorFlow에서 TF Lite를 사용하는 방법에 대해 알아보겠습니다.

## TF Lite 변환하기

먼저, TensorFlow 모델을 TF Lite 형식으로 변환해야 합니다. 이를 위해서는 `tensorflow.lite.TFLiteConverter` 클래스를 사용합니다. 아래의 예제 코드를 참고해보세요.

```python
import tensorflow as tf

# TensorFlow 모델 로드
model = tf.keras.models.load_model('model.h5')

# TF Lite 변환
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# 변환된 모델 저장
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```

위 코드에서 `model.h5`는 TensorFlow로 학습된 모델 파일을 가리키는 경로입니다. 이 파일을 TF Lite 형식으로 변환한 후 `model.tflite`로 저장합니다.

## TF Lite 모델 실행하기

변환된 TF Lite 모델을 실행하기 위해서는 TensorFlow Lite Interpreter를 로드해야 합니다. 아래는 예제 코드입니다.

```python
import tensorflow as tf

# TF Lite Interpreter 로드
interpreter = tf.lite.Interpreter(model_path='model.tflite')
interpreter.allocate_tensors()

# 입력과 출력 텐서 정보 가져오기
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# 입력 데이터 설정
input_data = ...  # 입력 데이터를 설정하세요

# 입력 데이터 설정
interpreter.set_tensor(input_details[0]['index'], input_data)

# 모델 실행
interpreter.invoke()

# 결과 가져오기
output_data = interpreter.get_tensor(output_details[0]['index'])
```

위 코드에서 `model.tflite`는 변환된 TF Lite 모델 파일을 가리키는 경로입니다. `input_data`에는 모델에 입력할 데이터를 설정해야 합니다. 모델을 실행한 후 `output_data`에 결과가 저장됩니다.

## TF Lite 모델 성능 최적화

TF Lite는 모델 크기를 줄이고 실행 시간을 개선하기 위한 다양한 최적화 기능을 제공합니다. 아래의 예제 코드는 TF Lite 변환 시에 최적화 기능을 활성화하는 방법을 보여줍니다.

```python
import tensorflow as tf

# TensorFlow 모델 로드
model = tf.keras.models.load_model('model.h5')

# TF Lite 변환하기 (최적화 활성화)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# 변환된 모델 저장
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```

위 코드에서 `converter.optimizations`을 설정하여 최적화 기능을 활성화합니다. 이를 통해 모델 크기가 더욱 줄어들고 실행 성능이 향상될 수 있습니다.

TF Lite는 모바일 기기와 임베디드 시스템에서 TensorFlow 모델을 실행하기 위한 빠르고 경량화된 솔루션입니다. 위에서 소개한 방법을 사용하여 TF Lite로 모델을 변환하고 실행해보세요!