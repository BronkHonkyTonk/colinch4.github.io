---
layout: post
title: "[파이썬] Scrapy 웹 스크레이핑 API 작성"
description: " "
date: 2023-09-06
tags: [python,Scrapy]
comments: true
share: true
---

Scrapy는 파이썬에서 작성되었으며, 웹 스크레이핑 및 웹 크롤링에 사용되는 강력한 프레임워크입니다. 이 블로그 게시물에서는 Scrapy를 사용하여 웹 스크레이핑 API를 작성하는 방법에 대해 알아보겠습니다.

## **설치하기**
Scrapy를 사용하기 위해서는 우선 설치가 필요합니다. 다음은 pip를 사용하여 Scrapy를 설치하는 명령입니다:

```python
pip install scrapy
```

## **프로젝트 생성하기**
Scrapy를 사용하여 웹 스크레이핑 API를 작성하기 전에, 프로젝트를 생성해야 합니다. 다음 명령을 실행하여 새로운 Scrapy 프로젝트를 생성합니다:

```python
scrapy startproject myproject
```

위 명령을 실행하면 `myproject`라는 이름의 디렉토리가 생성됩니다. 이 디렉토리는 프로젝트의 모든 파일을 담고 있습니다.

## **아이템(Item) 정의하기**
Scrapy에서는 스크레이핑한 데이터를 저장하기 위해 아이템(Item)을 사용합니다. 아이템은 스크레이핑한 데이터를 구조화하여 저장하는데 사용됩니다. 예를 들어, 웹 페이지에서 제목과 URL을 스크레이핑한다고 가정해 봅시다. 이를 아이템으로 나타내기 위해 다음과 같은 코드를 작성합니다:

```python
import scrapy

class WebsiteItem(scrapy.Item):
    title = scrapy.Field()
    url = scrapy.Field()
```

위 코드에서는 아이템의 구조를 정의하는 `title`과 `url` 필드를 만듭니다.

## **스파이더(Spider) 작성하기**
Scrapy에서 스파이더는 웹 페이지를 스크랩하는 데 사용되는 컴포넌트입니다. 스파이더는 어떤 웹 페이지를 스크래핑할 것인지 정의하고, 어떤 데이터를 추출할 것인지 결정합니다. 다음은 간단한 스파이더의 예입니다:

```python
import scrapy

class MySpider(scrapy.Spider):
    name = 'myspider'
    start_urls = ['https://example.com']

    def parse(self, response):
        item = WebsiteItem()
        item['title'] = response.css('h1::text').get()
        item['url'] = response.url
        yield item
```

위 코드에서는 `MySpider`라는 클래스를 정의하고, `start_urls`로 시작 URL을 지정합니다. `parse` 메서드에서는 `WebsiteItem`을 생성하고 웹 페이지에서 데이터를 추출하여 아이템의 필드에 할당합니다.

## **스크레이핑 실행하기**
Scrapy 프로젝트의 스파이더를 실행하기 위해 명령행에서 다음 명령을 실행합니다:

```python
scrapy crawl myspider
```

위 명령을 실행하면 `MySpider`의 `parse` 메서드가 실행되고 데이터가 스크랩되어 출력될 것입니다.

이제 Scrapy를 사용하여 웹 스크레이핑 API를 작성하는 방법에 대해 알아보았습니다. Scrapy는 다양한 기능을 제공하여 웹 스크레이핑 작업을 쉽게 수행할 수 있습니다. 자세한 내용은 [Scrapy 공식 문서](https://docs.scrapy.org/)를 참조하세요.