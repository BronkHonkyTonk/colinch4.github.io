---
layout: post
title: "[파이썬] SQLAlchemy Bulk 연산 처리"
description: " "
date: 2023-09-06
tags: [SQLAlchemy]
comments: true
share: true
---

SQLAlchemy는 파이썬에서 SQL 데이터베이스를 다룰 수 있는 유용한 라이브러리입니다. 이 라이브러리를 사용하면 SQL 문을 직접 작성하지 않고도 데이터베이스와 상호 작용할 수 있습니다. 이번 글에서는 SQLAlchemy의 Bulk 연산 처리에 대해 알아보고, 대량의 데이터를 효율적으로 처리하는 방법에 대해 알아보겠습니다.

## SQLAlchemy Bulk 연산 처리란?

Bulk 연산 처리란, 데이터베이스에 대량의 데이터를 한 번에 삽입, 갱신 또는 삭제하는 작업을 말합니다. 이렇게 대량의 데이터를 한 번에 처리하면 추가적인 네트워크 오버헤드를 줄일 수 있고, 실행 시간을 단축시킬 수 있습니다.

## SQLAlchemy를 사용한 Bulk Insert

SQLAlchemy를 사용하여 대량의 데이터를 한 번에 삽입하는 방법은 간단합니다. SQLAlchemy에서는 `bulk_insert_mappings` 메소드를 제공합니다. 이 메소드를 사용하면 데이터베이스에 대량의 데이터를 효율적으로 삽입할 수 있습니다.

다음은 SQLAlchemy를 사용하여 `users` 테이블에 대량의 데이터를 삽입하는 예제입니다.

```python
from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData
from sqlalchemy.orm import sessionmaker

engine = create_engine('sqlite:///database.db')
Session = sessionmaker(bind=engine)
session = Session()

metadata = MetaData(bind=engine)
users = Table('users', metadata,
              Column('id', Integer, primary_key=True),
              Column('name', String),
              Column('age', Integer)
              )

data = [
    {'name': 'John', 'age': 25},
    {'name': 'Jane', 'age': 30},
    {'name': 'Jake', 'age': 28}
]

session.bulk_insert_mappings(users, data)
session.commit()
```

위 예제에서는 `users` 테이블에 `bulk_insert_mappings` 메소드를 사용하여 `data` 리스트의 데이터를 한 번에 삽입합니다. 이렇게 하면 개별적으로 데이터를 삽입하는 것보다 훨씬 빠르고 효율적으로 데이터를 처리할 수 있습니다.

## SQLAlchemy를 사용한 Bulk Update

SQLAlchemy를 사용하여 대량의 데이터를 한 번에 갱신하는 방법도 간단합니다. SQLAlchemy에서는 `bulk_update_mappings` 메소드를 제공합니다. 이 메소드를 사용하면 데이터베이스에 대량의 데이터를 효율적으로 갱신할 수 있습니다.

다음은 SQLAlchemy를 사용하여 `users` 테이블의 데이터를 갱신하는 예제입니다.

```python
from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData
from sqlalchemy.orm import sessionmaker

engine = create_engine('sqlite:///database.db')
Session = sessionmaker(bind=engine)
session = Session()

metadata = MetaData(bind=engine)
users = Table('users', metadata,
              Column('id', Integer, primary_key=True),
              Column('name', String),
              Column('age', Integer)
              )

data = [
    {'id': 1, 'name': 'John Doe', 'age': 26},
    {'id': 2, 'name': 'Jane Smith', 'age': 31},
    {'id': 3, 'name': 'Jake Johnson', 'age': 29}
]

session.bulk_update_mappings(users, data)
session.commit()
```

위 예제에서는 `users` 테이블에 `bulk_update_mappings` 메소드를 사용하여 `data` 리스트의 데이터를 한 번에 갱신합니다. 이렇게 하면 개별적으로 데이터를 갱신하는 것보다 훨씬 빠르고 효율적으로 데이터를 처리할 수 있습니다.

## SQLAlchemy를 사용한 Bulk Delete

SQLAlchemy를 사용하여 대량의 데이터를 한 번에 삭제하는 방법도 간단합니다. SQLAlchemy에서는 `delete` 메소드를 사용하여 데이터를 삭제할 수 있습니다.

다음은 SQLAlchemy를 사용하여 `users` 테이블의 데이터를 삭제하는 예제입니다.

```python
from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData
from sqlalchemy.orm import sessionmaker

engine = create_engine('sqlite:///database.db')
Session = sessionmaker(bind=engine)
session = Session()

metadata = MetaData(bind=engine)
users = Table('users', metadata,
              Column('id', Integer, primary_key=True),
              Column('name', String),
              Column('age', Integer)
              )

data = [
    {'id': 1},
    {'id': 2},
    {'id': 3}
]

for entry in data:
    stmt = users.delete().where(users.c.id == entry['id'])
    session.execute(stmt)
session.commit()
```

위 예제에서는 `users` 테이블에 `delete` 메소드를 사용하여 `data` 리스트의 데이터를 한 번에 삭제합니다. 개별적으로 데이터를 삭제하는 것보다 효율적으로 데이터를 처리할 수 있습니다.

## 결론

SQLAlchemy를 사용하여 대량의 데이터를 한 번에 처리하는 방법에 대해 알아보았습니다. Bulk 연산을 사용하면 데이터베이스와의 상호 작용을 효율적으로 처리할 수 있습니다. SQLAlchemy의 `bulk_insert_mappings`, `bulk_update_mappings`, `delete` 등의 메소드를 사용하여 대량의 데이터를 효과적으로 처리할 수 있으니, 필요한 경우에는 이러한 메소드를 활용해 보세요.