---
layout: post
title: "[파이썬] `nltk`에서의 FreqDist 사용"
description: " "
date: 2023-09-06
tags: [python,nltk]
comments: true
share: true
---

자연어 처리를 위한 파이썬 라이브러리인 `nltk(Natural Language Toolkit)`는 다양한 기능을 제공하며, 데이터셋에 대한 빈도 분석을 도와주는 `FreqDist` 클래스를 포함하고 있습니다. 이번 글에서는 `nltk`의 `FreqDist` 클래스를 사용하여 텍스트 데이터의 단어 빈도를 계산하는 방법에 대해 알아보겠습니다.

### FreqDist 클래스 소개

`FreqDist` 클래스는 `nltk` 패키지에서 제공하는 클래스로, 주어진 텍스트 데이터에 대한 단어의 빈도를 계산합니다. 이 빈도 정보는 사전 형식으로 저장되어 있어서 각 단어와 해당 단어의 등장 횟수를 추출할 수 있습니다.

### FreqDist 클래스의 사용법

먼저, `nltk` 패키지를 설치한 후, 다음과 같이 코드를 작성하여 `FreqDist` 클래스를 사용할 수 있습니다.

```python
import nltk
from nltk import FreqDist

# 텍스트 데이터를 리스트로 선언
text_data = [
    'I love programming in Python',
    'Python is a popular programming language',
    'Python has great libraries for data analysis'
]

# FreqDist 클래스를 사용하여 단어 빈도 계산
fdist = FreqDist()

# 각 문장에 대해 단어를 토큰화(분리)하여 빈도 계산
for sentence in text_data:
    words = nltk.word_tokenize(sentence)
    fdist.update(words)

# 빈도 분포 출력
print(fdist)
```

위의 코드 예제에서는 `text_data` 리스트에 세 개의 문장을 저장하였습니다. 이러한 문장들에 대해서 `FreqDist` 클래스를 이용하여 단어의 빈도를 계산합니다. 각 문장에 대해 `nltk`의 `word_tokenize()` 함수를 사용하여 단어를 토큰화(분리)하고, `update()` 메서드를 사용하여 단어의 빈도를 갱신합니다.

마지막으로, `print(fdist)`문을 사용하여 빈도 분포를 출력합니다. 이 때, 출력되는 값은 단어와 해당 단어의 등장 횟수로 구성된 사전 형식의 데이터입니다.

### FreqDist 클래스의 활용

`FreqDist` 클래스의 활용은 단순히 단어의 빈도를 계산하는 것에 그치지 않습니다. 이 클래스는 여러 가지 다양한 메서드를 제공하며, 다양한 통계적 분석을 수행할 수 있습니다. 예를 들어, 가장 많이 등장한 단어를 추출하는 `most_common()` 메서드를 사용하거나, 단어의 히스토그램을 그리는 `plot()` 메서드를 사용할 수 있습니다.

```python
# 가장 빈도가 높은 단어 3개 출력
print(fdist.most_common(3))

# 단어의 빈도를 시각화하여 히스토그램 그리기
fdist.plot(30, cumulative=False)
```

위의 코드 예제에서는 `most_common()` 메서드를 이용하여 가장 빈도가 높은 단어 3개를 출력하고, `plot()` 메서드를 사용하여 단어의 빈도를 시각화하여 히스토그램을 그립니다.

### Wrap Up

이번 글에서는 `nltk`의 `FreqDist` 클래스를 사용하여 텍스트 데이터의 단어 빈도를 계산하는 방법에 대해 알아보았습니다. `nltk`를 사용하면 간단하게 단어의 빈도를 계산하고, 다양한 통계적 분석을 수행할 수 있습니다. 이러한 기능들을 통해 텍스트 데이터에 대한 분석과 처리를 더욱 효율적으로 수행할 수 있습니다.