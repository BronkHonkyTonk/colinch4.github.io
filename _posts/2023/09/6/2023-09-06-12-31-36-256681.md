---
layout: post
title: "[파이썬] Scrapy 크롤링 데이터의 지리적 분석"
description: " "
date: 2023-09-06
tags: [Scrapy]
comments: true
share: true
---

지금은 데이터가 점점 더 중요해지고 있습니다. 많은 회사와 조직은 웹 상의 데이터를 수집하여 경영에 활용하고 있습니다. 그러나 데이터만 수집하는 것은 충분하지 않습니다. 데이터를 분석하고 시각화하여 의미 있는 정보를 얻는 것이 중요합니다.

지리적 분석은 데이터에서 지리적인 특성을 파악하는 것을 의미합니다. 이는 데이터를 지도 위에 시각화하는 것을 통해 이루어질 수 있습니다. 이 글에서는 Scrapy 크롤링 데이터를 활용하여 지리적 분석을 수행하는 방법을 알아보겠습니다.

## Scrapy란?

Scrapy는 파이썬 기반의 웹 크롤링 프레임워크입니다. 웹 페이지를 간단하게 크롤링하고 데이터를 추출하는 기능을 제공합니다. Scrapy를 사용하면 웹페이지에서 데이터를 추출하고 이를 자신의 목적에 맞게 가공할 수 있습니다.

Scrapy는 강력하면서도 유연한 동시에 확장 가능한 크롤링 솔루션입니다. 그러므로 Scrapy를 사용하여 데이터를 수집하고 이를 지리적 분석에 활용할 수 있습니다.

## 지리적 분석을 위한 데이터 수집

Scrapy를 사용하여 지리적 분석을 위한 데이터를 수집하기 위해서는 다음 단계를 따를 수 있습니다.

1. Scrapy 프로젝트 생성
2. 크롤링할 웹페이지 설정
3. 데이터 추출

먼저, Scrapy 프로젝트를 생성해 보겠습니다. 아래의 명령어를 실행하여 새로운 Scrapy 프로젝트를 생성합니다.

```python
scrapy startproject geospatial_analysis
```

프로젝트가 성공적으로 생성되면, 생성된 프로젝트 디렉토리로 이동합니다.

```python
cd geospatial_analysis
```

다음으로, 크롤링할 웹페이지를 설정해야 합니다. `spiders` 디렉토리에 새로운 스파이더를 생성하여 원하는 웹페이지를 크롤링할 수 있습니다.

예를 들어, `example.com` 웹페이지를 크롤링한다고 가정해 보겠습니다. 다음 명령어를 실행하여 `example_spider.py` 파일을 생성합니다.

```python
scrapy genspider example example.com
```

이제 `example_spider.py` 파일을 열어 웹페이지 크롤링에 필요한 코드를 작성합니다. 예를 들어, 웹페이지의 제목을 추출하는 코드는 다음과 같습니다.

```python
import scrapy

class ExampleSpider(scrapy.Spider):
    name = 'example'
    
    def start_requests(self):
        urls = ['http://www.example.com']
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)
    
    def parse(self, response):
        title = response.css('h1::text').get()
        yield {'title': title}
```

이제 데이터를 추출했으므로, 이를 지리적 분석에 활용할 수 있습니다.

## 지리적 분석 예시

지리적 분석을 위해 수집한 데이터를 지도 위에 시각화해 보겠습니다. 아래 코드는 `folium` 라이브러리를 사용하여 추출한 데이터를 지도 위에서 표시합니다.

```python
import folium

# 데이터 로드 (위도, 경도 포함)
data = [
    {
        'title': 'Example',
        'lat': 37.5665,
        'lon': 126.9780
    },
    # ...
]

# 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=12)

# 데이터 마커 추가
for d in data:
    folium.Marker([d['lat'], d['lon']], popup=d['title']).add_to(m)

# 지도 출력
m.save('map.html')
```

위의 코드를 실행하면 `map.html` 파일이 생성되고, 이 파일을 열어 지도를 확인할 수 있습니다.

## 결론

Scrapy를 사용하여 데이터를 수집하고, 이를 지리적 분석에 활용하는 방법을 알아보았습니다. 데이터를 효과적으로 분석하고 시각화함으로써 의미 있는 정보를 얻을 수 있습니다. 이를 통해 조직의 경영에 도움을 주는 지리적 분석을 수행할 수 있습니다.