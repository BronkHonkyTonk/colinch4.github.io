---
layout: post
title: "[파이썬] requests-html 소개"
description: " "
date: 2023-09-06
tags: [python,requests-html]
comments: true
share: true
---

## 소개

requests-html은 Python에서 **웹 스크래핑**을 간편하게 수행할 수 있는 도구입니다. 이 도구는 `requests`와 `Beautiful Soup` 라이브러리를 결합하여 사용합니다. requests-html을 사용하면 웹 페이지의 내용을 쉽게 가져올 수 있으며, HTML 문서를 파싱하고 검색하는 작업을 간단하게 수행할 수 있습니다.

## 특징

requests-html은 다음과 같은 특징을 가지고 있습니다:

- **자동 세션 관리**: requests-html은 자동으로 세션을 관리하기 때문에 쿠키, 레퍼러 등의 정보를 쉽게 사용할 수 있습니다.

- **Javscript 렌더링**: requests-html은 `HTMLSession` 객체를 통해 JavaScript를 실행하여 동적으로 생성되는 웹 페이지의 내용을 가져올 수 있습니다.

- **CSS 선택자 및 XPath**: BeautifulSoup과 유사한 방식으로 CSS 선택자나 XPath를 사용하여 원하는 요소를 쉽게 찾을 수 있습니다.

- **편리한 API**: requests-html은 직관적이고 사용하기 편리한 API를 제공하여 개발자가 웹 스크래핑 작업을 빠르고 쉽게 수행할 수 있도록 도와줍니다.

## 설치

requests-html은 pip를 사용하여 간단하게 설치할 수 있습니다. 아래 명령을 터미널에서 실행하여 requests-html을 설치하세요:

```python
pip install requests-html
```

## 예제

아래는 requests-html을 사용하여 웹 페이지의 제목과 링크를 가져오는 간단한 예제입니다:

```python
from requests_html import HTMLSession

# HTML 세션 시작
session = HTMLSession()

# 웹 페이지 가져오기
response = session.get('https://example.com')

# 제목 가져오기
title = response.html.find('title', first=True).text

# 링크 가져오기
links = response.html.links

# 결과 출력
print(f'Title: {title}')
print('Links:')
for link in links:
    print(link)
```

위 예제에서는 requests-html의 `HTMLSession` 객체를 사용하여 세션을 시작하고, `get()` 메서드를 사용하여 웹 페이지의 내용을 가져옵니다. 그런 다음, `find()` 메서드를 사용하여 제목 태그를 찾고, `links` 속성을 사용하여 모든 링크를 가져옵니다. 마지막으로, 결과를 화면에 출력합니다.

## 마무리

requests-html은 강력한 웹 스크래핑 도구로, Python을 사용하여 웹 페이지의 내용을 쉽게 가져올 수 있습니다. 이번 포스트에서는 requests-html의 소개와 간단한 예제를 살펴보았습니다. requests-html의 다양한 기능을 사용하여 웹 스크래핑 작업을 더욱 효율적으로 수행할 수 있습니다.