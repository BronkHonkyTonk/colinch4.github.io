---
layout: post
title: "[파이썬] Scrapy 소개"
description: " "
date: 2023-09-06
tags: [python,Scrapy]
comments: true
share: true
---

## 무엇인가요?

Scrapy는 파이썬으로 만들어진 웹 크롤링 및 웹 스크래핑 프레임워크입니다. 이 프레임워크를 사용하면 웹 사이트에서 데이터를 추출하고 웹 크롤링을 자동화할 수 있습니다.

## 주요 특징

Scrapy는 다음과 같은 주요 특징을 가지고 있습니다:

- **스피더(Spider):** Scrapy의 핵심 구성 요소로, 웹 사이트를 탐색하고 데이터를 추출하는데 사용됩니다.

- **선택적 다운로드:** Scrapy는 데이터를 수집할 때 선택적으로 다운로드할 수 있습니다. 예를 들어, 이미지 파일이나 문서 파일만 다운로드하거나 정해진 규칙에 따라 필터링하여 다운로드할 수 있습니다.

- **설정 가능한 파이프라인:** Scrapy는 추출한 데이터를 처리하는 파이프라인을 설정할 수 있습니다. 이를 통해 데이터베이스에 저장하거나 CSV 파일로 내보낼 수 있습니다.

- **HTTP 캐싱 및 세션 관리:** Scrapy는 HTTP 요청을 캐싱하고 세션을 관리하여 크롤링 속도를 향상시킬 수 있습니다.

- **분산 크롤링:** Scrapy는 분산 환경에서 여러 대의 컴퓨터를 사용하여 크롤링 작업을 병렬로 처리할 수 있습니다.

## 예제 코드

다음은 Scrapy를 사용하여 간단한 웹 크롤러를 작성하는 예제 코드입니다.

```python
import scrapy

class MySpider(scrapy.Spider):
    name = 'example_spider'
    start_urls = ['http://example.com']

    def parse(self, response):
        # 웹 페이지에서 데이터 추출
        title = response.css('h1::text').get()
        content = response.css('p::text').get()

        # 추출한 데이터 출력
        print(f'Title: {title}')
        print(f'Content: {content}')

        # 다음 링크를 따라가기 위해 parse 함수 재귀 호출
        for link in response.css('a::attr(href)'):
            yield response.follow(link.get(), self.parse)
```

위 코드는 `MySpider`라는 스파이더를 정의하고, `start_urls`에 지정된 웹 페이지에서 데이터를 추출하는 기본적인 구조입니다. `parse` 함수는 각 웹 페이지에서 데이터를 추출하고 출력하는 역할을 합니다. 또한, 다음 링크를 따라가기 위해 재귀적으로 `parse` 함수를 호출합니다.

이 예제 코드로 실행하면 `example.com`에서 데이터를 추출하고 출력하는 간단한 웹 크롤러가 작동합니다.

## 결론

Scrapy는 웹 크롤링 및 스크래핑 작업을 간편하고 효율적으로 수행할 수 있는 강력한 프레임워크입니다. 다양한 기능과 유연한 구성으로 웹 데이터 수집 작업을 자동화하는데 유용하게 사용할 수 있습니다.