---
layout: post
title: "[파이썬] requests-html 페이징 처리"
description: " "
date: 2023-09-06
tags: [python,requests-html]
comments: true
share: true
---

In web scraping, it is often necessary to scrape data from multiple pages. One common scenario is when a website has multiple pages of search results or when data is divided into multiple pages for better organization. In such cases, handling pagination becomes crucial. 

The `requests-html` library in Python provides a convenient way to handle pagination and scrape data from multiple pages. In this blog post, we will explore how to use `requests-html` for paging in Python.

### Installing requests-html
First, let's make sure you have `requests-html` installed. Open your terminal and run the following command to install it using pip:

```bash
pip install requests-html
```

### Setting Up requests-html
After installing `requests-html`, we need to import the necessary modules and set up a session to use the library:

```python
from requests_html import HTMLSession

session = HTMLSession()
```

### Scraping Multiple Pages with Paging
To scrape data from multiple pages, we need to follow these steps:

1. Define a base URL that represents the initial page.
2. Make a GET request to the base URL using the `get()` method of the session object.
3. Extract the necessary data from the response using HTML parsing techniques.
4. Check if there are more pages available.
5. If more pages are available, extract the URL of the next page and repeat steps 2-4.
6. If there are no more pages, stop scraping.

Here's an example that demonstrates how to scrape data from multiple pages using `requests-html`:

```python
base_url = 'https://example.com/search?page='
page_num = 1

while True:
    url = base_url + str(page_num)

    # Make a GET request to the page
    response = session.get(url)

    # Extract data from the response
    # Code for extracting data goes here...

    # Check if more pages are available
    if 'Next' not in response.html.links:
        break

    page_num += 1

session.close()
```

In this example, we start with the initial page by setting `page_num` to 1. Inside the while loop, we dynamically generate the URL of the next page by appending the page number to the base URL. We then make a GET request to the generated URL using the `get()` method.

After extracting the desired data from the response, we check if more pages are available by looking for a "Next" link in the response's HTML. If the "Next" link is not present, we break out of the loop and stop scraping.

### Conclusion
In this blog post, we explored how to handle pagination using `requests-html` in Python for scraping data from multiple pages. By following the steps and using the example code provided, you can easily scrape data from web pages with multiple pages. Happy scraping!