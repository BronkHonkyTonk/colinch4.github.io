---
layout: post
title: "[파이썬] Selenium 동적 웹 페이지 다루기"
description: " "
date: 2023-09-06
tags: [python,Selenium]
comments: true
share: true
---

![Selenium Logo](https://www.selenium.dev/images/selenium_logo_square_yellow.png)

## Introduction
Selenium is a powerful tool for automating web browsers. It is widely used for testing web applications and scraping data from websites. In this blog post, we will explore how to handle dynamic web pages using Selenium in Python.

## What is a dynamic web page?
A dynamic web page is a web page that changes its content dynamically, without the need for a page refresh. This is typically done using JavaScript to update or add new content to the page.

## Why is handling dynamic web pages important?
Dynamic web pages can pose a challenge when it comes to web scraping or automation, as the content may not be immediately available when the page loads. Additionally, elements on the page may change or be added/removed dynamically, making it difficult to locate and interact with them.

## Getting started with Selenium in Python
To begin, make sure you have Selenium installed. You can install it using pip with the following command:
```
pip install selenium
```
You will also need a web driver corresponding to your browser. Selenium supports various browsers, such as Chrome, Firefox, and Edge. For this example, we will use the Chrome web driver.

## Example: Scraping data from a dynamic web page
Let's say we want to scrape data from a web page that dynamically loads new content as we scroll down. Here's how we can achieve that using Selenium in Python:

```python
from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys

# Instantiate the Chrome web driver
driver = webdriver.Chrome()

# Navigate to the desired web page
driver.get("https://www.example.com")

# Scroll down to load more content
while True:
    # Perform scroll by sending PAGE_DOWN key
    ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()
    
    # Check if new content is loaded
    if new_content_loaded():
        break

# Extract the desired data from the web page
data = extract_data(driver)

# Close the web driver
driver.quit()

# Process the extracted data
process_data(data)
```

In this example, we are using the Chrome web driver to navigate to a web page and scroll down until all the content is loaded. We then extract the desired data from the web page and finally process it.

## Conclusion
Selenium is a powerful tool for handling dynamic web pages in Python. It allows us to interact with web elements and perform actions on web pages dynamically. By using Selenium, we can easily automate tasks or extract data from websites that rely on JavaScript to update their content.

In this blog post, we saw how to scrape data from a dynamically loading web page using Selenium in Python. With this knowledge, you can start exploring more complex scenarios and build robust web scraping or automation solutions.