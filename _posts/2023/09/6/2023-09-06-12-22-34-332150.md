---
layout: post
title: "[파이썬] Scrapy와 Jupyter Notebook 통합"
description: " "
date: 2023-09-06
tags: [Scrapy]
comments: true
share: true
---

Scrapy와 Jupyter Notebook은 둘 다 파이썬 개발자들에게 매우 유용한 도구입니다. Scrapy는 웹 크롤링과 스크래핑을 위한 강력한 프레임워크이며, Jupyter Notebook은 데이터 분석과 시각화를 위한 인터랙티브한 환경을 제공합니다. 이 글에서는 Scrapy와 Jupyter Notebook을 통합하여 더 효율적인 웹 스크래핑과 데이터 분석 작업을 수행하는 방법에 대해 알아보겠습니다.

### Scrapy와 Jupyter Notebook 설치

먼저, Scrapy와 Jupyter Notebook을 설치해야 합니다. 아래의 명령어를 사용하여 설치할 수 있습니다.

```python
pip install scrapy
pip install jupyter notebook
```

### Scrapy 프로젝트 생성

다음으로, Scrapy 프로젝트를 생성해야 합니다. 아래의 명령어를 실행하여 Scrapy 프로젝트를 생성하십시오.

```python
scrapy startproject myproject
```

### Jupyter Notebook 실행

Jupyter Notebook을 실행해야 Scrapy와 통합할 수 있습니다. 아래의 명령어를 실행하여 Jupyter Notebook을 실행하십시오.

```python
jupyter notebook
```

### Scrapy 코드 작성

Scrapy 프로젝트를 생성하고 Jupyter Notebook을 실행했다면, 이제 Scrapy 코드를 작성할 차례입니다. 주피터 노트북을 사용하면 Scrapy 코드를 쉽게 작성하고 실행할 수 있습니다.

아래는 Scrapy의 예시 코드입니다. 이 예시 코드는 http://quotes.toscrape.com 사이트에서 명언들을 스크래핑하는 코드입니다.

```python
import scrapy

class QuotesSpider(scrapy.Spider):
    name = "quotes"
    start_urls = ['http://quotes.toscrape.com/page/1/',
                  'http://quotes.toscrape.com/page/2/']

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('span small::text').get(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
```

### Scrapy 코드 실행

Scrapy 코드를 작성했다면, 이제 해당 코드를 실행할 차례입니다. 주피터 노트북을 사용하여 Scrapy 코드를 실행하는 것은 간단합니다. 아래의 코드를 실행하여 Scrapy 코드를 실행하십시오.

```python
from scrapy.crawler import CrawlerProcess
from myproject.spiders.quotes_spider import QuotesSpider

process = CrawlerProcess()
process.crawl(QuotesSpider)
process.start()
```

### 데이터 분석과 시각화

Scrapy를 사용하여 웹 스크래핑한 데이터를 Jupyter Notebook에서 바로 데이터 분석과 시각화 작업을 할 수 있습니다. Scrapy로 스크랩한 데이터를 Pandas 데이터프레임으로 변환한 후, 데이터를 분석하고 시각화하는 작업을 수행할 수 있습니다.

아래는 예시 코드입니다. 이 코드는 스크랩한 명언 데이터를 데이터프레임으로 변환하고, 가장 많이 나온 저자를 막대 그래프로 시각화합니다.

```python
import pandas as pd
import matplotlib.pyplot as plt

data = [
    {'text': 'quote1', 'author': 'author1'},
    {'text': 'quote2', 'author': 'author2'},
    {'text': 'quote3', 'author': 'author3'},
    ...
]

df = pd.DataFrame(data)
author_counts = df['author'].value_counts()

plt.figure(figsize=(10, 6))
author_counts.plot(kind='bar')
plt.xlabel('Author')
plt.ylabel('Count')
plt.title('Most Popular Authors')
plt.show()
```

### 마무리

이렇게 Scrapy와 Jupyter Notebook을 통합하여 웹 스크래핑과 데이터 분석 작업을 더 효율적이고 편리하게 수행할 수 있습니다. Scrapy로 데이터를 수집하고 Jupyter Notebook으로 데이터를 분석하면, 데이터 기반의 의사 결정을 빠르게 할 수 있습니다. 이를 통해 개발자들은 보다 재미있고 효과적인 웹 스크래핑 및 데이터 분석 경험을 얻을 수 있습니다.