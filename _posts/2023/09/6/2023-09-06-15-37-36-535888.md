---
layout: post
title: "[파이썬] nltk 토큰화 (Tokenization)"
description: " "
date: 2023-09-06
tags: [python,nltk]
comments: true
share: true
---

텍스트 처리 작업을 수행할 때, 자연어 처리와 텍스트 분석을 위해 텍스트를 작은 단위로 나누어야합니다. 이러한 단위를 **토큰(Token)** 이라고 합니다. 토큰화(Tokenization)는 자연어 처리에서 텍스트를 토큰으로 분리하는 과정을 의미합니다. 

Python에서 자주 사용되는 자연어 처리 라이브러리 중 하나인 NLTK(Natural Language Toolkit)는 토큰화를 위한 다양한 기능과 메서드를 제공합니다. 

## 단어 토큰화 (Word Tokenization)

가장 기본적인 토큰화 방법 중 하나는 단어 토큰화입니다. 이 방법은 문장을 단어로 나누는 작업입니다. Python에서 NLTK를 사용하여 단어 토큰화를 수행하는 코드는 다음과 같습니다:

```python
import nltk

sentence = "Hello, World! This is a sample sentence."
tokens = nltk.word_tokenize(sentence)

print(tokens)
```

위의 코드는 입력문장을 단어로 나누어 토큰화한 결과를 출력합니다. 출력은 다음과 같습니다:

```
['Hello', ',', 'World', '!', 'This', 'is', 'a', 'sample', 'sentence', '.']
```

## 문장 토큰화 (Sentence Tokenization)

텍스트를 문장 단위로 나누기 위해 문장 토큰화(Sentence Tokenization)를 사용할 수 있습니다. Python의 NLTK를 사용하면 다음과 같이 문장 토큰화를 수행할 수 있습니다:

```python
import nltk

paragraph = "Hello, World! This is a sample paragraph. It contains multiple sentences."
sentences = nltk.sent_tokenize(paragraph)

print(sentences)
```

위의 코드는 입력 문단을 문장으로 나누어 토큰화한 결과를 출력합니다. 출력은 다음과 같습니다:

```
['Hello, World!', 'This is a sample paragraph.', 'It contains multiple sentences.']
```

## 특수문자 제거

토큰화 과정에서는 종종 텍스트에서 특수문자를 제거하는 것이 필요합니다. 이를 위해 정규표현식을 사용하여 특수문자를 제거하는 방법을 알아보겠습니다. 다음 코드는 문장에서 특수문자를 제거하는 예시입니다:

```python
import re

sentence = "Hello, World! Please remove all the special characters."
cleaned_sentence = re.sub(r'[^a-zA-Z0-9\s]', '', sentence)

print(cleaned_sentence)
```

위의 코드는 입력 문장에서 알파벳, 숫자, 및 공백을 제외한 모든 특수문자를 제거한 결과를 출력합니다. 출력은 다음과 같습니다:

```
Hello World Please remove all the special characters
```

위의 예시 코드를 참고하여 자신의 텍스트 데이터에 대한 토큰화 작업을 수행해 보세요. NLTK에는 더 많은 토큰화 방법과 기능이 있으며, 이를 통해 텍스트 처리 작업을 더욱 쉽게 수행할 수 있습니다.