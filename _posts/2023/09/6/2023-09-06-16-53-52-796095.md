---
layout: post
title: "[파이썬] nltk 문서 유사도 측정"
description: " "
date: 2023-09-06
tags: [nltk]
comments: true
share: true
---

머신 러닝 또는 자연어 처리 프로젝트에서 문서 간의 유사도를 측정하는 것은 중요한 작업입니다. 이를 통해 문서의 유사성을 파악하고, 관련된 문서를 찾거나 텍스트 분류를 수행할 수 있습니다. NLTK(Natural Language Toolkit)는 파이썬에서 자연어 처리 작업에 유용한 도구 모음입니다. 이번 블로그 포스트에서는 NLTK를 사용하여 문서 유사도를 측정하는 방법에 대해 알아보겠습니다.

## 문서 유사도 측정 방법

NLTK는 다양한 문서 유사도 측정 알고리즘을 제공합니다. 여기서는 두 가지 유명한 알고리즘을 소개하고, 예제 코드를 통해 실제로 사용하는 방법을 알아보겠습니다.

### 코사인 유사도(Cosine Similarity)

코사인 유사도는 문서 간의 유사성을 측정하는 일반적인 방법 중 하나입니다. 이 방법은 문서를 특정한 공간에 벡터로 표현하고, 벡터 간의 각도를 측정하여 유사도를 계산합니다.

NLTK에서 코사인 유사도를 계산하는 방법은 다음과 같습니다.

```python
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet
from sklearn.feature_extraction.text import TfidfVectorizer

def preprocess_text(text):
    # 텍스트 전처리 작업 수행
    tokens = word_tokenize(text.lower())
    stopwords_removed = [token for token in tokens if token not in stopwords.words('english')]
    lemmatized_tokens = [wordnet.lemmatize(token) for token in stopwords_removed]
    return ' '.join(lemmatized_tokens)

def calculate_cosine_similarity(doc1, doc2):
    # 문서를 전처리하고 벡터 표현으로 변환
    preprocessed_doc1 = preprocess_text(doc1)
    preprocessed_doc2 = preprocess_text(doc2)
    vectorizer = TfidfVectorizer()
    vectors = vectorizer.fit_transform([preprocessed_doc1, preprocessed_doc2])

    # 코사인 유사도 계산
    cosine_similarity = (vectors * vectors.T).A[0, 1]

    return cosine_similarity

# 예제 문서
doc1 = "I like to eat apples."
doc2 = "I enjoy eating apples."

# 문서 유사도 계산
similarity = calculate_cosine_similarity(doc1, doc2)
print(f"Cosine similarity: {round(similarity, 2)}")
```

### 자카드 유사도(Jaccard Similarity)

자카드 유사도는 문서 간의 공통된 단어 비율을 측정하는 방법입니다. 이 방법은 문서를 집합으로 간주하고, 두 집합 간의 교집합과 합집합의 비율을 계산하여 유사도를 판단합니다.

NLTK에서 자카드 유사도를 계산하는 방법은 다음과 같습니다.

```python
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

def preprocess_text(text):
    # 텍스트 전처리 작업 수행
    tokens = word_tokenize(text.lower())
    stopwords_removed = [token for token in tokens if token not in stopwords.words('english')]
    return set(stopwords_removed)

def calculate_jaccard_similarity(doc1, doc2):
    # 문서를 전처리하고 집합으로 변환
    set1 = preprocess_text(doc1)
    set2 = preprocess_text(doc2)

    # 자카드 유사도 계산
    intersection = set1.intersection(set2)
    union = set1.union(set2)
    jaccard_similarity = len(intersection) / len(union)

    return jaccard_similarity

# 예제 문서
doc1 = "I like to eat apples."
doc2 = "I enjoy eating apples."

# 문서 유사도 계산
similarity = calculate_jaccard_similarity(doc1, doc2)
print(f"Jaccard similarity: {round(similarity, 2)}")
```

## 결과 및 결론

NLTK를 사용하여 문서 유사도를 측정하는 방법에 대해 알아보았습니다. 코사인 유사도와 자카드 유사도는 각각 다른 방식으로 문서 간의 유사성을 측정하며, 프로젝트에 따라 적합한 방법을 선택할 수 있습니다. 이러한 유사도 측정 알고리즘을 활용하면 자연어 처리 작업에 필요한 문서 분석과 관련된 다양한 작업을 수행할 수 있습니다.