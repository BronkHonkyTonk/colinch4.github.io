---
layout: post
title: "[파이썬] requests-html 웹 크롤러 편의성 향상"
description: " "
date: 2023-09-06
tags: [requests-html]
comments: true
share: true
---

![requests-html logo](https://raw.githubusercontent.com/psf/requests-html/master/docs/.vuepress/public/static/requests-html-logo.png)

크롤링은 웹 개발 및 데이터 분석 과정에서 중요한 부분이다. Python에서는 다양한 라이브러리를 사용하여 웹 크롤러를 구현할 수 있다. 그 중 Requests-HTML은 강력하면서도 사용하기 편한 웹 크롤링 도구이다. 이번 포스트에서는 Requests-HTML을 사용하여 웹 크롤러를 구현하는 과정에서 편의성을 높이는 몇 가지 기능을 알아볼 것이다.

## 1. HTML 파싱의 용이성

Requests-HTML은 BeautifulSoup와 유사한 방식으로 HTML을 파싱할 수 있다. 하지만 Requests-HTML은 HTML 요소에 대한 CSS 선택자 기반으로 쉽게 탐색할 수 있는 기능을 제공한다. 아래의 예제를 살펴보자.

```python
from requests_html import HTMLSession

session = HTMLSession()
response = session.get('https://example.com')

# CSS 선택자를 사용하여 원하는 요소 선택
title = response.html.find('h1', first=True).text
print(title)
```

위의 예제에서는 `h1` 태그를 가지고 있는 첫 번째 요소의 텍스트를 추출하여 `title` 변수에 저장하고 출력한다. 이렇게 CSS 선택자를 활용하면 HTML 요소를 쉽게 찾을 수 있어 웹 크롤링 프로세스를 단순화할 수 있다.

## 2. 자바스크립트 렌더링 지원

많은 웹 페이지에서는 자바스크립트를 사용하여 동적으로 콘텐츠를 로드하는 경우가 많다. 기존의 웹 크롤러로는 이러한 동적 콘텐츠를 크롤링하기 어려웠다. 하지만 Requests-HTML은 자체적으로 자바스크립트를 실행시킬 수 있는 모듈을 내장하고 있다. 아래의 예제를 살펴보자.

```python
from requests_html import HTMLSession

session = HTMLSession()
response = session.get('https://example.com')

# 자바스크립트를 실행하여 동적 콘텐츠를 로드
response.html.render()

# 동적으로 로드된 콘텐츠에서 원하는 요소 선택
title = response.html.find('h1', first=True).text
print(title)
```

위의 예제에서는 `render()` 메서드를 사용하여 자바스크립트를 실행시키고 동적으로 로드된 콘텐츠를 얻는다. 이후 CSS 선택자를 활용하여 원하는 요소를 선택하여 정보를 추출한다. 이렇게 Requests-HTML은 자바스크립트로 생성된 콘텐츠도 크롤링할 수 있도록 편의성을 제공한다.

## 3. 다양한 기능 및 확장성

Requests-HTML은 다양한 기능을 제공하여 웹 크롤링 프로세스를 더욱 편하게 만들어준다. 예를 들어 세션 유지, 쿠키 처리, HTTP 프록시 지원 등과 같은 기능을 손쉽게 활용할 수 있다. 또한, 다른 Python 라이브러리와 함께 사용할 수 있는 유연성도 가지고 있다.

:::tip
Requests-HTML은 Requests 라이브러리를 기반으로 하고 있으므로 Requests의 기능도 모두 사용 가능하다.
:::

```python
from requests_html import HTMLSession
import csv

session = HTMLSession()
response = session.get('https://example.com')

# 테이블 데이터 추출하여 CSV 파일로 저장
table = response.html.find('table', first=True)
rows = table.find('tr')

with open('data.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    for row in rows:
        cols = row.find('td')
        writer.writerow([col.text for col in cols])
```

위의 예제에서는 Requests-HTML과 함께 csv 모듈을 사용하여 테이블 데이터를 추출하고 CSV 파일로 저장한다. 이처럼 Requests-HTML은 다른 라이브러리와의 통합도 용이하여 사용자의 요구에 맞게 확장할 수 있다.

## 결론

Requests-HTML은 사용하기 쉽고 편의성을 갖춘 Python 웹 크롤링 도구이다. HTML 파싱의 용이성과 자바스크립트 렌더링 지원은 웹 크롤링 프로세스를 단순화하고, 다양한 기능과 확장성은 사용자 요구에 유연하게 대응할 수 있도록 도와준다. 따라서 데이터 수집 및 분석을 위한 웹 크롤러를 개발할 때, Requests-HTML을 고려해보는 것이 좋다.

:::note
Requests-HTML의 자세한 사용법은 [공식 문서](https://html.python-requests.org/)를 참조하자.
:::