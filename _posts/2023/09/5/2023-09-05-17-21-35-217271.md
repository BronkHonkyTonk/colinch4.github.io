---
layout: post
title: "[파이썬][scikit-learn] scikit-learn에서 릿지 회귀"
description: " "
date: 2023-09-05
tags: [python,scikit learn]
comments: true
share: true
---

## 소개
리지 회귀는 scikit-learn 라이브러리에서 제공하는 회귀 알고리즘 중 하나입니다. 리지 회귀는 선형 모델 중 한 종류로, 주어진 데이터를 가장 잘 설명하는 선형 함수를 찾는 알고리즘입니다. 이 알고리즘은 데이터에 대한 과적합을 방지하기 위해 큰 가중치를 가진 특성들을 제한하는 데 초점을 둡니다.

## 리지 회귀 예제

```python
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 데이터 준비
X = [[0, 0], [1, 1], [2, 2]]
y = [0, 1, 2]

# 학습 및 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 리지 회귀 모델 생성
ridge_model = Ridge(alpha=1.0)

# 모델 학습
ridge_model.fit(X_train, y_train)

# 테스트 데이터에 대한 예측
y_pred = ridge_model.predict(X_test)

# 성능 평가 (평균 제곱 오차 계산)
mse = mean_squared_error(y_test, y_pred)

print("Mean Squared Error:", mse)
```

위의 예제는 scikit-learn을 사용하여 리지 회귀 모델을 생성하고 학습 및 예측 수행하는 간단한 코드입니다. 이 예제에서는 입력 데이터 X와 출력 데이터 y를 준비하고, 학습 데이터와 테스트 데이터로 분리한 다음, 리지 회귀 모델을 생성하여 학습합니다. 마지막으로 테스트 데이터에 대한 예측을 수행하고 평균 제곱 오차를 계산하여 모델의 성능을 평가합니다.

## 모델 성능 향상을 위한 alpha 조정
리지 회귀의 핵심 파라미터인 alpha는 가중치를 제한하는 정도를 조절합니다. alpha 값이 크면 가중치가 작아지므로 과적합이 줄어듭니다. 하지만 alpha 값이 너무 크면 모델이 과소적합 될 수 있습니다. 따라서 alpha 값을 적절히 조정하여 최적의 모델 성능을 얻을 수 있도록 해야합니다.

```python
# alpha 값 바꿔가며 모델 훈련 및 평가
for alpha_val in [0.1, 1, 10]:
    ridge_model = Ridge(alpha=alpha_val)
    ridge_model.fit(X_train, y_train)
    y_pred = ridge_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    print(f"Alpha: {alpha_val}, Mean Squared Error: {mse}")
```

위의 예제는 여러 가지 alpha 값에 대해 리지 회귀 모델을 학습하고 평가하는 코드입니다. alpha 값을 바꿔가며 마찬가지로 모델을 훈련하고 평가하는 과정을 반복합니다. 이를 통해 최적의 alpha 값을 찾아 모델의 성능을 향상시킬 수 있습니다.

## 결론
리지 회귀는 scikit-learn 라이브러리를 활용하여 간편하게 구현할 수 있는 회귀 알고리즘입니다. 알파 값을 조정하여 모델의 성능을 최적화할 수 있으며, 과적합을 줄여 안정적인 예측 결과를 얻을 수 있습니다. 이러한 이유로 리지 회귀는 다양한 회귀 분석 문제에 유용하게 활용될 수 있습니다.