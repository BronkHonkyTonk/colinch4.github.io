---
layout: post
title: "[파이썬][scikit-learn] scikit-learn에서 특성 공학"
description: " "
date: 2023-09-05
tags: [scikit learn]
comments: true
share: true
---

Scikit-Learn은 Python에서 머신러닝을 위한 강력한 라이브러리입니다. 이 라이브러리를 사용하여 데이터를 분석하고 예측 모델을 개발할 수 있습니다. 특성 공학은 데이터의 특성을 변형, 조합 또는 선택하여 원래 데이터에서 새로운 특성을 생성하는 프로세스입니다. 특성 공학을 통해 모델의 성능을 향상시킬 수 있습니다.

## 왜 특성 공학이 필요한가요?

일반적으로 데이터는 원시 형태로 제공되지 않습니다. 이러한 데이터를 분석하고 모델에 적용하려면 적절하게 가공해야 합니다. 특성 공학은 데이터를 더 유용하고 의미 있는 형태로 변환하는 과정입니다. 예를 들어, 텍스트 데이터를 벡터로 변환하거나, 범주형 데이터를 이진 인코딩 또는 원-핫 인코딩으로 변환할 수 있습니다. 이러한 변환을 통해 모델이 더 나은 예측을 수행할 수 있습니다.

## Scikit-Learn에서 특성 공학을 수행하는 방법

Scikit-Learn에서 특성 공학을 수행하는 방법은 다양합니다. 주요한 메서드들과 사용 예제를 살펴보겠습니다.

### Feature scaling (특성 스케일링)

특성들이 다른 범위를 갖는 경우, 이를 동일한 범위로 스케일링하는 것이 중요합니다. 이를 통해 모델이 특성들을 공정하게 취급할 수 있습니다. Scikit-Learn에서는 `StandardScaler` 클래스를 사용하여 표준화를 수행할 수 있습니다.

```python
from sklearn.preprocessing import StandardScaler

# 데이터 준비
X = [[1, 2], [3, 4], [5, 6]]

# 특성 스케일링
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### Feature extraction (특성 추출)

데이터에서 의미 있는 특성을 추출할 수도 있습니다. Scikit-Learn에서는 다양한 특성 추출 방법을 제공합니다. 가장 일반적인 방법 중 하나는 `PCA` (주성분 분석)입니다. 이를 통해 데이터의 분산을 최대화하는 새로운 특성을 추출할 수 있습니다.

```python
from sklearn.decomposition import PCA

# 데이터 준비
X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]

# 특성 추출
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
```

### Feature selection (특성 선택)

데이터에서 중요한 특성들을 선택하여 모델의 복잡도를 줄일 수 있습니다. Scikit-Learn에서는 다양한 특성 선택 방법을 제공합니다. 가장 일반적인 방법 중 하나는 `SelectKBest`를 사용하여 가장 중요한 `k`개의 특성을 선택하는 것입니다.

```python
from sklearn.feature_selection import SelectKBest, f_regression

# 데이터 준비
X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
y = [10, 20, 30]

# 특성 선택
selector = SelectKBest(score_func=f_regression, k=2)
X_selected = selector.fit_transform(X, y)
```

## 결론

Scikit-Learn은 특성 공학을 위한 다양한 기능을 제공합니다. 특성 스케일링, 추출 및 선택을 통해 데이터를 고도로 가공하고 예측 모델의 성능을 향상시킬 수 있습니다. 이러한 과정을 통해 데이터의 의미를 더 잘 이해하고 유용한 정보를 추출할 수 있습니다.