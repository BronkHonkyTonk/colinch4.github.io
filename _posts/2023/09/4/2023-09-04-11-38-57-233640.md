---
layout: post
title: "[파이썬] 멀티스레딩과 병렬 처리의 성능 최적화 전략"
description: " "
date: 2023-09-04
tags: [python]
comments: true
share: true
---

## 소개

컴퓨터 시스템의 성능을 향상시키기 위해서 병렬 처리와 멀티스레딩은 중요한 개념입니다. 이러한 기술들을 사용하여 작업을 분산시키고 동시에 처리함으로써 실행 시간을 단축시킬 수 있습니다. 특히 Python에서는 GIL(Global Interpreter Lock)으로 인해 멀티스레딩이 제한적이지만, 병렬 처리를 통해 성능을 최적화시킬 수 있습니다.

이번 포스트에서는 Python에서 멀티스레딩과 병렬 처리의 성능을 최적화하기 위한 몇 가지 전략을 소개하도록 하겠습니다.

## 1. GIL 우회하기

Python에서 멀티스레딩을 사용할 때 가장 큰 제약인 GIL을 우회하는 방법 중 하나는 `multiprocessing` 모듈을 사용하는 것입니다. `multiprocessing`는 각 스레드에 별도의 인터프리터를 할당하여 GIL 제한을 우회할 수 있습니다.

```python
from multiprocessing import Pool

def parallel_func(x):
   # 병렬로 처리할 로직 작성
   return result

pool = Pool()
result = pool.map(parallel_func, data)
```

위의 예제에서 `Pool` 객체를 생성하여 `map` 함수를 사용하여 병렬 처리를 수행합니다. 각 작업은 별도의 프로세스에서 실행되므로 GIL의 영향을 받지 않습니다.

## 2. 작업 분할하기

크고 복잡한 작업을 여러 개의 작은 작업으로 분할하여 동시에 처리하는 것은 성능을 최적화하는 좋은 전략입니다. 작업을 분할하고 개별적으로 처리할 수 있게 하려면 알맞은 자료구조를 사용하는 것이 중요합니다. 예를 들어 리스트나 큐를 사용하여 작업을 분배하고 각 스레드 또는 프로세스에서 작업을 처리하는 것이 이에 해당합니다.

```python
import threading

def worker(queue):
    while True:
        job = queue.get()
        if job is None:
            break
        # 작업 처리 로직 작성
        print(f"Processing job: {job}")

def parallel_processing(data, num_threads):
    queue = Queue()
    threads = []

    for _ in range(num_threads):
        thread = threading.Thread(target=worker, args=(queue,))
        thread.start()
        threads.append(thread)
    
    for job in data:
        queue.put(job)
    
    # 작업 처리가 완료될 때까지 대기
    queue.join()

    # 스레드 종료
    for _ in range(num_threads):
        queue.put(None)

    for thread in threads:
        thread.join()

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
num_threads = 4
parallel_processing(data, num_threads)
```

위의 예제에서는 `Queue` 자료구조를 사용하여 작업을 분배하고, 여러 개의 스레드가 동시에 작업을 처리합니다.

## 3. 비동기 프로그래밍

비동기 프로그래밍은 멀티스레딩과 병렬 처리를 사용하여 성능을 향상시키는 또 다른 방법입니다. Python에서는 `asyncio`와 `aiohttp`와 같은 라이브러리를 사용하여 비동기 처리를 구현할 수 있습니다. 이를 통해 I/O 바운드 작업에서 높은 성능을 얻을 수 있습니다.

```python
import asyncio
import aiohttp

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    async with aiohttp.ClientSession() as session:
        tasks = []
        for url in urls:
            task = asyncio.ensure_future(fetch(session, url))
            tasks.append(task)
        responses = await asyncio.gather(*tasks)
        # 응답 데이터를 처리하는 로직 작성

urls = [...]
loop = asyncio.get_event_loop()
loop.run_until_complete(main())
```

위의 예제는 `aiohttp`를 사용하여 비동기적으로 여러 개의 URL에서 데이터를 가져오는 코드입니다. `asyncio.gather` 함수를 사용하여 여러 개의 작업을 동시에 실행하고, 그 결과를 한꺼번에 수집할 수 있습니다.

## 결론

Python에서 멀티스레딩과 병렬 처리를 사용하여 성능을 최적화하는 방법을 살펴보았습니다. GIL을 우회하는 방법, 작업 분할 및 비동기 프로그래밍을 활용하는 것은 대용량의 작업을 빠르게 처리하는 데 도움이 됩니다. 적합한 전략을 선택하여 본인의 프로젝트에 적용해보세요.