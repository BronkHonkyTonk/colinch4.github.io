---
layout: post
title: "[파이썬] 워드 임베딩과 단어 표현 학습"
description: " "
date: 2023-09-04
tags: [python]
comments: true
share: true
---

워드 임베딩(word embedding)은 자연어 처리(Natural Language Processing, NLP) 분야에서 단어를 벡터로 표현하는 기술입니다. 이러한 임베딩은 단어의 의미와 관련된 특성을 포착하여 컴퓨터가 텍스트를 이해하고 처리할 수 있게 해줍니다. 이번 포스트에서는 파이썬을 사용하여 워드 임베딩과 단어 표현 학습의 기본 개념과 예제를 살펴보겠습니다.

## 1. 워드 임베딩의 개념

워드 임베딩은 단어를 벡터로 표현하는 기술로, 단어들 간의 의미적 유사도를 계산하거나, 문장 내 단어들의 특성을 추출하는 등 다양한 자연어 처리 태스크에 활용됩니다. 워드 임베딩은 주로 단어의 의미를 벡터 공간상의 좌표로 표현하는 방식을 말합니다.

## 2. 워드 임베딩 방법

워드 임베딩은 다양한 방법으로 구현할 수 있지만, 가장 대표적인 방법 중 하나는 **Word2Vec**입니다. Word2Vec은 대규모 텍스트 코퍼스를 활용하여 단어의 의미를 학습하는 방법으로, 단어의 분산 표현(distributed representation)을 학습합니다. Word2Vec은 **Continuous Bag of Words (CBOW)**와 **Skip-gram** 두 가지 모델로 구성되어 있습니다.

```python
import gensim

# 텍스트 데이터로부터 Word2Vec 모델 학습
sentences = [['I', 'love', 'to', 'code'], ['Python', 'is', 'awesome']]
model = gensim.models.Word2Vec(sentences, min_count=1)

# 특정 단어에 대한 벡터 확인
vector = model['code']
print(vector)
```

## 3. 단어 표현 학습

워드 임베딩 외에도 다양한 방법으로 단어 표현을 학습할 수 있습니다. 가장 기본적인 방법은 **One-Hot Encoding**입니다. 이 방법은 단어를 고유한 인덱스에 매핑하고, 해당 인덱스의 위치만 1로 표시하고 나머지는 0으로 표시하는 방식입니다.

```python
from sklearn.preprocessing import OneHotEncoder

# 단어 집합 생성
word2index = {'I': 0, 'love': 1, 'to': 2, 'code': 3, 'Python': 4, 'is': 5, 'awesome': 6}

# One-Hot Encoding
encoder = OneHotEncoder(sparse=False)
encoded = encoder.fit_transform([[word2index['I']]])
print(encoded)
```

## 결론

워드 임베딩과 단어 표현 학습은 자연어 처리의 기반 기술로서 매우 중요합니다. 이번 포스트에서는 워드 임베딩과 단어 표현 학습의 개념과 예제를 파이썬을 통해 살펴보았습니다. 이를 통해 워드 임베딩과 단어 표현 학습에 대한 이해를 높일 수 있었습니다. 추가적으로 관련된 데이터와 모델을 사용하여 다양한 NLP 태스크를 수행할 수 있습니다.