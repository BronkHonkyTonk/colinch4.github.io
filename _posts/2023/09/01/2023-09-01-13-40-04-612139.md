---
layout: post
title: "[파이썬] 웹 스크래핑과 환경 정보 추출"
description: " "
date: 2023-09-01
tags: [python]
comments: true
share: true
---

**웹 스크래핑**은 웹사이트로부터 데이터를 수집하는 과정을 말합니다. 웹 스크래핑을 통해 웹사이트의 정보를 추출하고 이를 활용할 수 있습니다. 이번 블로그에서는 Python을 이용하여 웹 스크래핑을 하고 환경 정보를 추출하는 방법에 대해 알아보겠습니다.

## 환경 정보 추출

웹 스크래핑을 통해 환경 정보를 추출하기 위해서는 우선 웹페이지의 HTML 구조를 이해해야 합니다. 웹페이지는 HTML 태그로 구성되어 있으며, HTML 태그를 이용하여 원하는 정보를 선택할 수 있습니다.

```python
import requests
from bs4 import BeautifulSoup

# 웹페이지 요청
url = "https://www.example.com"
response = requests.get(url)

# BeautifulSoup 객체 생성
soup = BeautifulSoup(response.text, "html.parser")

# 환경 정보 추출
temperature = soup.find("span", class_="temperature").text
humidity = soup.find("div", id="humidity").text

print(f"Temperature: {temperature}")
print(f"Humidity: {humidity}")
```

위의 코드는 requests 모듈을 사용하여 웹페이지에 요청을 보내고, 응답 받은 HTML을 BeautifulSoup 모듈로 파싱하는 과정입니다. BeautifulSoup 객체를 생성하고 find 메서드를 사용하여 웹페이지에서 원하는 환경 정보를 추출합니다.

## 데이터 저장

추출한 환경 정보를 저장하기 위해 다양한 방법을 사용할 수 있습니다. 가장 간단한 방법은 추출한 데이터를 변수에 저장하는 것입니다. 또는 추출한 데이터를 데이터베이스에 저장하거나 CSV 파일로 저장하는 방법도 있습니다.

```python
import csv

# 추출한 환경 정보
data = {
    "Temperature": temperature,
    "Humidity": humidity
}

# CSV 파일로 저장
with open("env_data.csv", "w", encoding="utf-8", newline="") as csvfile:
    fieldnames = ["Temperature", "Humidity"]
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerow(data)
```

위의 코드는 추출한 환경 정보를 딕셔너리 형태로 저장하고, CSV 파일로 저장하는 과정입니다. csv 모듈을 사용하여 CSV 파일을 생성하고, DictWriter를 이용하여 딕셔너리를 CSV 파일에 작성합니다.

## 웹 스크래핑의 윤리적 측면

웹 스크래핑은 강력한 도구이지만, 사용에 따라 윤리적인 문제가 발생할 수 있습니다. 항상 웹사이트의 이용 약관을 확인하고, 스크래핑을 허용하는지 확인하는 것이 중요합니다. 또한 데이터의 양과 빈도에도 신경을 써서 서버 부하를 줄이는 등 적절한 사용 방법을 고려해야 합니다.

## 결론

Python을 이용하여 웹 스크래핑을 통해 환경 정보를 추출하는 방법에 대해 알아보았습니다. 웹 스크래핑은 다양한 데이터를 수집하고 활용하는 데 유용한 도구입니다. 단, 항상 웹사이트의 이용 약관을 준수하고 적절한 사용 방법을 고려해야합니다.