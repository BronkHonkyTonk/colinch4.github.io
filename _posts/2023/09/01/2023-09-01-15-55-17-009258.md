---
layout: post
title: "[파이썬] 딥러닝 모델의 과적합과 정규화 기법"
description: " "
date: 2023-09-01
tags: [python]
comments: true
share: true
---

딥러닝은 강력한 모델로 이미지 분류, 자연어 처리 및 음성 인식과 같은 다양한 작업에서 놀라운 성능을 보여준다. 그러나 딥러닝 모델은 데이터에 과도하게 적합되어 과적합(overfitting) 문제가 발생할 수 있다. 이러한 문제는 모델이 훈련 데이터에 너무 특화되어 새로운 데이터에 일반화되지 못하는 경우를 의미한다.

과적합은 딥러닝 모델의 성능을 저하시킬 수 있으며, 실제 응용에서는 원하는 결과를 얻지 못할 수 있다. 이를 해결하기 위해 정규화(regularization) 기법이 사용된다. 정규화는 모델의 복잡도를 제어하고 과적합을 완화시키는 방법이다.

## L1 정규화

L1 정규화는 모델의 가중치를 제한하는 기법 중 하나이다. 이 방법은 각 가중치에 대해 가중치의 절대값에 페널티를 부여하는데, 작은 가중치 값을 갖는 피처를 만들어 모델의 특성을 제어하게 된다. L1 정규화는 모델 내에서 불필요한 피처를 제거하고 희소성을 부여하는 효과가 있다.

```python
from keras.models import Sequential
from keras.layers import Dense
from keras.regularizers import l1

model = Sequential()
model.add(Dense(64, activation='relu', kernel_regularizer=l1(0.01), input_shape=(10,)))
model.add(Dense(64, activation='relu', kernel_regularizer=l1(0.01)))
model.add(Dense(1, activation='sigmoid'))

```

위의 예제 코드에서는 `keras.regularizers.l1` 함수를 사용하여 L1 정규화를 적용하고 있다. `kernel_regularizer` 매개변수를 사용하여 층의 가중치에 정규화를 적용한다.

## L2 정규화

L2 정규화는 모델의 가중치를 제한하는 또 다른 기법으로, 가중치의 제곱에 페널티를 부여하는 방식이다. 이 방법은 L1 정규화와 유사하지만, 모델의 피처들을 평균화하여 제어하는 효과를 보여준다.

```python
from keras.models import Sequential
from keras.layers import Dense
from keras.regularizers import l2

model = Sequential()
model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(10,)))
model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dense(1, activation='sigmoid'))
```

위의 코드에서는 `keras.regularizers.l2` 함수를 사용하여 L2 정규화를 적용하고 있다. `kernel_regularizer` 매개변수를 사용하여 각 층의 가중치에 정규화를 적용한다.

## 드롭아웃

드롭아웃은 딥러닝 모델의 과적합을 방지하기 위한 효과적인 정규화 기법이다. 드롭아웃은 특정 뉴런의 출력을 임의로 0으로 설정하여 그 뉴런에 대한 정보가 전파되지 못하도록 하는 것이다. 이는 모델이 특정 뉴런에 지나치게 의존하지 않게 하여 과적합을 완화시킨다.

```python
from keras.models import Sequential
from keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(10,)))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

```

위의 예제 코드에서는 `keras.layers.Dropout` 함수를 사용하여 드롭아웃을 적용하고 있다. `Dropout` 층은 이전 층의 출력에 일정 비율 `0.5`만큼의 뉴런을 무작위로 비활성화한다.

과적합 문제는 딥러닝 모델의 성능에 부정적인 영향을 끼칠 수 있다. 이를 해결하기 위해 L1 정규화, L2 정규화 및 드롭아웃과 같은 다양한 정규화 기법을 사용할 수 있다. 그러나 각 기법의 효율성은 문제에 따라 다를 수 있으므로 실험을 통해 최적의 정규화 기법을 찾아야 한다.