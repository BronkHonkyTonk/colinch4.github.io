---
layout: post
title: "[파이썬] 데이터 과학과 머신러닝 평가 지표"
description: " "
date: 2023-09-01
tags: [python]
comments: true
share: true
---

데이터 과학과 머신러닝은 현대 기술의 핵심 분야이며, 이들 분야에서 모델의 성능을 평가하는 것은 매우 중요합니다. 평가 지표는 모델의 성능을 측정하고 비교하기 위해 사용되며, 모델의 정확성, 정밀도, 재현율 등을 평가하는 데 사용됩니다.

이 블로그 포스트에서는 몇 가지 일반적인 데이터 과학과 머신러닝 평가 지표에 대해 알아보고, 이를 Python으로 구현하는 방법을 살펴보겠습니다.

## 1. 정확도 (Accuracy)

정확도는 모델이 올바르게 예측한 샘플의 비율입니다. 일반적으로 이진 분류 문제에서 사용됩니다. 정확도는 다음과 같이 계산됩니다:

```
accuracy = (TP + TN) / (TP + TN + FP + FN)
```

예를 들어, 100개의 샘플이 있는 데이터셋에서 80개를 올바르게 예측했다면, 정확도는 0.8입니다.

```python
from sklearn.metrics import accuracy_score

y_true = [0, 1, 1, 0, 1]
y_pred = [0, 0, 1, 0, 1]

accuracy = accuracy_score(y_true, y_pred)
print(f"Accuracy: {accuracy}")
```

## 2. 정밀도 (Precision)

정밀도는 양성으로 예측한 샘플 중 실제로 양성인 샘플의 비율입니다. 이는 거짓 양성(FP)의 수를 줄이는 것이 목표일 때 사용됩니다. 정밀도는 다음과 같이 계산됩니다:

```
precision = TP / (TP + FP)
```

```python
from sklearn.metrics import precision_score

y_true = [0, 1, 1, 0, 1]
y_pred = [0, 0, 1, 0, 1]

precision = precision_score(y_true, y_pred)
print(f"Precision: {precision}")
```

## 3. 재현율 (Recall)

재현율은 실제 양성인 샘플 중 모델이 양성으로 예측한 비율입니다. 이는 거짓 음성(FN)의 수를 줄이는 것이 목표일 때 사용됩니다. 재현율은 다음과 같이 계산됩니다:

```
recall = TP / (TP + FN)
```

```python
from sklearn.metrics import recall_score

y_true = [0, 1, 1, 0, 1]
y_pred = [0, 0, 1, 0, 1]

recall = recall_score(y_true, y_pred)
print(f"Recall: {recall}")
```

## 4. F1 점수 (F1 Score)

F1 점수는 정밀도와 재현율의 조화 평균으로 계산됩니다. 이는 정밀도와 재현율 모두를 고려하여 모델의 성능을 평가하는 데 사용됩니다.

```
F1 = 2 * (precision * recall) / (precision + recall)
```

```python
y_true = [0, 1, 1, 0, 1]
y_pred = [0, 0, 1, 0, 1]

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)

f1_score = 2 * (precision * recall) / (precision + recall)
print(f"F1 Score: {f1_score}")
```

## 결론

데이터 과학과 머신러닝에서 평가 지표는 모델의 성능을 측정하고 비교하는 데 큰 역할을 합니다. 이 포스트에서는 정확도, 정밀도, 재현율, F1 점수와 같은 일반적인 평가 지표에 대해 알아보고, Python을 사용하여 이러한 지표를 계산하는 방법을 살펴보았습니다. 이를 통해 모델의 성능을 정량화하고 비교할 수 있습니다.