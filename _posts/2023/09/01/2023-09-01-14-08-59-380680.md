---
layout: post
title: "[파이썬] Flask의 웹 크롤링과 스크래핑"
description: " "
date: 2023-09-01
tags: [python]
comments: true
share: true
---

Flask는 파이썬 기반의 경량 웹 프레임워크로, 웹 개발을 쉽고 빠르게 할 수 있도록 도와줍니다. 이번 포스트에서는 Flask를 사용하여 웹 크롤링과 스크래핑을 어떻게 수행할 수 있는지 살펴보겠습니다.

### 웹 크롤링과 스크래핑

웹 크롤링은 웹 사이트를 자동으로 탐색하고 필요한 데이터를 수집하는 것을 의미합니다. 스크래핑은 이러한 크롤링 작업의 일부로, 크롤링한 웹 페이지에서 원하는 정보를 추출하는 과정을 의미합니다. 

이러한 작업은 대규모 데이터 수집, 특정 웹 사이트의 변경된 정보 추적, 가격 비교, 리뷰 수집 등 다양한 목적으로 사용될 수 있습니다. Flask를 사용하면 웹 크롤링과 스크래핑을 쉽게 구현할 수 있습니다.

### Flask 설치

먼저, Flask를 설치해야 합니다. 아래의 명령어로 Flask를 설치할 수 있습니다.

```python
pip install flask
```

### 웹 크롤링 예제

다음은 Flask를 사용하여 웹 크롤링을 수행하는 예제 코드입니다. 이 예제는 requests와 BeautifulSoup 라이브러리를 사용하여 웹 페이지를 크롤링하고, 크롤링한 데이터를 웹 브라우저에 표시합니다.

```python
from flask import Flask
import requests
from bs4 import BeautifulSoup

app = Flask(__name__)

@app.route('/')
def scrape_website():
    url = "https://example.com"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    data = soup.find('h1').text
    
    return data

if __name__ == '__main__':
    app.run()
```

위의 코드에서는 먼저 Flask 애플리케이션을 생성하고, "/" 루트 경로에 URL을 지정하여 웹 페이지를 크롤링합니다. 크롤링한 데이터 중에서 `<h1>` 태그에 해당하는 데이터를 추출하여 반환합니다.

### 스크래핑 예제

다음은 Flask를 사용하여 웹 스크래핑을 수행하는 예제 코드입니다. 이 예제는 requests와 Beautiful Soup 라이브러리를 사용하여 웹 페이지를 스크래핑하고, 필요한 정보를 추출하여 JSON 형태로 반환합니다.

```python
from flask import Flask, jsonify
import requests
from bs4 import BeautifulSoup

app = Flask(__name__)

@app.route('/')
def scrape_website():
    url = "https://example.com"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    data = {
        'title': soup.find('h1').text,
        'description': soup.find('p').text,
        'image_url': soup.find('img')['src']
    }
    
    return jsonify(data)

if __name__ == '__main__':
    app.run()
```

위의 코드에서는 "/" 루트 경로에 URL을 지정하여 웹 페이지를 스크래핑합니다. 추출한 정보를 딕셔너리 형태로 저장하고, `jsonify` 함수를 사용하여 JSON 형식으로 반환합니다.

### 마무리

이번 포스트에서는 Flask를 사용하여 웹 크롤링과 스크래핑을 쉽게 구현하는 방법을 알아보았습니다. Flask의 간결한 코드와 강력한 기능을 활용하여 다양한 웹 크롤링 및 스크래핑 작업을 수행할 수 있습니다.