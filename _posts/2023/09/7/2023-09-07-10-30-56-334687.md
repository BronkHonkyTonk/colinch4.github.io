---
layout: post
title: "[파이썬] xgboost 그리드 탐색과 랜덤 탐색 활용"
description: " "
date: 2023-09-07
tags: [python,xgboost]
comments: true
share: true
---

XGBoost는 현재 가장 인기 있는 머신러닝 알고리즘 중 하나이며, 다양한 문제에 대해 뛰어난 성능을 보입니다. 그러나 XGBoost의 성능을 극대화하기 위해서는 모델의 하이퍼파라미터를 최적화해야 합니다. 이를 위해 그리드 탐색(Grid Search)과 랜덤 탐색(Random Search)을 사용할 수 있습니다.

## 그리드 탐색(Grid Search)

그리드 탐색은 가능한 모든 하이퍼파라미터 조합에 대해 모델을 훈련하고 검증하는 방법입니다. 모든 조합을 순회하기 때문에 시간이 오래 걸리지만, 최적의 조합을 찾을 수 있습니다.

```python
import xgboost as xgb
from sklearn.model_selection import GridSearchCV

# XGBoost 모델 생성
model = xgb.XGBClassifier()

# 그리드 탐색할 하이퍼파라미터 지정
param_grid = {
    'learning_rate': [0.1, 0.2, 0.3],
    'max_depth': [3, 5, 7],
    'n_estimators': [100, 200, 300]
}

# GridSearchCV를 사용하여 그리드 탐색 수행
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# 최적의 하이퍼파라미터와 모델의 성능 출력
print("Best Hyperparameters: ", grid_search.best_params_)
print("Best Score: ", grid_search.best_score_)
```

위 코드에서는 XGBoost 분류기를 생성하고, `learning_rate`, `max_depth`, `n_estimators` 등의 하이퍼파라미터를 그리드 탐색할 범위를 지정합니다. 그리고 GridSearchCV를 사용하여 모델을 훈련하고 최적의 하이퍼파라미터와 성능을 출력합니다.

## 랜덤 탐색(Random Search)

랜덤 탐색은 하이퍼파라미터 조합을 무작위로 선택하여 모델을 훈련하고 검증하는 방법입니다. 그리드 탐색에 비해 빠르게 가능한 조합을 탐색할 수 있지만, 최적의 조합을 찾을 확률은 상대적으로 낮습니다.

```python
import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

# XGBoost 모델 생성
model = xgb.XGBClassifier()

# 랜덤 탐색할 하이퍼파라미터의 분포 지정
param_dist = {
    'learning_rate': [0.1, 0.2, 0.3],
    'max_depth': randint(3, 10),
    'n_estimators': [100, 200, 300]
}

# RandomizedSearchCV를 사용하여 랜덤 탐색 수행
random_search = RandomizedSearchCV(model, param_dist, cv=5, scoring='accuracy')
random_search.fit(X_train, y_train)

# 최적의 하이퍼파라미터와 모델의 성능 출력
print("Best Hyperparameters: ", random_search.best_params_)
print("Best Score: ", random_search.best_score_)
```

위 코드에서도 XGBoost 분류기를 생성하고, `learning_rate`, `max_depth`, `n_estimators` 등의 하이퍼파라미터의 분포를 지정합니다. 그리고 RandomizedSearchCV를 사용하여 모델을 훈련하고 최적의 하이퍼파라미터와 성능을 출력합니다.

## 결론

XGBoost를 사용할 때는 그리드 탐색과 랜덤 탐색을 활용하여 최적의 하이퍼파라미터 조합을 찾을 수 있습니다. 그리드 탐색은 모든 조합을 탐색하기 때문에 최적의 조합을 찾을 수 있지만, 시간이 오래 걸립니다. 반면에 랜덤 탐색은 빠르게 조합을 탐색할 수 있지만, 최적의 조합을 찾을 확률은 낮습니다. 따라서 시간과 성능 사이의 트레이드오프를 고려하여 적절한 탐색 방법을 선택해야 합니다.