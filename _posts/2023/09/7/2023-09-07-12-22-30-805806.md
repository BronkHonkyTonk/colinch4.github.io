---
layout: post
title: "[파이썬] PyTorch 미분 가능한 프로그래밍"
description: " "
date: 2023-09-07
tags: [PyTorch]
comments: true
share: true
---

PyTorch는 딥러닝을 위한 오픈 소스 머신 러닝 프레임워크이며, 미분 가능한 프로그래밍을 통해 모델의 학습과 예측 과정을 효율적으로 수행할 수 있습니다. 미분 가능한 프로그래밍의 핵심은 모델의 손실 함수를 계산할 때, 그래프 형태로 미분 가능한 연산을 사용하는 것입니다. 이를 통해 PyTorch는 자동 미분(auto differentiation)을 지원하여 모델의 가중치 갱신과 역전파(backpropagation)를 자동으로 수행할 수 있습니다.

## Autograd 모듈

PyTorch의 Autograd 모듈은 자동 미분을 수행하는 핵심 모듈입니다. Autograd 모듈은 사용자가 정의한 연산에 대한 미분값을 계산하고, 계산 과정에서 생성된 그래프를 추적하여 역전파를 자동으로 수행합니다. 이를 통해 우리는 미분 값을 직접 계산하거나 학습이 필요한 가중치를 수정하기 위해 직접 역전파를 구현할 필요가 없습니다.

```python
import torch

# 텐서 생성 및 requires_grad=True 옵션 설정
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
y = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)

# 연산 수행
z = x + y
loss = z.sum()

# 역전파 수행
loss.backward()

# 역전파 결과 출력
print(x.grad)  # tensor([1., 1., 1.])
print(y.grad)  # tensor([1., 1., 1.])
```

위의 예제에서 `requires_grad=True` 옵션을 통해 텐서 x와 y를 정의하면 해당 텐서의 연산은 추적 대상이 됩니다. 그리고 `loss.backward()`를 호출하여 손실 함수에 대한 역전파를 수행하면, x와 y의 grad 속성에 미분 값이 자동으로 저장됩니다.

## torch.nn.Module을 활용한 모델 구축

PyTorch에서는 `torch.nn.Module`을 사용하여 모델을 구축할 수 있습니다. `torch.nn.Module`은 레이어, 활성화 함수, 손실 함수 등 다양한 딥러닝 구성 요소를 포함하고 있으며, 이를 활용하여 복잡한 모델을 구축할 수 있습니다.

```python
import torch
import torch.nn as nn

# 모델 클래스 선언
class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.linear = nn.Linear(2, 1)
    
    def forward(self, x):
        out = self.linear(x)
        return out

# 모델 인스턴스 생성
model = MyModel()

# 입력 데이터 생성
x = torch.tensor([[1.0, 2.0]])

# 예측 수행
output = model(x)

print(output)  # tensor([[0.2376]], grad_fn=<AddmmBackward>)
```

위의 예제에서는 `torch.nn.Linear` 레이어를 포함하는 `MyModel` 클래스를 정의합니다. `forward` 메서드 내에서 입력 데이터를 레이어에 전달하여 예측 값을 계산합니다. 이렇게 정의한 모델을 인스턴스화하고 입력 데이터를 전달하면 예측 결과를 얻을 수 있습니다.

## 커스텀 손실 함수 정의

PyTorch에서는 사용자가 직접 손실 함수를 정의할 수도 있습니다. 이를 통해 복잡한 문제에 대한 특화된 손실 함수를 개발하거나, 기존 손실 함수의 변형을 만들 수 있습니다.

```python
import torch
import torch.nn as nn

# 커스텀 손실 함수 정의
class CustomLoss(nn.Module):
    def __init__(self):
        super(CustomLoss, self).__init__()

    def forward(self, y_pred, y_true):
        loss = torch.abs(y_pred - y_true).sum()
        return loss

# 모델 및 손실 함수 인스턴스 생성
model = MyModel()
criterion = CustomLoss()

# 입력 데이터 및 타겟 생성
x = torch.tensor([[1.0, 2.0]])
y_true = torch.tensor([[2.5]])

# 예측 수행
output = model(x)

# 손실 계산
loss = criterion(output, y_true)

print(loss)  # tensor(0.7624, grad_fn=<SumBackward0>)
```

위의 예제에서는 `nn.Module`을 상속받는 `CustomLoss` 클래스를 정의하여 커스텀 손실 함수를 구현합니다. `forward` 메서드 내에서 예측 값과 실제 값 사이의 절댓값을 계산하여 총 손실을 반환합니다. 이렇게 정의한 커스텀 손실 함수를 사용하여 모델의 예측 결과에 대한 손실을 계산할 수 있습니다.

PyTorch의 미분 가능한 프로그래밍을 활용하면 모델의 학습과 예측을 보다 효율적으로 수행할 수 있습니다. AutoGrad 모듈을 통해 자동 미분을 수행하고, `torch.nn.Module`을 사용하여 모델을 구축하며, 커스텀 손실 함수를 정의할 수 있습니다. 이를 통해 높은 수준의 추상화와 유연성을 제공하여 딥러닝 모델 개발을 간단하고 효과적으로 할 수 있게 됩니다.