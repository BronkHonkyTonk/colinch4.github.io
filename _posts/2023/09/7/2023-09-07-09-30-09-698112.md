---
layout: post
title: "[파이썬] xgboost의 트리 가지치기"
description: " "
date: 2023-09-07
tags: [python,xgboost]
comments: true
share: true
---

xgboost는 강력한 기계 학습 라이브러리로서, 대용량 데이터셋에서 뛰어난 성능을 보여줍니다. 그 중에서도 트리 가지치기는 모델의 일반화 성능을 향상시키는 데 있어 중요한 역할을 합니다. 이번 블로그 포스트에서는 xgboost에서 트리 가지치기를 수행하는 방법을 알아보겠습니다.

## xgboost의 트리 가지치기 개요

트리 가지치기는 과적합을 방지하고 모델의 일반화 성능을 향상시키기 위해 사용됩니다. xgboost에서는 다음과 같은 트리 가지치기 방법을 제공합니다:

1. 규칙 기반 가지치기: 특정 규칙에 따라 노드를 분할하는 방식입니다.
2. 가중치 기반 가지치기: 노드 분할 시 가중치를 적용하여 특정 피처를 우선적으로 선택하도록 합니다.
3. 감마 기반 가지치기: 트리를 가지치기하기 위해 필요한 최소 손실 감마 값을 설정합니다.

## 트리 가지치기의 중요 매개변수

xgboost에서 트리 가지치기를 조절하기 위해 중요한 매개변수들이 있습니다:

- `max_depth`: 트리의 최대 깊이를 제한합니다. 기본값은 6입니다.
- `min_child_weight`: 리프 노드가 형성되기 위한 최소한의 가중치 합을 설정합니다. 기본값은 1입니다.
- `gamma`: 트리를 가지치기하기 위해 필요한 최소 손실 감마 값을 설정합니다. 기본값은 0입니다.

이러한 매개변수들을 조절하여 트리 가지치기를 효과적으로 수행할 수 있습니다.

## xgboost에서 트리 가지치기 적용하기

아래는 Python에서 xgboost의 트리 가지치기를 적용하는 예제 코드입니다:

```python
import xgboost as xgb

# 데이터셋 로드
dataset = xgb.DMatrix('data.csv')

# 모델 학습하기
params = {
    'max_depth': 5,
    'min_child_weight': 1,
    'gamma': 0.1
}
model = xgb.train(params, dataset)

# 적용된 트리 가지치기 확인
print(model.get_score(importance_type='weight'))
```

위 코드에서는 `max_depth`를 5로 설정하여 트리의 최대 깊이를 제한하고, `min_child_weight`를 1로 설정하여 리프 노드가 형성되기 위한 최소 가중치 합을 조절하였습니다. 또한, `gamma`를 0.1로 설정하여 트리를 가지치기하기 위한 최소 손실 감마 값을 조절하였습니다. 최종적으로 `model.get_score()`를 통해 트리 가지치기가 적용된 피처들의 중요도를 확인할 수 있습니다.

## 결론

이번 포스트에서는 xgboost의 트리 가지치기에 대해 알아보았습니다. xgboost는 효과적인 트리 가지치기 기능을 제공하여 모델의 일반화 성능을 향상시킬 수 있습니다. 트리 가지치기를 조절하는 매개변수들을 적절히 사용하여 최적의 모델을 구축하는 데 도움이 되길 바랍니다.