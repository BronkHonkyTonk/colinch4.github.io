---
layout: post
title: "[파이썬] lightgbm 그래디언트 부스팅의 원리"
description: " "
date: 2023-09-07
tags: [python,lightgbm]
comments: true
share: true
---

## 소개
LightGBM은 Microsoft에서 개발한 그래디언트 부스팅 프레임워크입니다. 그래디언트 부스팅은 앙상블 학습의 한 종류로, 약한 학습기(weak learner)를 이용하여 강한 학습기(strong learner)를 구축하는 방법입니다. LightGBM은 대규모 데이터셋에서도 효율적으로 작동하며, 높은 예측 성능과 빠른 학습 속도를 제공합니다.

## 그래디언트 부스팅의 개요
그래디언트 부스팅은 여러 개의 결정 트리(decision tree)를 순차적으로 학습하는 방식입니다. 각 결정 트리는 이전 트리의 오차를 보완하는 방향으로 학습됩니다. 예측값과 실제값의 차이인 오차(residual)를 최소화하는 방향으로 학습되기 때문에, 결정 트리의 순차적인 추가로 예측 성능이 점진적으로 향상됩니다.

## LightGBM 알고리즘의 핵심 원리
LightGBM은 다양한 기능과 최적화 기법을 통해 그래디언트 부스팅의 학습 속도와 예측 성능을 향상시킵니다.

### 1. Leaf-wise 분할 방식
LightGBM은 다른 그래디언트 부스팅 프레임워크에서 사용하는 level-wise 분할 방식 대신, leaf-wise 분할 방식을 사용합니다. Leaf-wise 분할 방식은 현재 트리에서 예측 성능 향상에 가장 큰 영향을 미치는 데이터 포인트를 우선적으로 분할하는 방식입니다. 이를 통해 더 적은 수의 분할로 더 잘 특징을 학습할 수 있으며, 학습 속도를 향상시킬 수 있습니다.

### 2. Histogram 기반의 분할
LightGBM은 히스토그램 기반의 분할 방식을 사용하여 데이터의 분포를 이산화(discretization)합니다. 이렇게 함으로써 메모리 사용량을 줄이고, 학습 속도를 높이고, 카테고리형 특징의 학습 가능성을 개선할 수 있습니다.

### 3. 특징 별 최적 분할
LightGBM은 특징 별로 최적의 분할을 탐색하여 트리를 구축합니다. 분할 후의 오차 감소량이 가장 큰 분할을 선택함으로써 특징의 중요도와 예측 성능을 최적화합니다.

### 4. 정규화 기법
LightGBM은 leaf-wise 분할 방식을 사용할 때 오버피팅의 위험을 줄이기 위해 정규화 기법을 도입합니다. 정규화를 통해 각 트리의 예측값이 과도하게 커지는 것을 방지하고 일반화 성능을 향상시킵니다.

## 예제 코드
아래는 LightGBM을 사용하여 분류 문제를 해결하는 예제 코드입니다.

```python
import lightgbm as lgb
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# 데이터 로드
data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)

# LightGBM 모델 학습
lgb_train = lgb.Dataset(X_train, y_train)
lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)

params = {
    'boosting_type': 'gbdt',
    'objective': 'binary',
    'metric': 'binary_logloss',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9
}

model = lgb.train(params,
                  lgb_train,
                  num_boost_round=100,
                  valid_sets=[lgb_train, lgb_test],
                  early_stopping_rounds=10)

# 모델 평가
y_pred = model.predict(X_test)
y_pred_class = [round(pred) for pred in y_pred]

accuracy = sum(y_pred_class == y_test) / len(y_test)
print(f"Accuracy: {accuracy}")
```

위의 코드는 유방암 데이터셋을 로드하여 LightGBM 모델을 학습하고, 예측 결과를 평가하는 기본적인 과정을 보여줍니다. LightGBM은 파라미터 설정과 데이터 전처리에 따라 다양한 형태로 사용될 수 있으며, 해당 예제 코드를 시작으로 개인의 목적에 맞게 활용할 수 있습니다.

위의 예제 코드에서 사용된 파라미터는 실제로 최적의 성능을 제공하지는 않으며, 실제 문제에 맞게 조절해야 합니다.

## 결론
LightGBM은 그래디언트 부스팅의 핵심 원리를 효율적으로 구현한 프레임워크입니다. leaf-wise 분할 방식, histogram 기반의 분할, 특징 별 최적 분할, 정규화 기법 등을 통해 높은 예측 성능과 빠른 학습 속도를 제공합니다. 예제 코드를 통해 LightGBM을 간단히 사용할 수 있는 방법을 알아보았습니다.