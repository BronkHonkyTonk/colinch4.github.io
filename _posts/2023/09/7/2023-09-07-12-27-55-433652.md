---
layout: post
title: "[파이썬] lightgbm 모델 앙상블 및 스태킹 전략"
description: " "
date: 2023-09-07
tags: [python,lightgbm]
comments: true
share: true
---

앙상블(Ensemble) 및 스태킹(Stacking)은 기계 학습 분야에서 매우 유용한 전략입니다. 이러한 전략을 사용하면 여러 모델의 예측을 결합하여 더 강력하고 안정적인 예측을 할 수 있습니다. 이번 블로그 포스트에서는 LightGBM 모델의 앙상블 및 스태킹 전략을 소개하고, Python을 사용하여 구현하는 방법에 대해 알아보겠습니다.

## 앙상블(Ensemble) 전략

앙상블은 다양한 모델을 합치는 것을 의미합니다. LightGBM은 성능이 우수하고 학습이 빠른 모델이기 때문에 다양한 LightGBM 모델을 앙상블할 수 있습니다. 다음은 LightGBM 모델 앙상블을 구현하는 예제 코드입니다.

```python
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 데이터셋을 로드하고 훈련 데이터와 테스트 데이터로 분할
X, y = load_dataset()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM 모델 생성 및 훈련
model1 = lgb.LGBMClassifier(...)
model2 = lgb.LGBMClassifier(...)
model1.fit(X_train, y_train)
model2.fit(X_train, y_train)

# 테스트 데이터에 대한 예측 수행
pred1 = model1.predict(X_test)
pred2 = model2.predict(X_test)

# 예측 결과를 결합하여 최종 예측 생성
ensemble_pred = (pred1 + pred2) / 2

# 최종 예측의 정확도 평가
accuracy = accuracy_score(y_test, ensemble_pred)
```

위의 코드에서는 LightGBM 모델을 두 개 생성하고 각각 훈련시킨 후, 테스트 데이터에 대한 예측을 수행합니다. 예측 결과를 평균하여 최종 예측을 생성하고, 이를 평가하기 위해 정확도를 계산합니다. 앙상블을 통해 다양한 모델의 예측을 결합하므로 성능이 향상될 수 있습니다.

## 스태킹(Stacking) 전략

스태킹은 다양한 모델의 예측 결과를 기반으로 새로운 모델을 학습하는 전략입니다. LightGBM을 기반으로 하는 다른 모델을 사용하여 스태킹을 구현할 수 있습니다. 다음은 LightGBM 모델로 스태킹을 구현하는 예제 코드입니다.

```python
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

# 데이터셋을 로드하고 훈련 데이터와 테스트 데이터로 분할
X, y = load_dataset()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 첫 번째 LightGBM 모델 생성 및 훈련
model1 = lgb.LGBMClassifier(...)
model1.fit(X_train, y_train)
pred1 = model1.predict(X_test)

# 두 번째 LightGBM 모델 생성 및 훈련
model2 = lgb.LGBMClassifier(...)
model2.fit(X_train, y_train)
pred2 = model2.predict(X_test)

# 첫 번째 LightGBM 모델의 예측 결과를 새로운 특성으로 추가
X_train_stacked = np.hstack((pred1.reshape(-1,1), X_train))
X_test_stacked = np.hstack((pred1.reshape(-1,1), X_test))

# 스태킹에 사용할 모델(로지스틱 회귀) 생성 및 훈련
stacking_model = LogisticRegression(...)
stacking_model.fit(X_train_stacked, y_train)

# 스태킹 모델의 예측 수행
stacked_pred = stacking_model.predict(X_test_stacked)

# 스태킹 모델의 정확도 평가
accuracy = accuracy_score(y_test, stacked_pred)
```

위의 코드에서는 먼저 LightGBM 모델을 두 개 생성하고 각각 훈련시킨 후, 테스트 데이터에 대한 예측을 수행합니다. 그런 다음, 첫 번째 LightGBM 모델의 예측 결과를 새로운 특성으로 추가하여 훈련 데이터와 테스트 데이터를 업데이트합니다. 이후, 스태킹에 사용할 모델인 로지스틱 회귀 모델을 생성하고 훈련시키며, 이를 사용하여 새로운 테스트 데이터에 대한 예측을 수행합니다. 스태킹 모델의 정확도를 평가합니다.

## 결론

LightGBM 모델의 앙상블 및 스태킹 전략을 이용하면 모델의 성능을 개선하고 안정화할 수 있습니다. 앙상블을 통해 다양한 모델의 예측을 결합하거나, 스태킹을 통해 예측 결과를 기반으로 새로운 모델을 학습할 수 있습니다. 이러한 전략들은 Python의 LightGBM 라이브러리를 활용하여 간단히 구현할 수 있습니다.

이상으로, LightGBM 모델 앙상블 및 스태킹 전략에 대한 소개였습니다. 다양한 모델을 결합하여 예측 성능을 향상시키는 앙상블 및 스태킹 전략을 활용해보세요. 좀 더 정확하고 신뢰성 있는 예측을 할 수 있을 것입니다.