---
layout: post
title: "[파이썬] lightgbm의 학습 곡선 해석"
description: " "
date: 2023-09-07
tags: [python,lightgbm]
comments: true
share: true
---
**lightgbm**은 기계 학습 알고리즘인 그래디언트 부스팅 트리(Gradient Boosting Tree)의 효율적인 구현체입니다. 이 알고리즘은 대용량 데이터셋에서 빠른 학습과 예측 성능을 제공합니다. 하지만 모델의 학습 과정을 이해하고 해석하는 것은 중요한 과제입니다.

이번 포스트에서는 lightgbm의 학습 곡선을 해석하는 방법에 대해 알아보겠습니다. 학습 곡선은 모델의 학습 데이터에 대한 성능 변화를 나타내는 그래프로, 학습 과정에서 모델이 어떻게 개선되는지를 시각적으로 확인할 수 있습니다.

## 1. 학습 곡선 그리기
lightgbm에서는 `lgb.cv()` 함수를 통해 학습 곡선을 그릴 수 있습니다. 이 함수를 사용하기 위해서는 데이터셋과 모델의 설정을 미리 준비해야 합니다. 아래는 예제 코드입니다.

```python
import lightgbm as lgbm
import numpy as np
import matplotlib.pyplot as plt

# Load dataset
X, y = load_dataset()

# Prepare parameter configuration
params = {'objective': 'binary', 'metric': 'binary_logloss'}
train_data = lgbm.Dataset(X, label=y)

# Generate learning curves
cv_results = lgbm.cv(params, train_data, num_boost_round=100, nfold=5)

# Extract metrics
train_logloss = cv_results['binary_logloss-mean']
valid_logloss = cv_results['binary_logloss-stdv']

# Generate x-axis values (number of boosting rounds)
x_axis = np.arange(1, len(train_logloss) + 1)

# Plot learning curves
plt.plot(x_axis, train_logloss, label='Train')
plt.fill_between(x_axis, train_logloss - valid_logloss, train_logloss + valid_logloss, alpha=0.1)
plt.xlabel('Number of boosting rounds')
plt.ylabel('Log Loss')
plt.legend()
plt.show()
```

위 코드는 데이터셋을 로드하고, 학습 데이터와 모델 설정을 준비한 뒤, `lgb.cv()` 함수를 사용하여 학습 곡선을 생성합니다. 이후 `lgbm.cv()`의 결과로부터 학습 세트와 검증 세트의 로그 손실(log loss) 값을 추출하고, 이를 그래프로 표현합니다.

## 2. 해석 방법
학습 곡선을 통해 모델의 학습 과정을 해석할 수 있습니다. 아래는 학습 곡선을 해석하는 방법에 대한 몇 가지 예시입니다.

**a. Underfitting과 Overfitting 확인하기**: 학습 데이터의 로그 손실이 감소하는 동시에 검증 데이터의 로그 손실이 증가한다면, 모델이 과적합(overfitting)되고 있다는 신호입니다. 이 경우 모델의 복잡도를 줄이는 등의 조치가 필요합니다. 반대로 학습 데이터와 검증 데이터의 로그 손실이 동시에 증가한다면, 모델이 과소적합(underfitting)되고 있다는 신호입니다. 모델의 복잡도를 늘리는 등의 조치가 필요합니다.

**b. 최적의 학습 횟수 파악하기**: 학습 곡선에서 최적의 학습 횟수를 파악할 수 있습니다. 모델이 학습해야 하는 횟수를 더 이상 증가시키면, 검증 데이터의 로그 손실이 증가하게 됩니다. 이는 학습 과정을 제한하거나 조기 종료하는 데 유용한 정보일 수 있습니다.

**c. 모델 성능 평가하기**: 학습 곡선을 통해 모델의 성능을 평가할 수 있습니다. 학습 데이터의 로그 손실과 검증 데이터의 로그 손실이 모두 낮은 경우, 모델이 학습 데이터와 검증 데이터에 대해 효과적으로 일반화되었다고 할 수 있습니다.

## 마무리
이번 포스트에서는 lightgbm의 학습 곡선을 해석하는 방법에 대해 알아보았습니다. 학습 곡선은 모델의 학습 과정을 시각적으로 확인하고, 모델의 성능을 평가하는 데 유용한 도구입니다. 이를 통해 모델의 과적합 여부를 파악하고, 최적의 학습 횟수를 결정할 수 있습니다. 좀 더 깊은 이해와 분석을 위해선 다양한 시각화 기법을 활용하거나 다른 지표들과의 상관 관계를 파악하는 등의 작업이 필요합니다.