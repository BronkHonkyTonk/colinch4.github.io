---
layout: post
title: "[파이썬] xgboost와 `scikit-learn` 연동"
description: " "
date: 2023-09-07
tags: [xgboost]
comments: true
share: true
---

`xgboost`는 머신 러닝 알고리즘인 Gradient Boosting의 일종으로, 빠른 실행 속도와 높은 예측 성능을 제공하는 것으로 유명합니다. `scikit-learn`은 파이썬에서 머신 러닝을 수행하기 위한 매우 인기 있는 라이브러리입니다. 이번 블로그 포스트에서는 `xgboost`와 `scikit-learn`을 연동하여 사용하는 방법을 알아보겠습니다.

## 설치

먼저, `xgboost`와 `scikit-learn`을 설치해야 합니다. 아래의 명령어를 사용하여 설치할 수 있습니다:

```shell
pip install xgboost
pip install scikit-learn
```

## `scikit-learn`에서 `xgboost` 분류기 사용하기

`xgboost`를 `scikit-learn`의 분류기로 사용하기 위해서는 `xgboost.XGBClassifier` 클래스를 사용해야 합니다. 아래의 예제 코드를 통해 사용법을 살펴보겠습니다:

```python
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Iris 데이터셋 로드
iris = load_iris()
X, y = iris.data, iris.target

# 학습 데이터와 테스트 데이터로 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBClassifier 인스턴스 생성
xgb_model = XGBClassifier()

# 모델 학습
xgb_model.fit(X_train, y_train)

# 테스트 데이터로 예측
y_pred = xgb_model.predict(X_test)

# 정확도 평가
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
```

위의 코드에서 `XGBClassifier` 클래스를 사용하여 `xgboost` 분류기를 정의하고, `fit` 메소드로 모델을 학습시킵니다. 그리고 `predict` 메소드를 사용하여 테스트 데이터의 예측값을 계산하고, `accuracy_score` 함수를 통해 예측 성능을 평가합니다. 위의 예제에서는 아이리스 데이터셋을 사용하여 분류 작업을 수행하고 있습니다.

## `scikit-learn`에서 `xgboost` 회귀 모델 사용하기

`xgboost`를 `scikit-learn`의 회귀 모델로 사용하기 위해서는 `xgboost.XGBRegressor` 클래스를 사용해야 합니다. 아래의 예제 코드를 통해 사용법을 알아보겠습니다:

```python
import xgboost as xgb
from xgboost.sklearn import XGBRegressor
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 보스턴 주택가격 데이터셋 로드
boston = load_boston()
X, y = boston.data, boston.target

# 학습 데이터와 테스트 데이터로 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBRegressor 인스턴스 생성
xgb_model = XGBRegressor()

# 모델 학습
xgb_model.fit(X_train, y_train)

# 테스트 데이터로 예측
y_pred = xgb_model.predict(X_test)

# 평균 제곱근 오차 계산
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)
```

위의 코드에서 `XGBRegressor` 클래스를 사용하여 회귀 모델을 정의하고, 마찬가지로 `fit` 메소드로 모델을 학습시킵니다. 그리고 `predict` 메소드를 사용하여 테스트 데이터의 예측값을 계산하고, `mean_squared_error` 함수를 통해 오차를 평가합니다. 위의 예제에서는 보스턴 주택가격 데이터셋을 사용하여 회귀 작업을 수행하고 있습니다.

## 결론

이번 포스트에서는 `xgboost`와 `scikit-learn`을 연동하여 사용하는 방법을 알아보았습니다. `scikit-learn`의 편리한 인터페이스를 통해 `xgboost`를 사용할 수 있어, 머신 러닝 모델 개발에 많은 도움이 될 것입니다. 유연하고 높은 예측 성능을 가진 `xgboost`와 함께 더욱 효과적인 머신 러닝 시스템을 구축해보세요.

Happy coding!