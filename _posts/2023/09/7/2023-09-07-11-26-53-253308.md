---
layout: post
title: "[파이썬] fastai 데이터 로딩 및 처리"
description: " "
date: 2023-09-07
tags: [fastai]
comments: true
share: true
---

Fastai is a powerful deep learning library in Python that provides high-level abstractions for working with machine learning models. One of the core tasks in any machine learning project is loading and preprocessing the data. In this blog post, we will explore how to load and preprocess data using fastai.

## Loading Data

Fastai provides a convenient way to load data using the `DataBlock` API. This API allows you to define how your data should be loaded and transformed. Let's take a look at an example.

```python
from fastai.vision.all import *

# Define the path to your data
path = Path("/path/to/your/data")

# Define how your data should be loaded and transformed
dls = ImageDataLoaders.from_folder(path, train="train", valid="valid", bs=64)

# Visualize a batch of your data
dls.show_batch()
```
In the code above, we first import the necessary libraries. Then, we define the path to our data using the `Path` class from the `pathlib` module. Next, we use the `ImageDataLoaders` class to create a data loader. We specify the path to our data, the names of the training and validation folders, and the batch size. Finally, we visualize a batch of our data using the `show_batch` method.

## Data Preprocessing

Preprocessing the data is an essential step in machine learning. Fastai provides a variety of preprocessing techniques that can be easily applied to your data. Let's explore some of the common preprocessing techniques.

### Data Augmentation

Data augmentation is a technique used to artificially increase the size of the training set by applying random transformations to the data. Fastai provides a convenient way to apply data augmentation using the `aug_transforms` function.

```python
# Apply data augmentation to the training set
dls = ImageDataLoaders.from_folder(path, train="train", valid="valid",
                                  bs=64, item_tfms=Resize(224), batch_tfms=aug_transforms())

# Visualize a batch of augmented data
dls.show_batch()
```

In the code above, we modify the data loader to include data augmentation by passing the `aug_transforms()` function to the `batch_tfms` parameter. We also use the `Resize` transformation to resize the images to a specific size.

### Normalization

Normalization is a preprocessing technique used to scale the input data to a standard range. Fastai provides a normalization transformation that can be easily applied to your data.

```python
# Apply normalization to the data
dls = ImageDataLoaders.from_folder(path, train="train", valid="valid",
                                  bs=64, item_tfms=Resize(224), batch_tfms=aug_transforms(), normalize=True)
```

In the code above, we pass the `normalize=True` argument to the data loader to apply normalization.

### Custom Transformations

Fastai also allows you to define custom transformations using the `Pipeline` class. This is useful when you need to apply specific data preprocessing steps that are not provided by default.

```python
# Define a custom transformation pipeline
tfms = Pipeline([RandomResizedCrop(224), Flip(), Contrast()])

# Apply the custom transformation to the training set
dls = ImageDataLoaders.from_folder(path, train="train", valid="valid",
                                  bs=64, item_tfms=Resize(256), batch_tfms=tfms)

# Visualize a batch of transformed data
dls.show_batch()
```

In the code above, we define a custom transformation pipeline using the `Pipeline` class. We then pass the pipeline to the `batch_tfms` parameter of the data loader to apply the custom transformations.

## Conclusion

In this blog post, we explored how to load and preprocess data using fastai. We saw how to use the `DataBlock` API to load data and how to apply common preprocessing techniques such as data augmentation and normalization. We also learned how to define custom transformations using the `Pipeline` class. Fastai provides a powerful set of tools for data loading and preprocessing, making it easier to work with machine learning models.