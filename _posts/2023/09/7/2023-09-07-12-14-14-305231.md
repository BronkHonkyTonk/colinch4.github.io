---
layout: post
title: "[파이썬] lightgbm 벤치마크 및 경쟁 모델과의 비교"
description: " "
date: 2023-09-07
tags: [python,lightgbm]
comments: true
share: true
---

LightGBM은 Microsoft에서 개발한 Gradient Boosting 프레임워크로, 빠른 속도와 높은 성능으로 알려져 있습니다. 이번 블로그 포스트에서는 LightGBM의 벤치마크를 수행하고, 다른 경쟁 모델과의 비교를 해보겠습니다.

## LightGBM의 속도

LightGBM은 다른 Gradient Boosting 프레임워크에 비해 속도가 매우 빠른 편입니다. 이는 LightGBM이 트리 학습을 수평적으로 수행하는 Leaf-wise 트리 분할 방식을 사용하기 때문입니다. 이 방식은 데이터의 분포가 편향되어 있을 때 더욱 효과적으로 학습을 진행할 수 있습니다.

속도 비교를 위해 LightGBM과 XGBoost, CatBoost를 사용하여 벤치마크를 수행해보겠습니다.

```python
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import time

# 데이터셋 생성
X, y = make_classification(n_samples=10000, n_features=100, random_state=42)

# Train/Test 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM 학습 시간 측정
start_time = time.time()
lgb_model = lgb.LGBMClassifier()
lgb_model.fit(X_train, y_train)
lgb_pred = lgb_model.predict(X_test)
lgb_time = time.time() - start_time
lgb_accuracy = accuracy_score(y_test, lgb_pred)

# XGBoost 학습 시간 측정
start_time = time.time()
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)
xgb_time = time.time() - start_time
xgb_accuracy = accuracy_score(y_test, xgb_pred)

# CatBoost 학습 시간 측정
start_time = time.time()
cb_model = cb.CatBoostClassifier()
cb_model.fit(X_train, y_train)
cb_pred = cb_model.predict(X_test)
cb_time = time.time() - start_time
cb_accuracy = accuracy_score(y_test, cb_pred)

print("LightGBM 학습 시간:", lgb_time)
print("XGBoost 학습 시간:", xgb_time)
print("CatBoost 학습 시간:", cb_time)

print("LightGBM 예측 정확도:", lgb_accuracy)
print("XGBoost 예측 정확도:", xgb_accuracy)
print("CatBoost 예측 정확도:", cb_accuracy)
```

위 코드를 실행하면 LightGBM, XGBoost, CatBoost의 학습 시간과 예측 정확도를 비교할 수 있습니다.

## LightGBM의 성능

LightGBM의 성능은 빠른 학습과 함께 높은 정확도를 제공합니다. 이는 LightGBM이 데이터를 효과적으로 처리하는 Leaf-wise 트리 분할 방식을 사용하기 때문입니다. 이를 확인하기 위해 다른 경쟁 모델과의 정확도 비교를 수행해보겠습니다.

```python
import lightgbm as lgb
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 데이터셋 생성
X, y = make_classification(n_samples=10000, n_features=100, random_state=42)

# Train/Test 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM 모델 생성 및 학습
model = lgb.LGBMClassifier()
model.fit(X_train, y_train)

# 예측 및 정확도 계산
pred = model.predict(X_test)
accuracy = accuracy_score(y_test, pred)

print("LightGBM 예측 정확도:", accuracy)
```

위 코드를 실행하면 LightGBM을 사용하여 분류 태스크를 수행하고, 예측 정확도를 확인할 수 있습니다.

## 결론

LightGBM은 뛰어난 속도와 성능으로 인해 많은 데이터 과학자와 개발자들에게 사랑받고 있습니다. 이번 블로그 포스트에서는 LightGBM의 속도를 벤치마크하고, 다른 경쟁 모델과의 비교를 통해 그 성능을 확인해보았습니다. LightGBM은 다양한 분야에서 효과적인 모델 학습과 예측을 지원하며, 빠른 속도로 결과를 제공합니다.

**참고 자료:**
- LightGBM 공식 문서: [https://lightgbm.readthedocs.io](https://lightgbm.readthedocs.io)
- XGBoost 공식 문서: [https://xgboost.readthedocs.io](https://xgboost.readthedocs.io)
- CatBoost 공식 문서: [https://catboost.ai](https://catboost.ai)