---
layout: post
title: "[파이썬] csv 큰 CSV 파일 처리하기"
description: " "
date: 2023-09-08
tags: [python,csv]
comments: true
share: true
---

CSV (Comma Separated Values) 파일은 텍스트 파일 형식이며, 데이터를 행과 열로 구성하여 저장하는데 사용됩니다. 작은 크기의 CSV 파일은 일반적으로 쉽게 처리할 수 있지만, 큰 CSV 파일을 처리하는 것은 도전입니다.

이 블로그 포스트에서는 파이썬을 사용하여 큰 CSV 파일을 효율적으로 처리하는 방법을 알아보겠습니다.

## 1. CSV 파일 읽기

파이썬에는 CSV 파일을 읽기 위해 내장된 `csv` 모듈이 있습니다. 이 모듈을 사용하면 CSV 파일을 쉽게 읽고 데이터를 처리할 수 있습니다.

다음은 `csv.reader`를 사용하여 CSV 파일을 읽는 예제 코드입니다:

```python
import csv

# CSV 파일을 읽고 데이터를 출력하는 함수
def read_csv_file(file_path):
    with open(file_path, 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            # 데이터 처리 로직을 작성하세요
            print(row)
```

위의 코드에서 `csv.reader` 함수는 CSV 파일을 읽고, 각 행을 리스트로 반환합니다. 행의 데이터는 리스트의 요소로 저장됩니다. 이후에 데이터 처리 로직을 적용하여 원하는 방식으로 처리할 수 있습니다.

## 2. 큰 CSV 파일 처리하기

큰 CSV 파일을 처리할 때에는 메모리 사용량과 성능을 고려해야 합니다. 이를 위해 다음과 같은 방법들을 적용할 수 있습니다:

### 2.1. 청크 단위로 파일 읽기

CSV 파일을 한 번에 모두 읽는 대신, 청크 단위로 파일을 읽어오는 방식을 사용할 수 있습니다. 이를 위해 `csv.reader`를 사용하기 전에 파일을 여러 개의 청크로 나누어 읽을 수 있습니다.

```python
import csv

# CSV 파일을 청크 단위로 읽고 데이터를 출력하는 함수
def read_csv_file_in_chunks(file_path, chunk_size):
    with open(file_path, 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        while True:
            chunk = [next(csv_reader) for _ in range(chunk_size)]
            if not chunk:
                break
            # 청크 별로 데이터 처리 로직을 작성하세요
            print(chunk)
```

위의 코드에서 `chunk_size`는 읽을 청크의 크기를 나타내는 변수입니다. 이를 조정하여 메모리 사용량을 조절할 수 있습니다.

### 2.2. Pandas 라이브러리 사용

Pandas는 매우 큰 CSV 파일을 처리하기에 효율적인 도구입니다. Pandas를 사용하면 데이터를 DataFrame 형식으로 처리할 수 있으며, 다양한 데이터 조작 연산을 수행할 수 있습니다.

```python
import pandas as pd

# CSV 파일을 읽고 데이터를 DataFrame으로 반환하는 함수
def read_csv_file_with_pandas(file_path):
    df = pd.read_csv(file_path)
    # 데이터 처리 로직을 작성하세요
    print(df.head())
```

Pandas는 내부적으로 청크 단위로 데이터를 읽어옵니다. 따라서 메모리 사용량을 최적화하면서 큰 CSV 파일을 처리할 수 있습니다.

## 3. 메모리 사용량 최적화하기

큰 CSV 파일을 처리할 때 메모리 사용량을 최적화하는 것이 중요합니다. 메모리 사용량을 줄이는 몇 가지 방법을 소개합니다:

- `csv.reader` 대신 `csv.DictReader`를 사용하여 딕셔너리 형태로 데이터를 읽을 수 있습니다.
- 필요한 열만 읽어올 수 있도록 `usecols` 매개변수를 사용합니다.
- 데이터 처리 과정에서 불필요한 변수나 객체에 대한 레퍼런스를 제거합니다.

예를 들어, 다음과 같이 `csv.DictReader`와 `usecols`를 사용하여 메모리 사용량을 최적화할 수 있습니다:

```python
import csv

# 필요한 열만 딕셔너리 형태로 읽기
def read_csv_with_dict_reader(file_path):
    with open(file_path, 'r') as csv_file:
        csv_reader = csv.DictReader(csv_file, fieldnames=['col1', 'col2'])
        for row in csv_reader:
            # 데이터 처리 로직을 작성하세요
            print(row)
```

위의 코드에서 `fieldnames`는 CSV 파일의 열 이름을 지정하는 매개변수입니다. 필요한 열만 지정하여 읽을 수 있으며, 나머지 열은 무시됩니다.

## 결론

이 블로그 포스트에서는 Python을 사용하여 큰 CSV 파일을 처리하는 방법에 대해 알아보았습니다. 청크 단위로 파일을 읽거나 Pandas 라이브러리를 활용하여 데이터를 효율적으로 처리할 수 있습니다. 또한 메모리 사용량을 최적화하기 위해 몇 가지 기술을 소개했습니다.

큰 CSV 파일을 처리해야 할 때는 앞선 방법들을 적절히 혼합하여 사용하면 됩니다. 이를 통해 데이터 분석 및 처리 작업을 보다 효율적으로 수행할 수 있습니다.