---
layout: post
title: "[파이썬] Airflow와 ElasticSearch 연동"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow는 데이터 파이프라인 흐름을 자동화하고 모니터링하기 위한 오픈 소스 플랫폼입니다. ElasticSearch는 대규모 데이터의 실시간 검색 및 분석에 사용되는 오픈 소스 검색 및 분석 엔진입니다. 이 두 기술을 연동하여 Airflow에서 ElasticSearch에 데이터를 색인하고 검색할 수 있습니다.

## 필요한 패키지 설치

Airflow에서 ElasticSearch를 사용하기 위해서는 몇 가지 패키지를 설치해야 합니다.

```bash
pip install elasticsearch
pip install elasticsearch-dbapi
```

## Airflow DAG 설정

Airflow DAG 파일에서 ElasticSearch를 사용하기 위해 다음과 같이 `from elasticsearch import Elasticsearch`를 추가합니다.

```python
from elasticsearch import Elasticsearch
```

## ElasticSearch 연결

연결하려는 ElasticSearch 클러스터의 호스트 및 포트를 지정하여 Elasticsearch 객체를 초기화합니다.

```python
es = Elasticsearch(
    hosts=["localhost:9200"],
    http_auth=("username", "password"),
    scheme="http",
)
```

위의 예제에서는 `localhost:9200`으로 호스트 및 포트를 설정하고, `username`과 `password`를 사용하여 인증을 수행합니다.

## 데이터 색인하기

ElasticSearch에 데이터를 색인하기 위해서는 데이터를 JSON 형식으로 변환하고 Elasticsearch의 `index` 메서드로 전송해야 합니다.

```python
data = {
    "title": "Airflow와 ElasticSearch 연동",
    "content": "Airflow와 ElasticSearch를 연동하여 데이터 파이프라인을 관리하고 검색할 수 있습니다.",
    "timestamp": "2022-08-01T10:00:00",
}

index_name = "blog-posts"

es.index(index=index_name, body=data)
```

위의 예제에서는 `data`라는 JSON 객체를 생성하고, `index_name` 변수에 인덱스 이름을 할당합니다. `es.index()` 메서드를 사용하여 데이터를 색인합니다.

## 데이터 검색하기

ElasticSearch에서 데이터를 검색하려면 Elasticsearch의 `search` 메서드를 사용해야 합니다.

```python
query = {
    "query": {
        "match": {
            "content": "Airflow"
        }
    }
}

result = es.search(index=index_name, body=query)
hits = result["hits"]["hits"]

for hit in hits:
    print(hit["_source"]["title"])
```

위의 예제에서는 `query`라는 쿼리 객체를 생성하고, `content` 필드에서 "Airflow"를 검색하는 쿼리를 작성합니다. `es.search()` 메서드로 검색을 수행하고, 결과에서 필요한 데이터를 추출하여 출력합니다.

Airflow와 ElasticSearch를 연동하여 데이터를 색인하고 검색하는 방법에 대해 알아보았습니다. 이를 통해 Airflow를 사용하여 데이터 파이프라인을 자동화하고 ElasticSearch를 활용하여 데이터를 실시간으로 검색할 수 있습니다.