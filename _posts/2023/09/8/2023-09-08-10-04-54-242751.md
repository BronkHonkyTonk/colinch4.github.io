---
layout: post
title: "[파이썬] Airflow Task Retries 설정"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow, an open-source platform, is widely used for orchestrating and scheduling workflows. One of the key features of Airflow is its ability to handle task retries automatically when they fail. Configuring task retries correctly ensures reliable and robust task execution.

In this article, we'll explore how to configure task retries in Airflow using Python.

## Basic Retry Configuration

By default, Airflow tasks have a retry mechanism built-in. When a task fails, it will be retried a few times based on the Airflow configuration. To configure the basic retry behavior, you can set the following parameters in your DAG (Directed Acyclic Graph):

```python
from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.dummy_operator import DummyOperator

default_args = {
    'owner': 'airflow',
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'retry_example',
    default_args=default_args,
    start_date=days_ago(1),
)

task1 = DummyOperator(task_id='task1', dag=dag)

task2 = DummyOperator(task_id='task2', dag=dag)

task1 >> task2
```

In this example, we set `retries` to 3, meaning each failed task will be retried three times. The `retry_delay` parameter sets the delay between retries, which is set to 5 minutes in this case.

## Custom Retry Configuration

Sometimes, we may want to customize the retry behavior for specific tasks. Airflow provides the option to override the default retry configuration on a per-task basis.

```python
from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.dummy_operator import DummyOperator

dag = DAG(
    'custom_retry_example',
    start_date=days_ago(1),
)

# Task with custom retry settings
task1 = DummyOperator(
    task_id='task1',
    retries=5,  # Custom retry count
    retry_delay=timedelta(minutes=10),  # Custom retry delay
    dag=dag,
)

# Task using default retry settings
task2 = DummyOperator(task_id='task2', dag=dag)

task1 >> task2
```

In this example, we have configured `task1` with a custom retry count of 5 and a custom retry delay of 10 minutes. `task2`, on the other hand, will use the default retry configuration.

## Exponential Backoff Retries

Airflow also offers exponential backoff retries, which gradually increase the delay between retries. This can be helpful in cases where immediate retries might cause further issues or resource saturation.

To enable exponential backoff retries, you can set the `retry_exponential_backoff` parameter to `True` in the task configuration.

```python
from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.dummy_operator import DummyOperator

dag = DAG(
    'exponential_backoff_retry_example',
    start_date=days_ago(1),
)

# Task with exponential backoff retries
task1 = DummyOperator(
    task_id='task1',
    retries=3,
    retry_delay=timedelta(minutes=5),
    retry_exponential_backoff=True,  # Enable exponential backoff retries
    dag=dag,
)

# Task without exponential backoff retries
task2 = DummyOperator(task_id='task2', dag=dag)

task1 >> task2
```

With `retry_exponential_backoff` set to True, the retry delay for each subsequent retry will increase exponentially based on the formula `delay * 2^(retry_number - 1)`.

## Conclusion

Configuring task retries in Airflow is essential to ensure the reliability and resilience of your workflows. In this article, we explored how to configure basic retries, customize retry settings for specific tasks, and utilize exponential backoff retries.

By appropriately configuring retries, you can minimize the impact of failures and achieve more robust and fault-tolerant workflow executions in Airflow.