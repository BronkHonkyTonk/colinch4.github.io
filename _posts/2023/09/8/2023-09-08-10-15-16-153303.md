---
layout: post
title: "[파이썬] Airflow와 Microsoft Azure 연동"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow는 오픈 소스 데이터 파이프라인 오케스트레이션 도구입니다. Microsoft Azure는 대규모 클라우드 컴퓨팅 플랫폼으로 데이터 저장소, 분석, 인공 지능 등 다양한 서비스를 제공합니다. 이 블로그 포스트에서는 Airflow와 Microsoft Azure를 연동하는 방법을 알아보겠습니다.

## 1. Azure Blob Storage에 연결하기

Azure Blob Storage는 Azure에서 제공하는 객체 스토리지 서비스로, 대량의 비정형 데이터를 저장할 수 있습니다. Airflow에서 Azure Blob Storage에 접근하려면 다음 단계를 따르면 됩니다.

1. `azure-storage-blob` 패키지를 설치합니다.
   
```python
pip install azure-storage-blob
```

2. Airflow DAG에서 `BlobStorageHook`을 import하고 Azure Blob Storage에 연결합니다.

```python
from airflow.contrib.hooks.azure_storage_blob_hook import BlobStorageHook

def my_task():
    hook = BlobStorageHook(conn_id='my_azure_conn')
    # Azure Blob Storage 작업 수행
```

`my_azure_conn`은 Airflow의 연결 설정(configuration)에 정의된 Azure Blob Storage 연결 정보입니다.

## 2. Azure Databricks와 연결하기

Azure Databricks는 Apache Spark 기반의 분석 및 빅데이터 플랫폼으로, 높은 확장성과 성능을 제공합니다. Airflow에서 Azure Databricks와 연동하여 Databricks 작업을 처리할 수 있습니다.

1. `apache-airflow-providers-apache-spark` 패키지를 설치합니다.

```python
pip install apache-airflow-providers-apache-spark
```

2. Airflow DAG에서 `DatabricksSubmitRunOperator`를 import하고 Azure Databricks와 연결합니다.

```python
from airflow.providers.apache.spark.operators.databricks import DatabricksSubmitRunOperator

def my_task():
    spark_task = DatabricksSubmitRunOperator(
        task_id='my_spark_task',
        databricks_conn_id='my_databricks_conn',
        json={
            "sparkJarTask": {
                "mainClass": "com.example.ProcessData",
                "parameters": [
                    "--input", "input-data",
                    "--output", "output-data"
                ]
            }
        }
    )
    # Azure Databricks 작업 수행
```

`my_databricks_conn`은 Airflow의 연결 설정(configuration)에 정의된 Azure Databricks 연결 정보입니다.

## 3. Azure SQL Database와 연결하기

Azure SQL Database는 관리형 관계형 데이터베이스 서비스로, 신속한 애플리케이션 개발 및 배포에 적합합니다. Airflow에서 Azure SQL Database와 연동하여 데이터베이스 작업을 수행할 수 있습니다.

1. `azure-sqlalchemy` 패키지를 설치합니다.

```python
pip install azure-sqlalchemy
```

2. Airflow DAG에서 `MsSqlHook`을 import하고 Azure SQL Database에 연결합니다.

```python
from airflow.providers.microsoft.mssql.hooks.mssql import MsSqlHook

def my_task():
    hook = MsSqlHook(mssql_conn_id='my_sql_conn')
    # Azure SQL Database 작업 수행
```

`my_sql_conn`은 Airflow의 연결 설정(configuration)에 정의된 Azure SQL Database 연결 정보입니다.

## 결론

이렇게 Airflow와 Microsoft Azure를 연동하여 다양한 서비스와 데이터 워크로드를 처리할 수 있습니다. Azure Blob Storage, Azure Databricks, Azure SQL Database 외에도 다른 Azure 서비스와의 연동도 가능하며, 이를 통해 효율적인 데이터 파이프라인을 구축할 수 있습니다.