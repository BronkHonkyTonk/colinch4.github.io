---
layout: post
title: "[파이썬] Google Cloud Data Fusion 데이터 통합 및 변환"
description: " "
date: 2023-09-08
tags: [python,google cloud python]
comments: true
share: true
---

Google Cloud Data Fusion는 데이터 통합과 변환 작업을 위한 강력한 플랫폼입니다. 이를 사용하여 다양한 데이터 소스에서 데이터를 추출하고 변환하여 원하는 형식으로 가져올 수 있습니다. 이 블로그 포스트에서는 Python을 사용하여 Google Cloud Data Fusion을 활용하는 방법을 알아보겠습니다.

## 1. Google Cloud Data Fusion 설정

먼저, Google Cloud Data Fusion을 프로젝트에 설정해야 합니다. 다음 단계를 따라 진행해보세요:

1. Google Cloud Console에 로그인합니다.
2. 프로젝트를 선택하고 Data Fusion 서비스를 활성화합니다.
3. Data Fusion 인스턴스를 생성하고 필요한 구성을 완료합니다.

## 2. Data Fusion 파이프라인 생성

Data Fusion 인스턴스가 설정되면 파이프라인을 생성할 수 있습니다. 파이프라인은 데이터 추출, 변환 및 로드 작업을 정의하는 기본 단위입니다. 다음은 파이프라인을 생성하는 방법의 예입니다:

```python
from google.cloud import datafusion_v1beta1 as datafusion

# 인스턴스 이름 설정
INSTANCE_NAME = 'projects/<my-project-id>/locations/<my-location>/instances/<my-instance>'

# 파이프라인 구성 설정
pipeline_config = {
    'name': 'my-pipeline',
    'description': 'My Data Fusion pipeline',
    'enableStackdriverLogging': True,
    'networkConfig': {
        'network': 'default',
        'ipAllocation': '10.0.0.0/24'
    }
}

# Data Fusion 클라이언트 초기화
client = datafusion.DataFusionClient()

# 파이프라인 생성
pipeline = client.create_pipeline(parent=INSTANCE_NAME, pipeline=pipeline_config)

print(f'Pipeline created: {pipeline.name}')
```

위의 예제 코드에서는 `google-cloud-datafusion` 패키지를 사용하여 Data Fusion 클라이언트를 초기화하고, `create_pipeline` 메서드를 통해 파이프라인을 생성합니다.

## 3. Data Fusion 파이프라인 구성

파이프라인을 생성한 후에는 파이프라인의 구성을 정의해야 합니다. 이 단계에서는 데이터 추출, 변환 및 로드를 위한 단계를 추가합니다. 다음은 파이프라인 구성을 설정하는 예입니다:

```python
# 파이프라인 ID 설정
PIPELINE_ID = 'my-pipeline-id'

# 파이프라인 구성 설정
pipeline_config = {
    'name': PIPELINE_ID,
    'description': 'My Data Fusion pipeline',
    'project': '<my-project-id>',
    'location': '<my-location>',
    'stages': [
        {
            'name': 'source_stage',
            'plugin': {
                'name': 'Datastream Source',
                'type': 'source',
                'artifact': {
                    'name': 'datastream-mysql-source',
                    'version': '1.0.0'
                },
                'properties': {
                    'sourceJdbcUrl': 'jdbc:mysql://<mysql-host>:<mysql-port>/<mysql-database>',
                    'sourceUsername': '<mysql-username>',
                    'sourcePassword': '<mysql-password>',
                    'tableWhitelist': '<mysql-table>'
                }
            },
            'outputConnections': []
        },
        {
            'name': 'transform_stage',
            'plugin': {
                'name': 'Data Wrangler',
                'type': 'transform',
                'artifact': {
                    'name': 'wrangler-transform',
                    'version': '1.0.0'
                },
                'properties': {
                    'wranglerScript': 'transform_script.py'
                }
            },
            'inputConnections': [],
            'outputConnections': []
        },
        {
            'name': 'sink_stage',
            'plugin': {
                'name': 'BigQuery',
                'type': 'sink',
                'artifact': {
                    'name': 'bigquery-sink',
                    'version': '1.0.0'
                },
                'properties': {
                    'project': '<my-project-id>',
                    'dataset': 'my_dataset',
                    'table': 'my_table'
                }
            },
            'inputConnections': []
        }
    ]
}

# 파이프라인 구성 업데이트
pipeline = client.update_pipeline(pipeline=pipeline_config)

print(f'Pipeline updated: {pipeline.name}')
```

위의 예제 코드에서는 파이프라인 구성을 `stages` 리스트에 정의하여 설정합니다. 이 예에서는 Data Fusion에서 MySQL 데이터베이스에서 데이터를 추출하고, 변환 작업을 위해 Data Wrangler 플러그인을 사용하며, BigQuery로 데이터를 로드하는 단계를 추가합니다.

## 4. Data Fusion 파이프라인 실행

파이프라인이 구성되면 실행할 수 있습니다. 다음은 파이프라인을 실행하는 예입니다:

```python
# 파이프라인 실행
operation = client.set_instance_state(name=INSTANCE_NAME, state='RUNNING')

print(f'Pipeline is running: {operation.name}')
```

위의 예제 코드에서는 `set_instance_state` 메서드를 사용하여 파이프라인을 실행합니다.

## 5. Data Fusion 실행 모니터링

파이프라인이 실행되면 실행 상태를 모니터링할 수 있습니다. 다음은 상태를 확인하는 예입니다:

```python
# 파이프라인 상태 확인
response = client.get_pipeline(name=pipeline.name)

print(f'Pipeline state: {response.runtime_info.state}')
```

위의 예제 코드에서는 `get_pipeline` 메서드를 사용하여 파이프라인의 상태를 확인합니다.

## 6. 요약

위에서는 Python을 사용하여 Google Cloud Data Fusion을 설정하고, 파이프라인을 생성하고, 구성하고, 실행하며, 모니터링하는 방법을 알아보았습니다. 이것은 데이터 통합 및 변환 작업에 매우 효과적인 플랫폼이며, Python을 사용하여 더욱 유연하고 자동화된 방식으로 작업을 수행할 수 있습니다.