---
layout: post
title: "[파이썬] Airflow Parallelism 및 Concurrency 설정"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow is an open-source platform used for scheduling and orchestrating workflows. It allows users to define and schedule tasks as directed acyclic graphs (DAGs) and provides a web interface for monitoring and managing these workflows. One of the key features of Airflow is its ability to execute tasks in parallel, maximizing the efficiency of workflows.

In this blog post, we will explore how to configure parallelism and concurrency settings in Airflow using Python.

## Parallelism 설정

Parallelism in Airflow determines the number of tasks that can be executed simultaneously. By default, it is set to 32, but you can configure it according to your requirements.

To set the parallelism value, you need to modify the `parallelism` parameter in the Airflow configuration file which is typically named `airflow.cfg`. Locate the following line in the configuration file:

```python
parallelism = 32
```

You can change the value of `parallelism` to the desired number of parallel tasks. For example, if you want to set it to 50, modify the line as follows:

```python
parallelism = 50
```

Save the file and restart the Airflow scheduler and webserver for the changes to take effect.

## Concurrency 설정

Concurrency, on the other hand, determines the maximum number of task instances that can be executed by the Airflow scheduler at any given time. It limits the number of task instances that can be queued and executed concurrently.

To configure concurrency, locate the following line in the Airflow configuration file:

```python
dag_concurrency = 16
```

Change the value of `dag_concurrency` to the desired number. For example, if you want to set it to 20, modify the line as follows:

```python
dag_concurrency = 20
```

Similarly, save the file and restart the Airflow scheduler and webserver for the changes to take effect.

## Task Level Concurrency

In addition to setting overall concurrency, you can also configure concurrency at the task level. This allows you to control the maximum number of task instances that can be run concurrently for a specific task.

To set task level concurrency, you can modify the `task_concurrency` property of the task in the DAG definition. For example:

```python
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime

def some_task():
    # Task logic here

dag = DAG('my_dag', start_date=datetime(2022, 1, 1), schedule_interval='@daily')

task1 = PythonOperator(task_id='task1', python_callable=some_task, dag=dag, task_concurrency=3)
task2 = PythonOperator(task_id='task2', python_callable=some_task, dag=dag, task_concurrency=2)
```

In the above example, `task1` can have a maximum of 3 concurrent instances running at a time, while `task2` can have a maximum of 2 concurrent instances.

## Conclusion

Configuring parallelism and concurrency settings in Airflow is important to optimize the execution of your workflows. By adjusting these settings based on your resource constraints and workflow requirements, you can ensure efficient task execution and avoid performance bottlenecks.

Remember to always monitor your workflows and make incremental adjustments to these settings as needed.