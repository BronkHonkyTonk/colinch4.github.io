---
layout: post
title: "[파이썬] Airflow와 JSON 파일 처리"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow는 데이터 파이프라인을 작성하고 관리하기 위한 오픈 소스 플랫폼입니다. JSON 파일은 많은 데이터 시스템에서 일반적으로 사용되는 형식 중 하나입니다. 이 블로그 포스트에서는 Airflow를 사용하여 JSON 파일을 처리하는 방법을 살펴보겠습니다.

## JSON 파일 읽기

Python에서 JSON 파일을 읽기 위해서는 `json` 모듈을 사용해야 합니다. 다음 코드는 JSON 파일을 읽고 데이터를 파싱하는 예시입니다.

```python
import json

# JSON 파일 읽기
with open('data.json') as file:
    data = json.load(file)

# 데이터 접근
print(data["name"])
print(data["age"])
```

위 코드에서 `data.json`은 읽을 JSON 파일의 이름입니다. `json.load()` 함수를 사용하여 파일을 읽고 파이썬 데이터로 변환합니다. 그리고 추출한 데이터에 접근하여 필요한 정보를 얻을 수 있습니다.

## JSON 파일 쓰기

JSON 파일을 작성하는 것도 매우 간단합니다. 다음은 Python에서 JSON 파일을 작성하는 예시입니다.

```python
import json

# 작성할 데이터
data = {
    "name": "John",
    "age": 30
}

# JSON 파일 작성
with open('output.json', 'w') as file:
    json.dump(data, file)
```

위 코드에서 `output.json`은 작성할 JSON 파일의 이름입니다. `json.dump()` 함수를 사용하여 데이터를 JSON 포맷으로 변환하여 파일에 작성합니다.

## Airflow에서 JSON 파일 처리하기

이제 JSON 파일을 Airflow에서 처리해보겠습니다. Airflow는 다양한 작업을 효과적으로 관리하는데 도움을 주는 Task 스케줄링 및 모니터링 도구입니다. JSON 파일을 처리하기 위해 Airflow DAG(Directed Acyclic Graph) 파일을 작성해야 합니다.

예를 들어, JSON 파일을 읽고 `"name"`과 `"age"`를 출력하는 작업을 수행하는 DAG 파일은 다음과 같을 수 있습니다.

```python
import json
from airflow import DAG
from airflow.operators.python_operator import PythonOperator

def process_json():
    with open('data.json') as file:
        data = json.load(file)
    print(data["name"])
    print(data["age"])

with DAG('json_dag', description='Process JSON file', schedule_interval='@once', start_date=datetime(2022, 1, 1), catchup=False) as dag:
    task = PythonOperator(
        task_id='process_json',
        python_callable=process_json
    )
```

위 코드에서 `data.json`은 읽을 JSON 파일의 이름입니다. `process_json()` 함수는 JSON 파일을 읽고 데이터를 출력하는 작업을 수행합니다. `PythonOperator`를 사용하여 해당 함수를 실행하도록 설정합니다.

JSON 파일을 처리하기 위한 Airflow DAG 파일을 작성함으로써, JSON 데이터를 원하는 방식으로 읽거나 작성할 수 있게 됩니다. 이렇게 Airflow를 사용하여 JSON 파일을 처리하면 데이터 파이프라인을 구축하고 관리하는데 유용하게 활용할 수 있습니다.