---
layout: post
title: "[파이썬] Airflow와 Kubernetes 연동"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow와 Kubernetes는 모두 대중적인 오픈 소스 도구인데, 각각의 강력한 기능을 가지고 있다. Airflow는 작업 스케줄링과 모니터링을 위한 프레임워크로 사용되며, Kubernetes는 컨테이너 오케스트레이션 시스템으로 사용된다. 이 두 가지 기술을 연동하여 실행 가능한 워크플로우를 구축할 수 있다.

## Airflow와 Kubernetes의 연동 방법

Airflow와 Kubernetes를 연동하기 위해서는 몇 가지 설정과 작업이 필요하다. 이 글에서는 Python을 이용한 연동 방법을 설명할 것이다.

## 1. KubernetesExecutor 설정

우선 Airflow의 설정 파일(`airflow.cfg`)에서 `executor` 옵션을 `KubernetesExecutor`로 설정해야 한다. 이 옵션은 Airflow가 Kubernetes에서 작업을 실행하도록 지시하는 역할을 한다.

```
executor = KubernetesExecutor
```

## 2. Kubernetes 클러스터 설정

이제 Kubernetes 클러스터에 대한 설정을 해야 한다. Kubernetes 클러스터와 통신하기 위해서는 클러스터의 URL과 인증 토큰이 필요하다. 이 정보를 활용하여 Python 코드에서 Kubernetes 클라이언트를 초기화하고 사용할 수 있다.

```python
from kubernetes import client, config

# Kubernetes 클라이언트 초기화
config.load_kube_config() # Kubernetes 클러스터의 설정 파일을 로드
kube_client = client.CoreV1Api() # Kubernetes 클라이언트 생성
```

## 3. Kubernetes Pod 생성

Airflow에서 실행할 작업은 Kubernetes Pod로 실행된다. Pod는 실행할 컨테이너와 관련된 설정을 포함하고 있다. Kubernetes 클라이언트를 사용하여 Python 코드에서 Pod를 생성할 수 있다.

```python
pod = client.V1Pod()
pod.metadata = client.V1ObjectMeta(name="my-pod")
pod.spec = client.V1PodSpec(containers=[{"name": "my-container", "image": "my-image"}])

kube_client.create_namespaced_pod(namespace="default", body=pod)
```

위 코드에서 `my-pod`라는 이름의 Pod를 생성하고, `my-container`라는 이름의 컨테이너에 `my-image` 이미지를 사용하도록 설정했다.

## 4. Airflow DAG 작성

Airflow에서 실행할 워크플로우(Job)는 DAG(Directed Acyclic Graph)로 정의된다. DAG는 Airflow의 `dag` 모듈을 사용하여 작성할 수 있다. DAG에는 작업(task)들을 정의하고, 작업들 간의 의존성을 설정할 수 있다.

```python
from airflow import DAG
from airflow.contrib.operators import KubernetesPodOperator

dag = DAG("my-dag", schedule_interval="0 1 * * *")

task1 = KubernetesPodOperator(
    task_id="task1",
    name="task1",
    namespace="default",
    image="my-image",
    dag=dag
)

task2 = KubernetesPodOperator(
    task_id="task2",
    name="task2",
    namespace="default",
    image="my-image",
    dag=dag
)

task1 >> task2
```

위 코드에서는 `my-dag`라는 이름의 DAG를 생성하고, 두 개의 작업을 정의한 후 작업 간에 의존성을 설정했다. 각 작업은 Kubernetes Pod 형태로 실행되며, `my-image` 이미지를 사용한다.

## 5. 워크플로우 실행

Airflow에서 작성한 DAG를 실행하기 위해 Airflow UI나 Airflow Command Line Interface(CLI)를 사용할 수 있다. DAG가 실행되면 Airflow는 Kubernetes에 작업을 생성하고 실행한다.

```
airflow trigger_dag my-dag
```

위 CLI 명령어를 사용하면 `my-dag`라는 이름의 DAG를 실행할 수 있다.

## 마무리

이처럼 Airflow와 Kubernetes를 연동하여 Python을 사용해 실행 가능한 워크플로우를 구축할 수 있다. Airflow는 작업 스케줄링과 모니터링을 담당하고, Kubernetes는 컨테이너 오케스트레이션을 담당하여 복잡한 시스템 구성과 배포를 용이하게 한다. 이러한 연동은 대규모 데이터 파이프라인이나 머신러닝 워크플로우 등의 구축에 매우 유용하다.