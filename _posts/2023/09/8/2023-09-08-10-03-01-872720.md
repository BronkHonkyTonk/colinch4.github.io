---
layout: post
title: "[파이썬] Airflow CLI 사용법"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Apache Airflow is an open-source platform used for orchestrating and scheduling workflows. One of the powerful features it offers is the Command Line Interface (CLI), which allows users to interact with Airflow from the terminal. In this blog post, we will explore the various commands available in the Airflow CLI and how to use them effectively in Python.

## Installation

Before using the Airflow CLI, make sure you have Airflow installed in your Python environment. You can install Airflow using pip with the following command:

```python
pip install apache-airflow
```

## Initializing Airflow

Once Airflow is installed, you need to initialize the Airflow database and create necessary directories by running the following command:

```python
airflow initdb
```

This command initializes the Airflow metadata database and creates necessary directories like `dags`, `plugins`, and `logs`.

## Configuration

To configure Airflow, you can modify the `airflow.cfg` file located in the Airflow home directory. The CLI provides a command to view and edit configurations:

```python
# View the configuration
airflow config list

# Edit the configuration
airflow config set <section> <key> <value>
```

Replace `<section>`, `<key>`, and `<value>` with the appropriate values for the configuration you want to edit or view.

## Managing DAGs

DAGs (Directed Acyclic Graphs) are the central component in Airflow and represent the workflows to be executed. The CLI provides commands to manage DAGs:

```python
# List all available DAGs
airflow list_dags

# Show details of a specific DAG
airflow show_dag <dag_id>
```

Replace `<dag_id>` with the actual ID of the DAG you want to view details for.

## Controlling Workflows

The CLI provides commands to control the execution of workflows:

```python
# Start a DAG run
airflow trigger_dag <dag_id>

# Pause a DAG
airflow pause <dag_id>

# Unpause a DAG
airflow unpause <dag_id>

# Run a specific task within a DAG
airflow run <dag_id> <task_id> <execution_date>
```

Replace `<dag_id>`, `<task_id>`, and `<execution_date>` with the actual IDs or dates for the workflows and tasks you want to control.

## Monitoring and Logging

Airflow CLI also provides commands to monitor and access logs:

```python
# Show the status of a DAG run
airflow task_state <dag_id> <execution_date> <task_id>

# Show the logs of a specific task
airflow task_logs <dag_id> <execution_date> <task_id>
```

Replace `<dag_id>`, `<execution_date>`, and `<task_id>` with the actual IDs or dates for the workflows and tasks you want to monitor or access logs for.

## Conclusion

The Airflow CLI is a powerful tool for managing and controlling workflows in Apache Airflow. With the commands discussed in this blog post, you can interact with Airflow from the terminal, configure Airflow settings, manage DAGs, control workflow execution, and monitor task status and logs.

Using the Airflow CLI in Python gives you the flexibility to script and automate your workflow management tasks, making it convenient and efficient to work with Airflow.