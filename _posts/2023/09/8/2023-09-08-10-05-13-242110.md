---
layout: post
title: "[파이썬] Airflow Scheduler 동작 원리"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Airflow는 작업 스케줄링 및 실행을 수행하는데 도움이 되는 강력한 오픈 소스 플랫폼입니다. Airflow Scheduler는 이러한 작업 스케줄링을 관리하고 실행하는 핵심 구성 요소입니다. 이 글에서는 Airflow Scheduler의 동작 원리를 파이썬을 통해 알아보겠습니다.

## Airflow Scheduler란?

Airflow Scheduler는 Airflow 워크플로우의 실행을 관리하는 역할을 합니다. 작업 스케줄링, 의존성 관리, 작업 실행 등 Airflow 워크플로우의 모든 측면을 처리합니다. 이를 통해 사용자는 미리 정의된 스케줄에 따라 작업이 자동으로 실행되도록 설정할 수 있습니다.

## 동작 원리

Airflow Scheduler의 동작은 다음 단계로 이루어집니다:

1. Scheduler는 작업 실행을 담당하는 Airflow Executor와 통신합니다. Executor는 실제 작업을 실행하는 역할을 합니다. 

2. Scheduler는 작업 스케줄에 따라 실행할 작업을 결정합니다. 이를 위해 Scheduler는 사용자가 정의한 DAG(Directed Acyclic Graph)를 확인하고 의존성을 고려하여 실행 가능한 작업을 찾습니다.

3. Scheduler는 실행 가능한 작업을 Executor에게 전달합니다. Executor는 작업을 실행할 워커 노드를 선택하고 해당 작업을 수행합니다.

4. 작업이 성공적으로 완료되면 Scheduler는 작업의 상태를 업데이트합니다. 실패한 작업의 경우 재시도 정책에 따라 다시 시도할 수 있습니다.

5. Scheduler는 작업 실행 로그 및 상태를 Airflow 메타데이터베이스에 기록합니다. 이를 통해 사용자는 작업의 상태 및 이력을 추적할 수 있습니다.

## 예시 코드

아래는 간단한 Airflow DAG(Directed Acyclic Graph) 예시 코드입니다. 이 DAG는 매일 오전 9시에 데이터베이스에서 데이터를 추출하고 변환하는 작업을 수행합니다.

```python
from airflow import DAG
from airflow.operators.mysql_operator import MySqlOperator
from datetime import datetime

# DAG 정의
dag = DAG(
    dag_id='example_dag',
    start_date=datetime(2021, 1, 1),
    schedule_interval='0 9 * * *'  # 매일 오전 9시에 실행
)

# 데이터베이스에서 데이터 추출 및 변환 작업 정의
extract_data_task = MySqlOperator(
    task_id='extract_data',
    sql='SELECT * FROM data_table',
    mysql_conn_id='mysql_connection',
    dag=dag
)

# DAG 작업 의존성 설정
extract_data_task
```

위 코드에서 `DAG`는 DAG 객체를 생성하고, `MySqlOperator`는 MySQL 데이터베이스에서 데이터를 추출하는 작업을 정의합니다. `task_id`는 작업의 고유 식별자이며, `sql`은 실행할 SQL 쿼리입니다. `mysql_conn_id`는 데이터베이스 연결 정보를 지정합니다.

이렇게 정의된 DAG는 Airflow Scheduler에서 해당 작업의 스케줄을 관리하고 Executor에게 작업을 전달하게 됩니다.

## 결론

Airflow Scheduler는 Airflow 워크플로우의 실행 관리를 담당하는 핵심 구성 요소입니다. 이 글에서는 Airflow Scheduler의 동작 원리와 예시 코드를 통해 그 동작 방식을 알아보았습니다. Airflow를 사용하여 복잡한 작업 스케줄링을 자동화하고 실행할 수 있으며, 강력한 기능과 유연성을 제공합니다.