---
layout: post
title: "[파이썬] Airflow와 Apache Cassandra 연동"
description: " "
date: 2023-09-08
tags: [python,Airflow]
comments: true
share: true
---

Apache Cassandra is a highly scalable, distributed NoSQL database known for its high availability and fault tolerance. Airflow, on the other hand, is an open-source platform used for orchestrating and scheduling workflows.

In this blog post, we will explore how to integrate Airflow with Apache Cassandra in Python. We will cover the necessary steps to set up the connection, write data to Cassandra, and retrieve data from Cassandra using Airflow tasks.

## Setting up the Connection

To establish a connection between Airflow and Cassandra, we need to install the `cassandra-driver` library. You can install it using pip:

```
pip install cassandra-driver
```

Next, we need to configure the Cassandra connection in the Airflow configuration file (`airflow.cfg`). Update the following parameters under the `[cassandra]` section:

```
[cassandra]
cql_host = <cassandra_host>
cql_port = <cassandra_port>
cql_username = <cassandra_username>
cql_password = <cassandra_password>
```

Replace `<cassandra_host>`, `<cassandra_port>`, `<cassandra_username>`, and `<cassandra_password>` with your specific Cassandra credentials.

## Writing Data to Cassandra

To write data to Cassandra using Airflow, we can create a custom operator that encapsulates the logic to insert data into a Cassandra table. Here's an example of how you can do this:

```python
from cassandra.cluster import Cluster
from cassandra.query import SimpleStatement
from airflow.models import BaseOperator
from airflow.utils.decorators import apply_defaults

class CassandraInsertOperator(BaseOperator):
    @apply_defaults
    def __init__(self, cql_query, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cql_query = cql_query

    def execute(self, context):
        cluster = Cluster(contact_points=['<cassandra_host>'], port='<cassandra_port>')
        session = cluster.connect()
        statement = SimpleStatement(self.cql_query)
        session.execute(statement)
        cluster.shutdown()
```

In the above code, we define a custom operator called `CassandraInsertOperator`. The operator takes a CQL query as input and executes it against the Cassandra cluster.

To use this operator in an Airflow DAG, you can define a task like this:

```python
insert_task = CassandraInsertOperator(
    task_id='insert_data_to_cassandra',
    cql_query='INSERT INTO my_table (column1, column2) VALUES (value1, value2)',
    dag=dag
)
```

Replace `my_table`, `column1`, `column2`, `value1`, and `value2` with your specific table and column names, as well as the values you want to insert.

## Retrieving Data from Cassandra

To retrieve data from Cassandra using Airflow, we can create another custom operator that fetches data from a Cassandra table. Here's an example:

```python
from cassandra.cluster import Cluster
from cassandra.query import SimpleStatement
from airflow.models import BaseOperator
from airflow.utils.decorators import apply_defaults

class CassandraSelectOperator(BaseOperator):
    @apply_defaults
    def __init__(self, cql_query, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cql_query = cql_query

    def execute(self, context):
        cluster = Cluster(contact_points=['<cassandra_host>'], port='<cassandra_port>')
        session = cluster.connect()
        statement = SimpleStatement(self.cql_query)
        result = session.execute(statement)
        cluster.shutdown()
        return result
```

Similarly, in the above code, we define a custom operator called `CassandraSelectOperator`. This operator takes a CQL query as input and executes it against the Cassandra cluster. It then returns the result.

To use this operator in an Airflow DAG, you can define a task like this:

```python
select_task = CassandraSelectOperator(
    task_id='select_data_from_cassandra',
    cql_query='SELECT * FROM my_table',
    dag=dag
)
```

Replace `my_table` with your specific table name.

## Conclusion

Integrating Apache Cassandra with Airflow opens up new possibilities for building powerful workflows that interact with a highly scalable and distributed database. With the help of the `cassandra-driver` library and custom operators, you can easily perform data insertion and retrieval from Cassandra using Airflow tasks. This integration allows for better data management and automation in your data pipelines.

Happy Airflow and Cassandra integration in Python!