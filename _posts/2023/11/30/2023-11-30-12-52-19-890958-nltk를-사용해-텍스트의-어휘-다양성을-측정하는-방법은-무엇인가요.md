---
layout: post
title: "[python] NLTK를 사용해 텍스트의 어휘 다양성을 측정하는 방법은 무엇인가요?"
description: " "
date: 2023-11-30
tags: [python]
comments: true
share: true
---

`Text` 객체의 `vocab` 속성을 활용하여 어휘 다양성을 측정할 수 있습니다. 아래는 `Text` 객체에서 어휘 다양성을 측정하는 예제 코드입니다.

```python
import nltk

# 텍스트 데이터
text = "NLTK is a powerful tool for natural language processing. It provides various functionalities to process and analyze text data."

# 단어 토큰화
tokens = nltk.word_tokenize(text)

# Text 객체 생성
text_object = nltk.Text(tokens)

# 어휘 다양성 측정
vocab_size = len(set(text_object))
diversity_score = vocab_size / len(text_object)

# 결과 출력
print("Vocabulary Size:", vocab_size)
print("Diversity Score:", diversity_score)
```

위 코드에서는 먼저 `word_tokenize` 함수를 사용하여 텍스트를 단어로 분리합니다. 그런 다음 `Text` 객체를 생성하고, `set` 함수를 사용하여 고유한 단어만을 포함하는 집합을 만듭니다. 어휘 다양성은 고유한 단어의 개수를 전체 단어 수로 나눈 값으로 계산됩니다.

위의 예제 코드를 실행하면 다음과 같은 결과가 출력됩니다:

```
Vocabulary Size: 15
Diversity Score: 0.6521739130434783
```

위에서 출력된 결과에서 `Vocabulary Size`은 고유한 단어의 개수를 나타내며, `Diversity Score`는 어휘 다양성 지표를 나타냅니다.

참고문헌:
- NLTK documentation: [https://www.nltk.org/](https://www.nltk.org/)
- Natural Language Processing with Python: [http://www.nltk.org/book/](http://www.nltk.org/book/)