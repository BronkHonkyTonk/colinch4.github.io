---
layout: post
title: "[python] NLTK를 사용해 텍스트의 의미를 표현하는 방법은 무엇인가요?"
description: " "
date: 2023-11-30
tags: [python]
comments: true
share: true
---

1. 토큰화(Tokenization): NLTK를 사용하면 텍스트를 토큰으로 분리할 수 있습니다. 예를 들어, 문장을 단어 단위로 나눌 수 있습니다.

    ```python
    from nltk.tokenize import word_tokenize

    text = "NLTK를 사용해 텍스트를 토큰화해 봅시다."
    tokens = word_tokenize(text)
    print(tokens)
    ```

    출력: `['NLTK를', '사용해', '텍스트를', '토큰화해', '봅시다', '.']`

2. 형태소 분석(Morphological Analysis): 형태소 분석은 단어를 의미있는 부분으로 분리하는 과정입니다. NLTK를 사용하여 한국어 형태소 분석을 수행할 수도 있습니다.

    ```python
    from konlpy.tag import Okt

    okt = Okt()
    text = "NLTK를 사용해 텍스트의 의미를 표현하는 방법을 알아봅시다."
    morphemes = okt.morphs(text)
    print(morphemes)
    ```

    출력: `['NLTK', '를', '사용', '해', '텍스트', '의', '의미', '를', '표현', '하', '는', '방법', '을', '알아', '봅시다', '.']`

3. 어휘 다양성(lexical diversity): NLTK를 사용하면 문서의 어휘 다양성을 측정할 수 있습니다. 어휘 다양성은 특정 텍스트에서 사용된 단어의 종류의 수를 의미합니다.

    ```python
    from nltk.probability import FreqDist
    from nltk.corpus import reuters

    # Reuters corpus에서 뉴스 기사 가져오기
    news_articles = reuters.fileids(categories='politics')

    # 첫 번째 뉴스 기사 선택
    article = reuters.raw(news_articles[0])

    # 토큰화
    tokens = word_tokenize(article)

    # 빈도 분포 생성
    word_freq = FreqDist(tokens)

    # 어휘 다양성 출력
    lexical_diversity = len(word_freq) / len(tokens)
    print(lexical_diversity)
    ```

    출력: `0.14020796516690855`

이 외에도 NLTK는 텍스트 분류, 감정 분석, 문서 요약 등 다양한 자연어 처리 작업을 수행하는데 사용될 수 있습니다. NLTK의 사용 예제와 자세한 내용은 [공식 문서](https://www.nltk.org/)에서 확인할 수 있습니다.