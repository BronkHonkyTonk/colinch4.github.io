---
layout: post
title: "[java] 자바 API를 사용한 스파크 프로그래밍"
description: " "
date: 2023-11-28
tags: [java]
comments: true
share: true
---

## 목차
1. [스파크 개요](#1-스파크-개요)
2. [스파크 자바 API](#2-스파크-자바-API)
3. [스파크 DataFrame](#3-스파크-DataFrame)
4. [스파크 RDD](#4-스파크-RDD)
5. [참고 자료](#5-참고-자료)

## 1. 스파크 개요
스파크(Spark)는 대규모 데이터 처리를 위한 고성능 분산 처리 시스템입니다. 스파크는 다양한 언어로 작성된 API를 지원하며, 자바 또한 그 중 하나입니다. 스파크 자바 API를 사용하면 자바로 스파크를 프로그래밍할 수 있습니다.

## 2. 스파크 자바 API
스파크 자바 API는 자바에서 스파크 애플리케이션을 작성하기 위한 클래스와 메서드를 제공합니다. 스파크 애플리케이션을 작성할 때는 스파크 세션 생성, 데이터 입력 및 출력, 데이터 처리 등 다양한 작업을 수행할 수 있습니다.

자바 API를 사용하여 스파크 애플리케이션을 작성하는 예제 코드는 다음과 같습니다:

```java
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;

public class SparkApp {
  public static void main(String[] args) {
    // 스파크 세션 생성
    SparkSession spark = SparkSession.builder()
      .appName("SparkApp")
      .getOrCreate();

    // 데이터 입력
    Dataset<Row> data = spark.read()
      .format("csv")
      .option("header", "true")
      .load("input.csv");

    // 데이터 처리
    Dataset<Row> result = data.filter("age > 30")
      .groupBy("gender")
      .count();

    // 결과 출력
    result.show();

    // 스파크 세션 종료
    spark.stop();
  }
}
```

위의 예제 코드는 스파크 세션을 생성한 후 CSV 파일을 읽어들여 데이터를 처리하고 결과를 출력하는 간단한 스파크 애플리케이션입니다.

## 3. 스파크 DataFrame
스파크 DataFrame은 구조화된 데이터를 처리하기 위한 API입니다. DataFrame은 자바에서도 사용할 수 있으며, SQL 스타일의 쿼리나 함수를 사용하여 데이터를 처리할 수 있습니다.

DataFrame을 이용한 스파크 애플리케이션 작성 방법은 다음과 같습니다:

```java
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class SparkDataFrameApp {
  public static void main(String[] args) {
    // 스파크 세션 생성
    SparkSession spark = SparkSession.builder()
      .appName("SparkDataFrameApp")
      .getOrCreate();

    // 데이터 입력
    Dataset<Row> data = spark.read()
      .format("csv")
      .option("header", "true")
      .load("input.csv");

    // 데이터 처리
    Dataset<Row> result = data.select("name", "age")
      .filter("age > 30");

    // 결과 출력
    result.show();

    // 스파크 세션 종료
    spark.stop();
  }
}
```

위의 예제 코드는 DataFrame을 이용하여 CSV 파일의 특정 컬럼을 선택하고 조건에 맞는 행을 필터링한 후 결과를 출력하는 스파크 애플리케이션입니다.

## 4. 스파크 RDD
스파크 RDD(Resilient Distributed Dataset)는 분산 데이터 처리를 위한 핵심 데이터 구조입니다. RDD는 자바에서도 사용할 수 있으며, 다양한 연산을 지원합니다.

스파크 RDD를 이용한 애플리케이션 작성 방법은 다음과 같습니다:

```java
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

public class SparkRDDApp {
  public static void main(String[] args) {
    // 스파크 컨텍스트 생성
    JavaSparkContext sc = new JavaSparkContext();

    // 데이터 입력
    JavaRDD<String> data = sc.textFile("input.txt");

    // 데이터 처리
    JavaRDD<String> result = data.filter(line -> line.contains("spark"));

    // 결과 출력
    result.foreach(System.out::println);

    // 스파크 컨텍스트 종료
    sc.stop();
  }
}
```

위의 예제 코드는 RDD를 이용하여 텍스트 파일에서 특정 문자열을 필터링한 후 결과를 출력하는 스파크 애플리케이션입니다.

## 5. 참고 자료
- [스파크 공식 문서](https://spark.apache.org/documentation.html)
- [스파크 자바 API 문서](https://spark.apache.org/docs/latest/api/java/index.html)
- [스파크 자바 예제 코드](https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples)