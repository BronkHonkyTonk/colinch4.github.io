---
layout: post
title: "[swift] Swift 음성인식"
description: " "
date: 2023-11-28
tags: [swift]
comments: true
share: true
---

Swift를 사용하여 음성인식 기능을 구현하는 방법을 알아보겠습니다.

## 음성인식 API

iOS의 음성인식 기능은 `Speech.framework`를 사용하여 구현할 수 있습니다. 이 프레임워크를 사용하면 사용자의 음성을 텍스트로 변환할 수 있습니다.

### 음성인식 권한 요청

먼저, 사용자의 권한을 얻기 위해 `Info.plist` 파일에 다음 키를 추가해야 합니다.

```xml
<key>NSSpeechRecognitionUsageDescription</key>
<string>음성인식 사용을 위해 권한이 필요합니다.</string>
```

위와 같이 키와 설명을 추가하면 앱이 사용자에게 권한을 요청할 수 있습니다.

### 음성인식 구현

음성인식을 시작하기 위해 다음과 같은 단계를 따라야 합니다.

1. `SFSpeechRecognizer` 인스턴스 생성
2. 인식할 언어 설정
3. 인식 요청 생성
4. 음성인식 시작
5. 음성 인식 결과 처리

```swift
import Speech

class SpeechRecognitionManager {

    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ko-KR"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()

    func startRecording() throws {
        guard let recognizer = speechRecognizer else {
              // 음성인식을 지원하지 않는 디바이스의 경우 처리
              return
        }

        if !recognizer.isAvailable {
              // 음성인식을 사용할 수 없는 경우 처리
              return
        }

        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(AVAudioSession.Category.record)
        try audioSession.setMode(AVAudioSession.Mode.measurement)
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)

        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            fatalError("Unable to create speech recognition request")
        }

        recognitionTask = recognizer.recognitionTask(with: recognitionRequest) { result, error in
            if let result = result {
                let transcription = result.bestTranscription.formattedString
                // 음성인식 결과 처리
                print(transcription)
            }

            if let error = error {
                // 음성인식 오류 처리
                print(error.localizedDescription)
            }
        }

        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            self.recognitionRequest?.append(buffer)
        }

        audioEngine.prepare()
        try audioEngine.start()

        // 음성인식 시작
    }

    func stopRecording() {
        audioEngine.stop()
        recognitionRequest?.endAudio()
    }
}
```

위 코드는 간단한 음성인식 매니저 클래스입니다. `startRecording()` 메서드를 호출하면 음성인식이 시작되고, `stopRecording()` 메서드를 호출하면 인식을 종료합니다.

### 음성인식 결과 처리

`recognitionTask`의 `result` 파라미터에는 음성인식 결과가 포함되어 있습니다. 이를 통해 텍스트로 변환된 음성을 얻을 수 있습니다.

### 참고 자료
- [Apple Developer Documentation - Speech](https://developer.apple.com/documentation/speech)

음성인식 기능을 Swift로 구현하는 방법을 살펴보았습니다. 음성인식을 활용하여 사용자와 보다 효율적으로 상호작용할 수 있는 앱을 개발해보세요!