---
layout: post
title: "[java] Jsoup을 사용하여 웹페이지 링크 크롤링하기"
description: " "
date: 2023-11-15
tags: [java]
comments: true
share: true
---

> 이번 포스트에서는 Jsoup 라이브러리를 사용하여 Java 언어로 웹페이지 링크를 크롤링하는 방법에 대해 알아보겠습니다.

## Jsoup이란?

Jsoup은 Java 언어로 웹페이지를 파싱하고 조작할 수 있는 간단하고 효과적인 라이브러리입니다. HTML 요소를 선택하고 속성, 텍스트 등을 추출하거나 변경할 수 있습니다.

## Jsoup 라이브러리 추가

먼저, Maven이나 Gradle과 같은 의존성 관리 도구를 사용하여 Jsoup 라이브러리를 프로젝트에 추가합니다.

Maven:
```xml
<dependencies>
    <dependency>
        <groupId>org.jsoup</groupId>
        <artifactId>jsoup</artifactId>
        <version>1.14.2</version>
    </dependency>
</dependencies>
```

Gradle:
```groovy
dependencies {
    implementation 'org.jsoup:jsoup:1.14.2'
}
```

## 웹페이지 링크 크롤링하기

이제 Jsoup을 사용하여 웹페이지의 링크를 크롤링하는 예제 코드를 살펴보겠습니다.

```java
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class WebCrawler {
    public static void main(String[] args) {
        String url = "https://example.com";

        try {
            Document document = Jsoup.connect(url).get();
            Elements links = document.select("a[href]");

            for (Element link : links) {
                String href = link.attr("href");
                System.out.println(href);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

위 예제 코드는 "https://example.com" 웹페이지에서 링크를 추출하는 기본적인 크롤러입니다. `Jsoup.connect(url).get()`을 사용하여 지정한 URL의 HTML 문서를 가져온 뒤, `document.select("a[href]")`를 사용하여 `a` 태그의 `href` 속성을 가진 요소들을 선택합니다. 그리고 `link.attr("href")`를 사용하여 각 링크의 `href` 속성 값을 출력합니다.

## 실행 결과

위 예제 코드를 실행하면 해당 웹페이지의 링크들이 출력됩니다.

```
https://example.com/page1
https://example.com/page2
https://example.com/page3
```

## 결론

이처럼 Jsoup을 사용하면 Java 언어로 간편하게 웹페이지를 크롤링할 수 있습니다. Jsoup은 다양한 기능과 유연한 API를 제공하므로 웹 데이터 스크래핑 등 다양한 용도로 활용할 수 있습니다.

## 참고 자료

- [Jsoup 공식 홈페이지](https://jsoup.org/)
- [Jsoup 문서](https://jsoup.org/apidocs/)