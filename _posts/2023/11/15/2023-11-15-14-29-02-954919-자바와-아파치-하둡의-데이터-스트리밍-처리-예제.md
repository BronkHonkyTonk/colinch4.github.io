---
layout: post
title: "[java] 자바와 아파치 하둡의 데이터 스트리밍 처리 예제"
description: " "
date: 2023-11-15
tags: [java]
comments: true
share: true
---

아파치 하둡은 대규모 데이터를 처리하기 위한 분산 컴퓨팅 프레임워크로 유명합니다. 하둡은 데이터를 배치 처리하는데 특화되어 있지만, 데이터 스트리밍 처리를 위한 도구들도 제공하고 있습니다. 이번 예제에서는 자바와 아파치 하둡을 사용하여 데이터 스트리밍 처리를 하는 방법에 대해 알아보겠습니다.

## 1. 스트리밍 데이터 처리란

데이터 스트리밍 처리는 실시간으로 데이터를 처리하는 방법입니다. 일반적으로 배치 처리는 정해진 시간에 주기적으로 수행되는 반면, 스트리밍 처리는 데이터가 실시간으로 들어오면 즉시 처리하는 방식입니다. 스트리밍 데이터는 웹 로그, 센서 데이터, 주식 시세 등 실시간으로 발생하는 데이터로 예를 들 수 있습니다. 스트리밍 데이터 처리를 통해 빠른 응답과 실시간 분석이 가능해지므로, 실시간 대시보드, 사이버 보안, 실시간 예측 분석 등에 활용됩니다.

## 2. 자바를 사용한 스트리밍 데이터 처리 예제

자바에서 데이터 스트리밍 처리를 하기 위해 아파치 카프카(Kafka)와 스파크(Streaming)을 함께 사용할 수 있습니다. 카프카는 신뢰성 높은 분산형 메시지 큐로, 스파크는 대규모 데이터 스트림을 실시간으로 처리하는 분산 처리 엔진입니다. 이 두 기술을 조합하여 자바에서 스트리밍 데이터를 처리하는 예제를 살펴보겠습니다.

### 2.1. 의존성 설정

먼저, 프로젝트에 카프카와 스파크 의존성을 추가해야 합니다. Maven을 사용하는 경우, `pom.xml` 파일에 다음과 같이 의존성을 설정할 수 있습니다.

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-streaming-kafka-0-8_2.11</artifactId>
        <version>2.4.7</version>
    </dependency>
</dependencies>
```

### 2.2. 스트리밍 데이터 처리 예제

다음은 스트리밍 데이터를 처리하는 자바 예제 코드입니다.

```java
import org.apache.spark.SparkConf;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.kafka.KafkaUtils;
import scala.Tuple2;

public class StreamingExample {
    public static void main(String[] args) throws InterruptedException {
        // 스파크 설정
        SparkConf conf = new SparkConf().setAppName("StreamingExample");
        JavaStreamingContext jssc = new JavaStreamingContext(conf, Durations.seconds(1));

        // 카프카 설정
        String brokers = "localhost:9092";
        String topic = "streaming-example-topic";
        String groupId = "streaming-example-group";

        // 카프카에서 스트림 생성
        final HashMap<String, String> kafkaParams = new HashMap<>();
        kafkaParams.put("metadata.broker.list", brokers);
        kafkaParams.put("group.id", groupId);
        Set<String> topics = Collections.singleton(topic);
        JavaPairReceiverInputDStream<String, String> stream =
                KafkaUtils.createDirectStream(jssc, String.class, String.class,
                        StringDecoder.class, StringDecoder.class, kafkaParams, topics);

        // 스트림 처리
        JavaDStream<String> lines = stream.map(Tuple2::_2);
        JavaDStream<String> filtered = lines.filter(line -> line.contains("keyword"));

        // 결과 출력
        filtered.print();

        // 스트리밍 시작
        jssc.start();
        jssc.awaitTermination();
    }
}
```

위 코드는 스파크 스트리밍을 초기화하고, 카프카에서 스트림을 생성하여 지정한 키워드를 포함하는 데이터만 필터링하고 결과를 출력하는 예제입니다.

## 3. 결론

이번 예제에서는 자바와 아파치 하둡을 사용하여 스트리밍 데이터 처리하는 방법을 살펴보았습니다. 자바와 스파크를 통해 실시간 대용량 데이터를 처리할 수 있으며, 이를 활용하여 다양한 스트리밍 데이터 처리 애플리케이션을 개발할 수 있습니다.

## 참고 자료
- [아파치 하둡 공식 웹사이트](https://hadoop.apache.org/)
- [아파치 카프카 공식 웹사이트](https://kafka.apache.org/)
- [아파치 스파크 공식 웹사이트](https://spark.apache.org/)