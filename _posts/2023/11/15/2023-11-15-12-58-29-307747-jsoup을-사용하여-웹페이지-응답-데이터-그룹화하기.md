---
layout: post
title: "[java] Jsoup을 사용하여 웹페이지 응답 데이터 그룹화하기"
description: " "
date: 2023-11-15
tags: [java]
comments: true
share: true
---

웹 스크래핑을 하거나 웹페이지의 데이터를 추출할 때, Jsoup은 자바를 사용하여 HTML 문서를 파싱하는 데 사용되는 강력한 라이브러리입니다. 이 기능을 사용하여 웹페이지의 응답 데이터를 그룹화하는 방법에 대해 알아보겠습니다.

## 1. Jsoup 라이브러리 추가하기

먼저, 프로젝트에 Jsoup 라이브러리를 추가해야 합니다. 이를 위해 Maven이나 Gradle과 같은 의존성 관리 도구를 사용할 수 있습니다. 아래는 Maven을 사용하는 경우, `pom.xml`에 Jsoup 의존성을 추가하는 과정입니다.

```xml
<dependencies>
    <dependency>
        <groupId>org.jsoup</groupId>
        <artifactId>jsoup</artifactId>
        <version>1.13.1</version>
    </dependency>
</dependencies>
```

## 2. 웹페이지 데이터 가져오기

다음으로, Jsoup을 사용하여 웹페이지의 응답 데이터를 가져옵니다. 예를 들어, 다음과 같은 코드를 사용하여 "https://example.com" 웹페이지를 가져올 수 있습니다.

```java
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class WebScrapper {

    public static void main(String[] args) {
        try {
            String url = "https://example.com";
            Document doc = Jsoup.connect(url).get();
            
            // 이후 그룹화할 데이터 추출 및 처리
            // ...
            
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

## 3. 데이터 그룹화하기

Jsoup으로 웹페이지 데이터를 가져온 후, 해당 데이터를 그룹화하여 원하는 정보를 추출할 수 있습니다. 예를 들어, 웹페이지의 모든 링크를 추출하여 그룹화하고자 하는 경우, 아래와 같이 코드를 작성할 수 있습니다.

```java
Elements links = doc.select("a");
HashMap<String, String> linkMap = new HashMap<>();

for (Element link : links) {
    String href = link.attr("href");
    String text = link.text();
    
    linkMap.put(text, href);
}

// 그룹화된 데이터 출력
for (Map.Entry<String, String> entry : linkMap.entrySet()) {
    System.out.println(entry.getKey() + ": " + entry.getValue());
}
```

위 코드에서는 Jsoup의 `select` 메소드를 사용하여 "a" 태그를 선택하고, 각 링크의 `href` 속성과 텍스트를 추출하여 `linkMap`이라는 HashMap에 저장합니다. 그 후, `linkMap`의 데이터를 그룹화하여 출력합니다.

## 결론

Jsoup을 사용하여 웹페이지의 응답 데이터를 파싱하고, 원하는 정보를 추출하여 그룹화할 수 있습니다. 이를 활용하여 웹 스크래핑 등 다양한 작업을 수행할 수 있습니다. 자세한 사항은 [Jsoup 공식 홈페이지](https://jsoup.org/)에서 확인할 수 있습니다.