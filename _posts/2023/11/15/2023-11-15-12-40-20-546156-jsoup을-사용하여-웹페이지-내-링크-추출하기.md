---
layout: post
title: "[java] Jsoup을 사용하여 웹페이지 내 링크 추출하기"
description: " "
date: 2023-11-15
tags: [java]
comments: true
share: true
---

이번 글에서는 Java에서 HTML 파싱 라이브러리인 Jsoup을 사용하여 웹페이지 내에 있는 링크를 추출하는 방법에 대해 알아보겠습니다.

## Jsoup이란?

Jsoup은 Java로 작성된 HTML 파싱 라이브러리로써, 웹페이지의 HTML 문서를 파싱하여 DOM 트리를 만들고, DOM 트리에서 필요한 정보를 추출할 수 있습니다.

## 의존성 추가하기

먼저, Jsoup을 사용하기 위해서는 Maven이나 Gradle을 통해 의존성을 추가해야 합니다.

Maven을 사용하는 경우, `pom.xml` 파일에 다음의 의존성을 추가합니다:

```xml
<dependency>
    <groupId>org.jsoup</groupId>
    <artifactId>jsoup</artifactId>
    <version>1.14.3</version>
</dependency>
```

Gradle을 사용하는 경우, `build.gradle` 파일에 다음의 의존성을 추가합니다:

```groovy
implementation 'org.jsoup:jsoup:1.14.3'
```

의존성을 추가한 후에는 빌드 도구를 사용하여 종속성을 가져옵니다.

## 웹페이지 내 링크 추출하기

이제 Jsoup을 사용하여 웹페이지 내에 있는 링크를 추출하는 방법을 알아보겠습니다.

```java
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;
import java.io.IOException;

public class LinkExtractor {
    public static void main(String[] args) {
        String url = "https://example.com"; // 추출할 링크를 포함한 웹페이지 URL
        
        try {
            Document document = Jsoup.connect(url).get();
            Elements links = document.select("a[href]");

            for (Element link : links) {
                String href = link.attr("href");
                System.out.println(href);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

위의 예제 코드에서는 `Jsoup.connect(url).get()`을 사용하여 웹페이지를 연결하고, `document.select("a[href]")`를 사용하여 `<a>` 태그 내에 있는 링크를 선택합니다. 그리고 선택된 링크의 `href` 속성 값을 출력합니다.

실행 결과로는 웹페이지 내에 있는 모든 링크의 URL이 출력됩니다.

## 결론

이렇게 Jsoup을 사용하여 Java로 웹페이지 내에 있는 링크를 추출할 수 있습니다. Jsoup은 간편하게 HTML 파싱을 처리할 수 있는 유용한 라이브러리이므로, 웹 크롤링이나 데이터 수집 등의 작업에 활용할 수 있습니다.

더 자세한 내용은 [Jsoup 공식 문서](https://jsoup.org/)를 참조하시기 바랍니다.