---
layout: post
title: "[java] Jsoup을 사용하여 웹페이지 파싱하기"
description: " "
date: 2023-11-15
tags: [java]
comments: true
share: true
---

Java에서 웹페이지의 HTML을 파싱하고 데이터를 추출하는 작업은 많은 개발자들이 자주 하는 작업 중 하나입니다. 이를 위해 Jsoup이라는 HTML 파싱 라이브러리를 사용할 수 있습니다. Jsoup은 간편하고 직관적인 API를 제공하여 웹페이지 파싱을 손쉽게 할 수 있습니다.

## Jsoup 라이브러리 추가하기

먼저 프로젝트에 Jsoup 라이브러리를 추가해야 합니다. 이를 위해 Maven이나 Gradle 같은 의존성 관리 도구를 사용하거나, 수동으로 JAR 파일을 다운로드하여 프로젝트에 추가할 수 있습니다.

Maven을 사용하는 경우, `pom.xml` 파일에 다음 의존성을 추가하세요:

```xml
<dependency>
    <groupId>org.jsoup</groupId>
    <artifactId>jsoup</artifactId>
    <version>1.14.3</version>
</dependency>
```

Gradle을 사용하는 경우, `build.gradle` 파일에 다음 의존성을 추가하세요:

```groovy
implementation 'org.jsoup:jsoup:1.14.3'
```

## Jsoup을 사용하여 웹페이지 파싱하기

Jsoup을 사용하여 웹페이지를 파싱하는 예제를 살펴보겠습니다. 아래는 간단한 예제 코드입니다.

```java
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class WebPageParser {
    public static void main(String[] args) throws Exception {
        // 웹페이지 URL 지정
        String url = "https://example.com";

        // Jsoup을 사용하여 웹페이지 가져오기
        Document doc = Jsoup.connect(url).get();

        // 웹페이지의 제목 가져오기
        String title = doc.title();
        System.out.println("Title: " + title);

        // 웹페이지의 모든 링크 가져오기
        Elements links = doc.select("a[href]");
        for (Element link : links) {
            String href = link.attr("href");
            System.out.println("Link: " + href);
        }

        // 웹페이지의 특정 요소 가져오기
        Element element = doc.getElementById("id");
        System.out.println("Element: " + element.text());
    }
}
```

위 예제 코드에서는 `Jsoup.connect(url).get()` 메소드를 사용하여 웹페이지를 가져오고, `doc` 객체에 저장합니다. 그리고 `doc` 객체를 사용하여 웹페이지의 제목, 링크, 특정 요소 등을 추출합니다.

## 결론

이제 Java에서 Jsoup을 사용하여 웹페이지를 파싱하는 방법을 알아보았습니다. Jsoup은 강력하고 유용한 도구이며, 웹 크롤링이나 데이터 수집과 같은 작업에 사용할 수 있습니다. 자세한 내용은 [Jsoup 공식 문서](https://jsoup.org/)를 참조하세요.