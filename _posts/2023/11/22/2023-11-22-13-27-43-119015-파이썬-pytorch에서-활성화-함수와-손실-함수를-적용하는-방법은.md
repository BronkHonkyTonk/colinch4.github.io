---
layout: post
title: "[python] 파이썬 PyTorch에서 활성화 함수와 손실 함수를 적용하는 방법은?"
description: " "
date: 2023-11-22
tags: [python]
comments: true
share: true
---

PyTorch는 딥러닝 모델을 구성하는데 사용되는 많은 기능들을 제공합니다. 이 중에서 가장 중요한 것은 활성화 함수와 손실 함수입니다. 이 블로그는 PyTorch에서 활성화 함수와 손실 함수를 어떻게 적용하는지에 대해 알려드리겠습니다.

#### 활성화 함수 (Activation Function) 적용

파이썬 PyTorch에서는 다양한 활성화 함수를 제공합니다. 이 중 몇 가지 대표적인 함수들을 살펴보겠습니다.

##### 시그모이드 (Sigmoid) 함수

```python
import torch
import torch.nn as nn

sigmoid = nn.Sigmoid()
output = sigmoid(input)
```

여기서 `input`은 모델의 출력값이며, `output`은 시그모이드 함수를 통과한 결과입니다.

##### 렐루 (ReLU) 함수

```python
relu = nn.ReLU()
output = relu(input)
```

##### 소프트맥스 (Softmax) 함수

```python
softmax = nn.Softmax(dim=1)
output = softmax(input)
```

#### 손실 함수 (Loss Function) 적용

파이썬 PyTorch에서도 다양한 손실 함수를 사용할 수 있습니다. 다음은 몇 가지 대표적인 함수들입니다.

##### 평균 제곱 오차 (Mean Squared Error, MSE)

```python
criterion = nn.MSELoss()
loss = criterion(input, target)
```

여기서 `input`은 모델의 출력값이고, `target`은 정답값입니다. `loss`는 입력과 정답의 평균 제곱 오차를 계산한 결과입니다.

##### 교차 엔트로피 (Cross Entropy)

```python
criterion = nn.CrossEntropyLoss()
loss = criterion(input, target)
```

여기서 `input`은 모델의 출력값이고, `target`은 정답 레이블입니다. `loss`는 교차 엔트로피를 계산한 결과입니다.

이렇게 PyTorch에서 활성화 함수와 손실 함수를 적용할 수 있습니다. 이 외에도 다양한 함수들이 존재하니, 필요에 따라 적절한 함수를 선택하여 사용하시면 됩니다.

##### 참고 자료

- PyTorch 공식 문서: [활성화 함수](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)
- PyTorch 공식 문서: [손실 함수](https://pytorch.org/docs/stable/nn.functional.html#loss-functions)