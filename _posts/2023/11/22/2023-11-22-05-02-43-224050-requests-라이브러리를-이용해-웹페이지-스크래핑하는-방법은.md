---
layout: post
title: "[python] Requests 라이브러리를 이용해 웹페이지 스크래핑하는 방법은?"
description: " "
date: 2023-11-22
tags: [python]
comments: true
share: true
---

스크래핑은 웹페이지의 내용을 가져와 필요한 정보를 추출하는 작업을 의미합니다. Python에서는 `Requests` 라이브러리를 사용하여 웹페이지 스크래핑을 간단하게 수행할 수 있습니다.

## Requests 라이브러리 설치

먼저, `Requests` 라이브러리를 설치해야 합니다. 다음 명령어를 사용하여 설치할 수 있습니다.

```bash
$ pip install requests
```

## 웹페이지 가져오기

`Requests` 라이브러리를 사용하여 웹페이지를 가져오려면 `get` 메서드를 사용합니다. 다음은 간단한 예제 코드입니다.

```python
import requests

url = 'http://www.example.com'
response = requests.get(url)

# 응답코드 확인
if response.status_code == 200:
    # 웹페이지 내용 출력
    print(response.text)
else:
    print('웹페이지를 가져오는데 실패했습니다.')
```

## 웹페이지 내용 파싱

웹페이지를 가져왔다면, 이제 필요한 정보를 추출하기 위해 웹페이지 내용을 파싱해야 합니다. 데이터를 추출하기 위해 `BeautifulSoup`와 같은 HTML 파싱 라이브러리를 함께 사용할 수 있습니다.

```python
from bs4 import BeautifulSoup

# 웹페이지 내용 파싱
soup = BeautifulSoup(response.text, 'html.parser')

# 원하는 정보 추출
title = soup.title.text
print('웹페이지 제목:', title)
```

## 참고 자료

- Requests 라이브러리 공식 문서: [https://requests.readthedocs.io/en/latest/](https://requests.readthedocs.io/en/latest/)
- BeautifulSoup 라이브러리 공식 문서: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

위의 예제 코드와 참고 자료를 참고하여 `Requests` 라이브러리를 사용해 웹페이지 스크래핑을 수행해 보세요!