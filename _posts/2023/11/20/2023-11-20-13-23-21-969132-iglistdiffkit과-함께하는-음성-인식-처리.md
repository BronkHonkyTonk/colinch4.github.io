---
layout: post
title: "[swift] IGListDiffKit과 함께하는 음성 인식 처리"
description: " "
date: 2023-11-20
tags: [swift]
comments: true
share: true
---

이번 블로그에서는 IGListDiffKit을 사용하여 iOS 애플리케이션에서 음성 인식 처리를 어떻게 구현하는지 알아보겠습니다.

IGListDiffKit은 UICollectionView나 UITableView에서 데이터 변화를 효율적으로 처리하기 위한 라이브러리입니다. 이 라이브러리를 사용하면 데이터의 변경사항을 효율적으로 감지하고 UI를 업데이트할 수 있습니다.

이제 음성 인식 처리를 위해 어떻게 IGListDiffKit을 사용할 수 있는지 알아보겠습니다.

## 음성 입력 받기

음성 인식을 위해 iOS의 Speech framework를 사용할 수 있습니다. Speech framework는 사용자의 음성을 텍스트로 변환해주는 기능을 제공합니다.

```swift
import Speech

let audioEngine = AVAudioEngine()
let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
let request = SFSpeechAudioBufferRecognitionRequest()
var recognitionTask: SFSpeechRecognitionTask?

func startRecording() throws {
    let node = audioEngine.inputNode
    let recordingFormat = node.outputFormat(forBus: 0)
    
    recognitionTask?.cancel()
    self.recognitionTask = nil
    
    let recordingBlock = { [unowned self] (buffer: AVAudioPCMBuffer, when: AVAudioTime) in
        self.request.append(buffer)
    }
    
    audioEngine.inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat, block: recordingBlock)
    
    audioEngine.prepare()
    try audioEngine.start()
    
    recognitionTask = speechRecognizer?.recognitionTask(with: request, resultHandler: { [unowned self] (result, error) in
        if let result = result {
            let bestString = result.bestTranscription.formattedString
            // 변환된 텍스트 처리
            
            // IGListDiffKit를 이용해 UI 업데이트
        }
    })
}

func stopRecording() {
    audioEngine.stop()
    recognitionTask?.finish()
    audioEngine.inputNode.removeTap(onBus: 0)
}
```

위 코드에서 `startRecording()` 함수를 호출하면 음성 입력을 시작하고, `stopRecording()` 함수를 호출하면 음성 입력을 종료합니다. 음성 입력이 변환되면 결과가 `resultHandler`로 전달되며, 여기서 IGListDiffKit을 이용해 UI를 업데이트할 수 있습니다.

## IGListDiffKit을 이용한 UI 업데이트

IGListDiffKit을 사용하려면 먼저 데이터 모델을 구성해야 합니다. 음성 입력을 처리하는 동안 생성되는 각 텍스트의 모델을 생성합니다.

```swift
struct SpeechText {
    let text: String
}
```

데이터 모델을 구성했으면 IGListKit의 `ListAdapter`를 사용하여 UI를 업데이트할 수 있습니다.

```swift
import IGListKit

class SpeechViewController: UIViewController {
    
    let adapter = ListAdapter(updater: ListAdapterUpdater(), viewController: nil)
    var speechTexts: [SpeechText] = []
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        adapter.collectionView = collectionView
        adapter.dataSource = self
    }
    
    func updateCollectionView() {
        adapter.performUpdates(animated: true)
    }
}

extension SpeechViewController: ListAdapterDataSource {
    func objects(for listAdapter: ListAdapter) -> [ListDiffable] {
        return speechTexts
    }
    
    func listAdapter(_ listAdapter: ListAdapter, sectionControllerFor object: Any) -> ListSectionController {
        return SpeechTextSectionController()
    }
    
    func emptyView(for listAdapter: ListAdapter) -> UIView? {
        return nil
    }
}
```

위 코드에서 `SpeechViewController`는 데이터 소스로 `speechTexts`를 사용하고, `ListAdapter`를 이용해 컬렉션 뷰의 UI를 업데이트합니다. `SectionController`를 구현하여 데이터 모델과 UI를 연결해주는 역할을 합니다.

## 결론

이제 IGListDiffKit을 사용하여 iOS 애플리케이션에서 음성 인식 처리를 구현하는 방법을 알아봤습니다. IGListDiffKit을 이용하면 데이터 변화를 효율적으로 처리하고, UICollectionView나 UITableView의 UI를 업데이트할 수 있습니다. 음성 인식 처리를 위해 IGListDiffKit을 사용하는 경우, 데이터 모델을 구성하고 SectionController를 이용해 UI를 연결해주어야 합니다.

더 많은 정보를 원한다면 [IGListDiffKit 공식 문서](https://github.com/Instagram/IGListKit)를 참조하시기 바랍니다.