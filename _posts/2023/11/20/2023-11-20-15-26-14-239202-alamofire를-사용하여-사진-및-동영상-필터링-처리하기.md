---
layout: post
title: "[swift] Alamofire를 사용하여 사진 및 동영상 필터링 처리하기"
description: " "
date: 2023-11-20
tags: [swift]
comments: true
share: true
---

이번 글에서는 Swift에서 Alamofire를 사용하여 사진 및 동영상을 필터링하는 방법에 대해 알아보겠습니다. Alamofire는 Swift에서 네트워크 요청을 보내고 받기 위해 많이 사용되는 라이브러리입니다. 필터링은 주어진 이미지나 동영상에 특정한 변형을 적용하여 결과물을 생성하는 작업을 의미합니다.

## 1. Alamofire 설치하기

먼저 Alamofire를 설치해야 합니다. 프로젝트의 Podfile에 다음과 같이 추가해주세요.

```ruby
pod 'Alamofire'
```

그리고 Terminal을 열고 `pod install` 명령어를 실행하여 Alamofire를 프로젝트에 추가합니다.

## 2. 이미지 필터링하기

이미지를 필터링하는 방법은 다양합니다. 우리는 Alamofire를 사용하여 이미지 URL을 다운로드하고, 필터링을 적용한 뒤 결과를 보여줄 것입니다.

```swift
import Alamofire
import UIKit

func filterImage(url: URL, filter: CIFilter, completion: @escaping (UIImage?) -> Void) {
    Alamofire.request(url).responseData { response in
        if let data = response.data,
           let originalImage = UIImage(data: data),
           let ciImage = CIImage(image: originalImage) {
            filter.setValue(ciImage, forKey: kCIInputImageKey)
            if let outputImage = filter.outputImage {
                let context = CIContext()
                if let cgImage = context.createCGImage(outputImage, from: outputImage.extent) {
                    let filteredImage = UIImage(cgImage: cgImage)
                    completion(filteredImage)
                } else {
                    completion(nil)
                }
            } else {
                completion(nil)
            }
        } else {
            completion(nil)
        }
    }
}

let imageURL = URL(string: "https://example.com/image.jpg")!
let filter = CIFilter(name: "CISepiaTone")!

filterImage(url: imageURL, filter: filter) { filteredImage in
    if let filteredImage = filteredImage {
        // 필터링된 이미지를 이용하여 뭔가를 수행합니다.
    } else {
        // 이미지 필터링에 실패한 경우 처리합니다.
    }
}
```

위의 코드에서는 Alamofire를 사용하여 이미지 URL로부터 데이터를 받아온 다음, CIFilter를 사용하여 이미지에 필터링을 적용하고 결과물을 반환합니다.

## 3. 동영상 필터링하기

동영상을 필터링하는 방법은 이미지와 유사하게 작동하지만, 처리하는 대상이 동영상 파일이기 때문에 조금 다를 수 있습니다.

```swift
import Alamofire
import AVFoundation

func filterVideo(url: URL, filter: CIFilter, completion: @escaping (AVPlayerItem?) -> Void) {
    Alamofire.request(url).responseData { response in
        if let data = response.data {
            let tempURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent("temp.mp4")
            try? data.write(to: tempURL)
            
            let asset = AVURLAsset(url: tempURL)
            let composition = AVMutableComposition()
            
            guard let videoTrack = asset.tracks(withMediaType: .video).first,
                  let audioTrack = asset.tracks(withMediaType: .audio).first else {
                completion(nil)
                return
            }
            
            let videoCompositionTrack = composition.addMutableTrack(withMediaType: .video, preferredTrackID: kCMPersistentTrackID_Invalid)
            let audioCompositionTrack = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid)
            
            try? videoCompositionTrack?.insertTimeRange(CMTimeRange(start: .zero, duration: asset.duration), of: videoTrack, at: .zero)
            try? audioCompositionTrack?.insertTimeRange(CMTimeRange(start: .zero, duration: asset.duration), of: audioTrack, at: .zero)
            
            let videoComposition = AVMutableVideoComposition()
            videoComposition.frameDuration = CMTime(value: 1, timescale: 30)
            videoComposition.renderSize = videoTrack.naturalSize
            
            let videoLayer = CALayer()
            videoLayer.frame = CGRect(x: 0, y: 0, width: videoComposition.renderSize.width, height: videoComposition.renderSize.height)
            
            let filterLayer = CIFilterLayer(filter: filter)
            filterLayer.frame = videoLayer.bounds
            filterLayer.backgroundFilters = [filter]
            
            videoLayer.addSublayer(filterLayer)
            
            let instruction = AVMutableVideoCompositionInstruction()
            instruction.timeRange = CMTimeRange(start: .zero, duration: asset.duration)
            instruction.layerInstructions = [AVMutableVideoCompositionLayerInstruction(assetTrack: videoCompositionTrack!)]

            videoComposition.instructions = [instruction]
            videoComposition.animationTool = AVVideoCompositionCoreAnimationTool(postProcessingAsVideoLayer: videoLayer, in: videoLayer)
            
            let exporter = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetHighestQuality)
            let outputURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent("output.mp4")
            exporter?.outputURL = outputURL
            exporter?.outputFileType = .mp4
            exporter?.videoComposition = videoComposition
            
            exporter?.exportAsynchronously {
                DispatchQueue.main.async {
                    if exporter?.status == .completed {
                        let playerItem = AVPlayerItem(url: outputURL)
                        completion(playerItem)
                    } else {
                        completion(nil)
                    }
                }
            }
        } else {
            completion(nil)
        }
    }
}

let videoURL = URL(string: "https://example.com/video.mp4")!
let filter = CIFilter(name: "CIColorControls")!

filterVideo(url: videoURL, filter: filter) { playerItem in
    if let playerItem = playerItem {
        // 필터링된 동영상을 재생하거나 처리합니다.
    } else {
        // 동영상 필터링에 실패한 경우 처리합니다.
    }
}
```

위의 코드에서는 Alamofire를 사용하여 동영상 URL로부터 데이터를 받아와서 임시 파일로 저장한 다음, 필터링을 적용한 동영상을 내보내는 과정을 수행합니다.

## 마무리

이 글에서는 Swift에서 Alamofire를 사용하여 사진 및 동영상을 필터링하는 방법에 대해 살펴보았습니다. Alamofire를 사용하면 네트워크 요청을 쉽게 처리할 수 있으며, CIFilter를 사용하여 이미지와 동영상에 다양한 필터를 적용할 수 있습니다. 필요한 경우, 추가적인 애니메이션 효과나 사용자 지정 필터를 적용할 수도 있습니다. 자세한 내용은 [Alamofire](https://github.com/Alamofire/Alamofire)와 [CIFilter](https://developer.apple.com/documentation/coreimage/cifilter) 관련 문서를 참고하시기 바랍니다.