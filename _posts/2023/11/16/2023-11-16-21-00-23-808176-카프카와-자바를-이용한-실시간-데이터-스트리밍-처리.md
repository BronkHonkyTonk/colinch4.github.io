---
layout: post
title: "[java] 카프카와 자바를 이용한 실시간 데이터 스트리밍 처리"
description: " "
date: 2023-11-16
tags: [java]
comments: true
share: true
---

실시간 데이터 스트리밍 처리는 현대의 데이터 처리 시스템에서 매우 중요한 역할을 합니다. 많은 기업들이 대용량의 데이터를 실시간으로 처리하고 분석하기 위해 다양한 도구와 기술을 사용하고 있습니다. 이 중에서도 카프카와 자바는 가장 일반적으로 사용되는 조합입니다.

## 카프카란?

카프카는 LinkedIn에서 개발한 분산 메시징 시스템입니다. 카프카는 주로 대용량의 실시간 데이터 스트림을 처리하기 위해 사용되며, 이벤트 드리븐 아키텍처를 구현하는 데 적합합니다. 카프카는 대량의 데이터를 안정적이고 확장 가능하게 처리하며, 토픽(topic)이라는 단위로 데이터를 구분하여 처리합니다.

## 자바로 카프카 데이터 스트림 처리하기

카프카는 여러 가지 프로그래밍 언어로 사용할 수 있지만, 자바는 가장 흔히 사용되는 언어입니다. 자바에서 카프카를 사용하는 방법은 간단합니다. 먼저 카프카 클라이언트를 Maven 또는 Gradle과 같은 의존성 관리 도구를 사용하여 프로젝트에 추가해야 합니다.

```java
dependencies {
    implementation 'org.apache.kafka:kafka-clients:2.7.0'
}
```

카프카 클라이언트를 프로젝트에 추가한 후, 아래와 같은 코드를 사용하여 데이터를 생산(produce)하고 소비(consume)할 수 있습니다.

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.clients.consumer.*;

public class KafkaStreamingExample {
    private static final String KAFKA_TOPIC = "my_topic";
    private static final String KAFKA_BOOTSTRAP_SERVERS = "localhost:9092";

    public static void main(String[] args) {
        // Kafka Producer
        Properties producerProps = new Properties();
        producerProps.put("bootstrap.servers", KAFKA_BOOTSTRAP_SERVERS);
        producerProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        producerProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer<String, String> producer = new KafkaProducer<>(producerProps);
        ProducerRecord<String, String> record = new ProducerRecord<>(KAFKA_TOPIC, "key", "value");
        producer.send(record);
        producer.close();

        // Kafka Consumer
        Properties consumerProps = new Properties();
        consumerProps.put("bootstrap.servers", KAFKA_BOOTSTRAP_SERVERS);
        consumerProps.put("group.id", "my_consumer_group");
        consumerProps.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        consumerProps.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(consumerProps);
        consumer.subscribe(Collections.singleton(KAFKA_TOPIC));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            // 데이터 처리 로직 작성
            for (ConsumerRecord<String, String> record : records) {
                System.out.printf("partition = %d, offset = %d, key = %s, value = %s%n",
                        record.partition(), record.offset(), record.key(), record.value());
            }
        }
    }
}
```

위의 예제 코드는 카프카 프로듀서와 컨슈머(소비자)를 생성하고, 데이터를 생산하고 소비하는 간단한 방법을 보여줍니다.

## 결론

카프카와 자바를 결합하여 실시간 데이터 스트리밍 처리를 수행하는 것은 매우 강력하고 효율적인 방법입니다. 자바의 다양한 라이브러리와 카프카의 확장 가능성을 활용하여 대용량의 데이터를 신속하게 처리하고 분석할 수 있습니다. 카프카와 자바를 사용하여 실시간 데이터 스트리밍 처리에 도전해보세요!

참고 자료:
- [카프카 공식 홈페이지](https://kafka.apache.org/)
- [카프카 클라이언트 JavaDocs](https://kafka.apache.org/27/javadoc/index.html)