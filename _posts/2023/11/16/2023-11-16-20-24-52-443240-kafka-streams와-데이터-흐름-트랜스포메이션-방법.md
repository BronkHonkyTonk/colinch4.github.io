---
layout: post
title: "[java] Kafka Streams와 데이터 흐름 트랜스포메이션 방법"
description: " "
date: 2023-11-16
tags: [java]
comments: true
share: true
---

Kafka Streams는 실시간 데이터 스트리밍 애플리케이션을 구축하기 위한 클라이언트 라이브러리입니다. 이 라이브러리를 사용하면 Apache Kafka의 토픽에서 데이터를 읽어들여 처리하고, 다른 토픽에 결과를 전달할 수 있습니다. 이번 글에서는 Kafka Streams를 사용하여 데이터 흐름을 트랜스포메이션하는 방법에 대해 알아보겠습니다.

## 1. Kafka Streams 기본 개념

Kafka Streams는 흐름을 통해 들어오는 데이터를 처리하는 애플리케이션을 작성하기 위한 기본 개념을 제공합니다. 여기에는 다음과 같은 주요 개념들이 포함됩니다.

### 1.1. Topology

Topology는 데이터 흐름을 정의하는 개념입니다. 애플리케이션의 데이터 처리 로직을 정의하는 그래프로, Kafka Streams에서는 여러 개의 프로세서 노드와 스트림 처리 노드를 포함합니다.

### 1.2. Processor

Processor는 Topology에서 정의한 데이터 처리 로직을 구현한 개념입니다. 메시지를 처리하고 결과를 다른 프로세서에 전달하는 역할을 수행합니다. Kafka Streams에서는 Processor API를 사용하여 Processor를 구현할 수 있습니다.

### 1.3. Stream

Stream은 Kafka의 토픽에서 수신한 데이터를 나타내는 개념입니다. 데이터의 흐름을 나타내며, Stream API를 사용하여 토픽에서 데이터를 읽고 처리할 수 있습니다.

### 1.4. Table

Table은 Kafka의 토픽과 유사한 개념으로, 업데이트 가능한 상태를 갖는 데이터 스토어입니다. Table API를 사용하여 Table에 데이터를 쓰고 읽을 수 있습니다.

## 2. 데이터 흐름 트랜스포메이션 방법

데이터 흐름 트랜스포메이션은 Kafka Streams를 사용하여 수신한 데이터를 가공하고 결과를 다른 토픽에 전달하는 과정입니다. 이를 위해 다양한 트랜스포메이션 메서드를 활용할 수 있습니다. 몇 가지 예제를 살펴보겠습니다.

### 2.1. Filtering

데이터 흐름 중 일부만을 선택하여 처리해야 하는 경우 Filtering을 사용할 수 있습니다. 예를 들어, 특정 조건을 만족하는 데이터만을 처리하고자 할 때 filter 메서드를 사용합니다.

```java
KStream<String, String> inputStream = builder.stream("input-topic");
KStream<String, String> filteredStream = inputStream.filter((key, value) -> value.contains("filter"));
filteredStream.to("filtered-topic");
```

### 2.2. Mapping

데이터 흐름의 형태를 변환하기 위해 Mapping을 사용할 수 있습니다. 예를 들어, 각 데이터를 대문자로 변환하고자 할 때 mapValues 메서드를 사용합니다.

```java
KStream<String, String> inputStream = builder.stream("input-topic");
KStream<String, String> mappedStream = inputStream.mapValues(value -> value.toUpperCase());
mappedStream.to("mapped-topic");
```

### 2.3. Aggregating

데이터 흐름의 데이터를 집계하기 위해 Aggregating을 사용할 수 있습니다. 예를 들어, 특정 키로 그룹화된 데이터의 합계를 계산하고자 할 때 groupByKey와 reduce 메서드를 사용합니다.

```java
KStream<String, Integer> inputStream = builder.stream("input-topic");
KGroupedStream<String, Integer> groupedStream = inputStream.groupByKey();
KTable<String, Integer> aggregatedTable = groupedStream.reduce((value1, value2) -> value1 + value2);
aggregatedTable.toStream().to("aggregated-topic");
```

## 3. 결론

Kafka Streams를 사용하여 데이터 흐름을 트랜스포메이션하는 방법에 대해 알아보았습니다. Filtering, Mapping, Aggregating 같은 다양한 트랜스포메이션 메서드를 활용하여 데이터를 전처리하고 가공할 수 있습니다. 이를 통해 효율적이고 실시간으로 데이터를 처리하는 분산 데이터 처리 애플리케이션을 개발할 수 있습니다.

더 자세한 내용은 [Kafka Streams 문서](https://kafka.apache.org/documentation/streams/)를 참조하시기 바랍니다.