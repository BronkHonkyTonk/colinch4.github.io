---
layout: post
title: "[java] 카프카와 자바를 이용한 이벤트 기반 분산 시스템 구축하기"
description: " "
date: 2023-11-16
tags: [java]
comments: true
share: true
---

분산 시스템은 대규모 데이터 처리 및 이벤트 기반 아키텍처를 구현하는 데 매우 유용합니다. 이러한 경우에 카프카와 자바를 함께 사용하여 효과적인 분산 시스템을 구축할 수 있습니다. 

## 카프카란 무엇인가?

카프카는 분산 스트리밍 플랫폼으로, 대용량의 실시간 데이터를 안정적으로, 효율적으로 처리할 수 있습니다. 카프카는 여러 개의 브로커로 구성되어 있으며, 이벤트를 토픽으로 분류하여 메시지를 고가용성으로 저장하고 전달합니다.

## 카프카와 자바 연동하기

카프카와 자바를 연동하기 위해 먼저 카프카를 설치하고 실행해야 합니다. 그런 다음, 자바 애플리케이션에서 카프카 클라이언트를 사용하여 메시지를 생성하고 읽을 수 있습니다.

### 카프카 클라이언트 의존성 추가하기

Maven을 사용하여 카프카 클라이언트 의존성을 추가할 수 있습니다. 다음은 `pom.xml` 파일의 예입니다.

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.8.0</version>
</dependency>
```

### 메시지 생성하기

카프카 클라이언트를 사용하여 메시지를 생성하려면 `Producer` 클래스를 사용해야 합니다. 다음은 메시지를 생성하는 간단한 예제입니다.

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import java.util.Properties;

public class KafkaMessageProducer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        String topic = "my_topic";
        String key = "key1";
        String value = "Hello, Kafka!";

        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
        producer.send(record);

        producer.close();
    }
}
```

### 메시지 읽기

메시지를 읽기 위해서는 `Consumer` 클래스를 사용해야 합니다. 다음은 메시지를 읽는 간단한 예제입니다.

```java
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import java.util.Collections;
import java.util.Properties;

public class KafkaMessageConsumer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "my_group");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        Consumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("my_topic"));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Long.MAX_VALUE);
            records.forEach(record -> {
                System.out.println("Key: " + record.key() + ", Value: " + record.value());
            });
        }
    }
}
```

위의 예제에서 `my_topic`은 메시지를 읽을 토픽입니다. 읽은 메시지는 각각의 키(Key)와 값(Value)으로 출력됩니다.

## 결론

이와 같이 카프카와 자바를 함께 사용하여 이벤트 기반 분산 시스템을 구축할 수 있습니다. 카프카는 안정적이고 확장 가능한 분산 스트리밍 플랫폼으로, 대용량 데이터 처리에 매우 유용합니다. 자바 클라이언트를 사용하여 메시지를 생성하고 읽을 수 있으며, 이를 활용하여 다양한 이벤트 처리 로직을 개발할 수 있습니다.

## 참고 자료

- [카프카 공식 문서](https://kafka.apache.org/documentation/)
- [카프카 클라이언트 API](https://kafka.apache.org/28/javadoc/)