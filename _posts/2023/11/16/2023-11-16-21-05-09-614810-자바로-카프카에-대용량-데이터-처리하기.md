---
layout: post
title: "[java] 자바로 카프카에 대용량 데이터 처리하기"
description: " "
date: 2023-11-16
tags: [java]
comments: true
share: true
---

## 소개
카프카는 대용량 실시간 데이터 스트리밍 플랫폼으로 알려져 있습니다. 자바는 가장 인기 있는 프로그래밍 언어 중 하나이며, 카프카와 함께 사용할 때 강력한 기능을 제공합니다. 이번 포스트에서는 자바를 사용하여 카프카에 대용량 데이터를 처리하는 방법에 대해 알아보겠습니다.

## 카프카 클라이언트 의존성 추가하기
자바로 카프카를 사용하기 위해서는 카프카 클라이언트 의존성을 프로젝트에 추가해야 합니다. Maven을 사용한다면, `pom.xml` 파일에 다음과 같이 의존성을 추가할 수 있습니다:

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.8.0</version>
</dependency>
```

Gradle을 사용한다면, `build.gradle` 파일에 다음과 같이 의존성을 추가할 수 있습니다:

```groovy
implementation 'org.apache.kafka:kafka-clients:2.8.0'
```

## 카프카 프로듀서 작성하기
카프카 프로듀서는 메시지를 카프카 토픽으로 보내는 역할을 합니다. 다음은 간단한 예제 코드입니다:

```java
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.KafkaProducer;
import java.util.Properties;

public class KafkaProducerExample {

    public static void main(String[] args) {
        // Kafka 프로듀서 설정
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // Kafka 프로듀서 생성
        Producer<String, String> producer = new KafkaProducer<>(props);

        // 메시지 전송
        String topic = "my-topic";
        String message = "Hello, Kafka!";
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, message);
        producer.send(record);

        // Kafka 프로듀서 종료
        producer.close();
    }
}
```

위의 코드는 localhost에 있는 카프카 브로커로 메시지를 전송하는 간단한 카프카 프로듀서를 생성합니다.

## 카프카 컨슈머 작성하기
카프카 컨슈머는 카프카 토픽으로부터 메시지를 가져오는 역할을 합니다. 다음은 간단한 예제 코드입니다:

```java
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import java.util.Collections;
import java.util.Properties;

public class KafkaConsumerExample {

    public static void main(String[] args) {
        // Kafka 컨슈머 설정
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.deserializer", StringDeserializer.class.getName());
        props.put("value.deserializer", StringDeserializer.class.getName());
        props.put("group.id", "my-group");

        // Kafka 컨슈머 생성
        Consumer<String, String> consumer = new KafkaConsumer<>(props);

        // 구독할 토픽 설정
        String topic = "my-topic";
        consumer.subscribe(Collections.singleton(topic));

        // 메시지 가져오기
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(100);
            records.forEach(record -> {
                System.out.println("Received message: " + record.value());
            });
        }
    }
}
```

위의 코드는 localhost에 있는 카프카 브로커로부터 메시지를 가져와 출력하는 간단한 카프카 컨슈머를 생성합니다.

## 결론
이번 포스트에서는 자바로 카프카에 대용량 데이터를 처리하는 방법에 대해 알아보았습니다. 카프카 클라이언트 의존성을 추가하고, 프로듀서와 컨슈머를 작성하는 방법을 다루었습니다. 카프카를 사용하여 대용량 데이터를 처리하고 실시간 스트리밍을 구현하는 것은 매우 강력한 도구입니다. 앞으로 더 많은 기능과 활용법을 익혀서 멋진 프로젝트를 만들어보세요!

## 참고 자료
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Kafka and Java Tutorial](https://www.baeldung.com/java-kafka)