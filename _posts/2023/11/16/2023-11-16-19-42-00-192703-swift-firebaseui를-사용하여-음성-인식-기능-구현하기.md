---
layout: post
title: "[swift] Swift FirebaseUI를 사용하여 음성 인식 기능 구현하기"
description: " "
date: 2023-11-16
tags: [swift]
comments: true
share: true
---

FirebaseUI는 Firebase를 사용하여 iOS 앱을 빠르게 개발할 수 있도록 도와주는 라이브러리입니다. 이 라이브러리를 사용하여 음성 인식 기능을 구현하는 방법에 대해 알아보겠습니다.

## FirebaseUI 설치하기

FirebaseUI를 사용하기 위해 먼저 Cocoapods를 이용하여 프로젝트에 FirebaseUI를 설치해야 합니다. Podfile에 다음과 같이 FirebaseUI를 추가합니다.

```swift
pod 'FirebaseUI/Google'
```

그리고 터미널에서 다음 명령어를 실행하여 팟을 설치합니다.

```shell
$ pod install
```

## Google 음성 API 설정하기

Google 음성 API를 사용하기 위해 Google Cloud Platform에서 프로젝트를 생성하고 API 키를 발급해야 합니다. [Google Cloud Console](https://console.cloud.google.com/)에 접속하여 새 프로젝트를 생성하고, 음성 API를 활성화하고 API 키를 발급받습니다.

## 음성 인식 구현하기

FirebaseUI에서 제공하는 FirebaseAuthUI를 사용하여 음성 인식 기능을 구현합니다. 먼저, 음성을 입력받을 화면을 구성합니다. UIViewController를 상속받은 SpeechRecognitionViewController 클래스를 생성합니다.

```swift
import UIKit
import Firebase
import FirebaseUI

class SpeechRecognitionViewController: UIViewController {

    // Firebase Auth UI 인스턴스 생성
    var authUI: FUIAuth?

    override func viewDidLoad() {
        super.viewDidLoad()

        // FirebaseUI 인스턴스 초기화
        authUI = FUIAuth.defaultAuthUI()
        authUI?.delegate = self

        // 음성 입력 버튼 추가
        let speechButton = UIButton(type: .system)
        speechButton.setTitle("음성 입력", for: .normal)
        speechButton.addTarget(self, action: #selector(handleSpeechButton), for: .touchUpInside)
        view.addSubview(speechButton)

        // Constraints 설정
        speechButton.translatesAutoresizingMaskIntoConstraints = false
        NSLayoutConstraint.activate([
            speechButton.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            speechButton.centerYAnchor.constraint(equalTo: view.centerYAnchor)
        ])
    }

    @objc func handleSpeechButton() {
        // 음성 인식 시작
        // FirebaseUI를 사용하여 음성 인식 기능을 구현합니다.
    }
}

// Firebase Auth UI delegate 구현
extension SpeechRecognitionViewController: FUIAuthDelegate {
    func authUI(_ authUI: FUIAuth, didSignInWith user: User?, error: Error?) {
        // 사용자 인증 완료 시 처리할 로직 작성
    }
}
```

위의 코드에서는 SpeechRecognitionViewController에서 음성 입력 버튼을 추가하고, 버튼을 누르면 음성 인식이 시작되도록 구현하였습니다.

## 음성 인식 완료 후 처리하기

음성 인식이 완료되면, 할당된 음성 텍스트 데이터를 Firebase에 업로드하고 처리할 수 있습니다. Firebase의 Realtime Database를 사용하여 음성 텍스트를 저장하고 필요한 로직을 추가로 작성할 수 있습니다.

```swift
@objc func handleSpeechButton() {
    SpeechRecognizer.shared.startRecognition { (result, error) in
        if let error = error {
            print("음성 인식 오류: \(error.localizedDescription)")
            return
        }
        
        // 음성 텍스트 업로드
        guard let resultText = result else { return }
        let speechTextRef = Database.database().reference().child("speechText")
        let speechId = speechTextRef.childByAutoId().key
        let speechData = [
            "text": resultText
        ]
        speechTextRef.child(speechId).setValue(speechData) { (error, _) in
            if let error = error {
                print("음성 텍스트 업로드 오류: \(error.localizedDescription)")
            } else {
                print("음성 텍스트 업로드 완료")
            }
        }
        
        // 추가로 처리할 로직
        // 음성 텍스트를 이용한 다양한 로직 추가
    }
}
```

위의 코드에서는 SpeechRecognizer.shared.startRecognition() 메서드를 이용하여 음성 인식을 시작하고, 인식 결과를 Firebase에 업로드합니다. 업로드가 완료되면 추가적인 처리 로직을 작성할 수 있습니다.

이제 음성 인식 기능을 FirebaseUI를 사용하여 구현하는 방법을 알아보았습니다. FirebaseUI를 이용하면 빠르게 음성 인식 기능을 구현할 수 있으며, Firebase의 다른 기능과 함께 사용할 수 있습니다.

## 참고 자료

- [FirebaseUI](https://firebaseopensource.com/projects/firebase/firebaseui-ios/)
- [Google Cloud Console](https://console.cloud.google.com/)