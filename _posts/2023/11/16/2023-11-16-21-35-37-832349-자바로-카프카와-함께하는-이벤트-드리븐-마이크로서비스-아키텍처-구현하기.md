---
layout: post
title: "[java] 자바로 카프카와 함께하는 이벤트 드리븐 마이크로서비스 아키텍처 구현하기"
description: " "
date: 2023-11-16
tags: [java]
comments: true
share: true
---

## 개요
이 글에서는 자바를 사용하여 카프카와 함께하는 이벤트 드리븐 마이크로서비스 아키텍처를 구현하는 방법에 대해 알아보겠습니다. 이 아키텍처는 각각 독립적인 마이크로서비스로 구성되어 있으며, 이벤트를 기반으로 상호작용하고 데이터를 교환합니다. 카프카는 이벤트 브로커로 사용되며, 이벤트를 발행하고 구독하는 역할을 수행합니다.

## 준비물
- JDK 8 이상 설치
- Apache Kafka 설치 (https://kafka.apache.org/downloads)
- Maven 프로젝트 생성

## 카프카 설정
1. 카프카를 다운로드하고 압축을 해제하십시오.
2. `server.properties` 파일을 열고 다음 설정을 수정하십시오.
```
listeners=PLAINTEXT://localhost:9092
auto.create.topics.enable=false
```
3. 카프카를 시작하십시오.
```
bin/kafka-server-start.sh config/server.properties
```

## Maven 의존성 추가
`pom.xml` 파일을 열고 카프카 클라이언트를 추가하십시오.
```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>2.8.0</version>
    </dependency>
</dependencies>
```

## 이벤트 발행
이벤트를 발행하는 프로듀서를 구현해 보겠습니다.

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class EventProducer {

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        String topic = "event-topic";
        String message = "Hello, Kafka!";

        ProducerRecord<String, String> record = new ProducerRecord<>(topic, message);
        producer.send(record);

        producer.close();
    }

}
```

## 이벤트 구독
이벤트를 구독하는 컨슈머를 구현해 보겠습니다.

```java
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

public class EventConsumer {

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "event-group");
        props.put("key.deserializer", StringDeserializer.class);
        props.put("value.deserializer", StringDeserializer.class);

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

        String topic = "event-topic";

        consumer.subscribe(Collections.singleton(topic));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

            records.forEach(record -> {
                System.out.println("Received event: " + record.value());
            });
        }
    }

}
```

## 실행
1. 이벤트를 발행하기 위해 `EventProducer`를 실행하십시오.
2. 이벤트를 구독하기 위해 `EventConsumer`를 실행하십시오.
3. `EventProducer`에서 발행한 이벤트가 `EventConsumer`에서 수신되는 것을 확인할 수 있습니다.

## 결론
이렇게 자바를 사용하여 카프카와 이벤트 드리븐 마이크로서비스 아키텍처를 구현하는 방법을 알아보았습니다. 이 아키텍처를 활용하면 시스템의 확장성과 유연성을 향상시킬 수 있으며, 이벤트를 통해 다양한 컴포넌트 간의 통신과 데이터 교환을 할 수 있습니다.

## 참고 자료
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Kafka Tutorial](https://www.confluent.io/kafka-tutorial/)
- [Event-Driven Architecture with Apache Kafka](https://www.confluent.io/learn/event-driven/)