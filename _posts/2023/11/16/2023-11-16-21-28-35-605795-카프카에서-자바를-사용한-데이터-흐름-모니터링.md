---
layout: post
title: "[java] 카프카에서 자바를 사용한 데이터 흐름 모니터링"
description: " "
date: 2023-11-16
tags: [java]
comments: true
share: true
---

카프카는 대량의 데이터를 신속하게 처리하기 위한 분산 데이터 스트리밍 플랫폼으로 널리 사용되고 있습니다. 데이터의 수집, 분석, 처리를 돕는 도구로서 많은 기업에서 사용되고 있으며, 자바로 쉽게 통합하여 사용할 수 있습니다.

이번 글에서는 카프카에서 자바를 사용하여 데이터 흐름을 모니터링하는 방법에 대해 알아보겠습니다. 데이터 흐름 모니터링은 생산자(Producer)가 카프카에 데이터를 전송하고, 소비자(Consumer)가 해당 데이터를 소비하는 과정에서 데이터의 흐름을 실시간으로 모니터링하는 것을 의미합니다. 이를 통해 데이터의 전달 여부, 속도, 지연 시간 등을 확인할 수 있습니다.

## 1. 카프카 클러스터 설정

먼저 카프카 클러스터를 구성해야 합니다. 클러스터는 여러 대의 브로커로 구성되며, 토픽(Topic)이라는 개념으로 데이터를 구분합니다. 각 토픽은 여러 개의 파티션으로 나누어지며, 각 파티션은 브로커에 저장됩니다. 카프카 클러스터를 구성하는 방법은 다양한데, 여기서는 간단히 하나의 브로커를 사용하여 클러스터를 구성하는 예제를 보여드리겠습니다.

```java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
```

위의 코드는 카프카 클러스터에 연결하기 위한 설정을 구성하는 부분입니다. `bootstrap.servers` 속성은 카프카 클러스터에 접속할 브로커의 주소를 지정합니다. `key.serializer`와 `value.serializer` 속성은 카프카로 데이터를 전송할 때 사용할 직렬화 방식을 지정합니다. 위의 예제에서는 문자열 데이터를 사용하고 있으므로 `StringSerializer`를 사용하였습니다.

## 2. 데이터 프로듀싱

데이터를 카프카에 전송하는 과정을 데이터 프로듀싱(Producing)이라고 합니다. 카프카는 메시지의 순서를 보장하기 위해 순서를 기준으로 파티션에 데이터를 저장합니다. 이때 데이터의 키(Key)를 설정하여 같은 키를 가진 데이터들이 동일한 파티션에 저장되도록 할 수 있습니다.

```java
ProducerRecord<String, String> record = new ProducerRecord<>("my_topic", "my_key", "my_value");
producer.send(record);
```

위의 코드는 `my_topic` 토픽에 `my_key` 키와 `my_value` 값으로 데이터를 전송하는 예제입니다. `ProducerRecord` 객체는 데이터를 표현하는 객체로서 토픽, 키, 값을 지정하여 생성할 수 있습니다. `producer.send()` 메서드를 호출하여 데이터를 전송합니다.

## 3. 데이터 컨슈밍

전송된 데이터를 소비하는 과정을 데이터 컨슈밍(Consuming)이라고 합니다. 데이터 컨슈머를 생성하고, 토픽에서 데이터를 읽어오는 과정을 간단한 코드로 살펴보겠습니다.

```java
props.put("bootstrap.servers", "localhost:9092");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

Consumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Collections.singletonList("my_topic"));

ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
for (ConsumerRecord<String, String> record : records) {
    System.out.println("Key: " + record.key() + ", Value: " + record.value());
}
```

위의 코드에서는 `my_topic` 토픽에서 데이터를 읽어와 출력하는 예제입니다. `bootstrap.servers` 속성을 설정하여 카프카 클러스터에 연결하고, `key.deserializer`와 `value.deserializer` 속성을 지정하여 직렬화된 데이터를 역직렬화합니다. `consumer.subscribe()` 메서드를 사용하여 토픽을 구독하고, `consumer.poll()` 메서드를 사용하여 데이터를 조회합니다. 조회된 데이터는 `ConsumerRecord` 객체로 전달되며, 이를 통해 데이터의 키와 값을 확인할 수 있습니다.

## 4. 데이터 흐름 모니터링

카프카에서 데이터 흐름을 모니터링하려면, 데이터 프로듀서와 컨슈머의 상태를 주기적으로 체크해야 합니다. 예를 들어 프로듀서에서는 메시지 전송에 실패한 경우, 컨슈머에서는 메시지를 올바르게 수신하지 못한 경우 등을 모니터링할 수 있습니다.

```java
props.put("acks", "all");
props.put("retries", 0);

producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            System.err.println("Message sending failed: " + exception.getMessage());
        } else {
            System.out.println("Message sent to topic: " + metadata.topic() + ", partition: " + metadata.partition() + ", offset: " + metadata.offset());
        }
    }
});
```

위의 코드에서는 메시지 전송이 완료되면 `Callback` 함수가 호출되도록 작성되어 있습니다. `Callback` 함수에서는 전송 실패에 대한 처리와 성공한 경우에 대한 로그를 출력하도록 구현하실 수 있습니다.

## 마무리

이번 글에서는 카프카에서 자바를 사용하여 데이터 흐름을 모니터링하는 방법에 대해 알아보았습니다. 데이터 흐름 모니터링은 데이터의 전달 여부와 속도를 확인하기 위해 매우 중요한 기능입니다. 자바를 사용하여 카프카와 통합하면, 신속하게 데이터를 처리하고 모니터링할 수 있는 장점을 가질 수 있습니다. 카프카의 다양한 기능을 활용하여 데이터 플로우를 세밀하게 모니터링할 수 있다면, 더욱 효율적인 데이터 처리를 구현할 수 있을 것입니다.