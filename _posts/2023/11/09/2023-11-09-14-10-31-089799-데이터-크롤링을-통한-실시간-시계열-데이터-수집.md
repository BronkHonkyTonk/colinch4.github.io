---
layout: post
title: "데이터 크롤링을 통한 실시간 시계열 데이터 수집"
description: " "
date: 2023-11-09
tags: [python]
comments: true
share: true
---

데이터 크롤링은 웹에서 데이터를 수집하는 과정을 의미합니다. 이는 실시간 시계열 데이터 수집에 매우 유용하게 사용될 수 있습니다. 실시간 시계열 데이터는 시간에 따라 변화하는 데이터를 의미하며, 예를 들어 주식 가격, 날씨 정보, 트위터 트렌드 등이 있습니다.

이 글에서는 Python을 사용하여 데이터 크롤링을 통해 실시간 시계열 데이터를 수집하는 방법에 대해 알아보겠습니다.

## 1. 웹 페이지 파싱하기

가장 먼저 필요한 단계는 웹 페이지를 파싱하여 원하는 데이터를 추출하는 것입니다. 웹 페이지 파싱은 HTML 또는 XML 형식의 데이터를 구문 분석하는 과정을 의미합니다. Python에서는 `requests`와 `Beautiful Soup` 라이브러리를 이용하여 간단하게 웹 페이지 파싱을 할 수 있습니다.

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com" # 크롤링할 웹 페이지 URL
response = requests.get(url) # 웹 페이지 요청

soup = BeautifulSoup(response.text, 'html.parser') # HTML 파싱

# 원하는 데이터 추출
data = soup.find('div', class_='data-container').text
```

위 코드에서 `requests`를 사용하여 웹 페이지에 GET 요청을 보내고, `BeautifulSoup`를 사용하여 HTML을 파싱합니다. 그런 다음 `find()` 메서드를 사용하여 원하는 데이터를 추출합니다.

## 2. 실시간 데이터를 업데이트하는 웹 사이트 크롤링

시계열 데이터는 지속적으로 업데이트되는 경우가 많기 때문에, 실시간으로 데이터를 수집해야 할 때가 있습니다. 이 경우 데이터를 주기적으로 업데이트하는 웹 사이트를 크롤링하는 방법을 사용할 수 있습니다.

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com" # 크롤링할 웹 페이지 URL

while True:
    response = requests.get(url) # 웹 페이지 요청
    soup = BeautifulSoup(response.text, 'html.parser') # HTML 파싱

    # 원하는 데이터 추출
    data = soup.find('div', class_='data-container').text    
    print(data)

    time.sleep(60) # 1분마다 업데이트된 데이터를 가져오기 위해 대기합니다.
```

위 코드는 `while` 루프를 사용하여 주기적으로 데이터를 업데이트하는 웹 페이지를 크롤링합니다. `time.sleep()` 함수를 사용하여 1분마다 데이터를 가져오기 위해 대기합니다.

## 3. 데이터 저장하기

데이터를 수집한 후에는 저장하여 필요한 경우 나중에 사용할 수 있도록 해야 합니다. 일반적으로는 데이터베이스에 저장하는 것이 좋습니다. Python에서는 다양한 데이터베이스 관련 라이브러리를 사용할 수 있습니다.

```python
import sqlite3

# 데이터베이스 연결 생성
conn = sqlite3.connect('data.db')

# 커서 생성
cursor = conn.cursor()

# 데이터 저장
cursor.execute("INSERT INTO table_name (column1, column2) VALUES (?, ?)", (data1, data2))

# 변경 사항 저장
conn.commit()

# 연결 종료
conn.close()
```

위 코드는 SQLite 데이터베이스를 사용하여 데이터를 저장하는 예시입니다. `sqlite3` 라이브러리를 사용하여 데이터베이스 연결을 생성한 다음, `cursor()`를 사용하여 커서를 생성합니다. `execute()` 메서드를 사용하여 SQL 쿼리를 실행하여 데이터를 저장합니다. 마지막으로 `commit()` 메서드를 사용하여 변경 사항을 저장하고, `close()` 메서드를 사용하여 데이터베이스 연결을 종료합니다.

데이터 크롤링을 통해 실시간 시계열 데이터를 수집하는 방법에 대해 알아보았습니다. Python을 사용하여 웹 페이지 파싱, 실시간 데이터 업데이트, 그리고 데이터 저장을 할 수 있습니다. 이를 통해 필요한 실시간 데이터를 수집하여 다양한 분석이나 예측에 활용할 수 있습니다.

#데이터 #크롤링