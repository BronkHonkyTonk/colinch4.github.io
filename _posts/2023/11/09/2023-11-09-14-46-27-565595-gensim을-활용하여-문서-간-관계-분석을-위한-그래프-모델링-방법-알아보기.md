---
layout: post
title: "Gensim을 활용하여 문서 간 관계 분석을 위한 그래프 모델링 방법 알아보기"
description: " "
date: 2023-11-09
tags: [NaturalLanguageProcessing, DocumentAnalysis]
comments: true
share: true
---

Gensim은 Python에서 자연어 처리를 위한 라이브러리로, 토픽 모델링, 문서 유사도 계산, 단어 임베딩 등 다양한 기능을 제공합니다. 이번 포스트에서는 Gensim을 사용하여 문서 간의 관계를 분석하고, 그래프 모델을 생성하는 방법에 대해 알아보겠습니다.

## 문서 간의 관계 분석

Gensim을 사용하여 문서 간의 관계를 분석하기 위해서는 먼저 문서를 벡터로 변환해야 합니다. 이를 위해 Word2Vec, Doc2Vec, TF-IDF 등의 기법을 사용할 수 있습니다.

### Word2Vec
Word2Vec은 단어의 의미를 벡터로 표현하는 방법으로, 문맥을 기반으로 단어 간의 관계를 파악합니다. Word2Vec 모델을 훈련시키면 단어들이 공간상의 벡터로 매핑되기 때문에, 벡터 간의 거리를 계산하여 단어 간의 유사도를 구할 수 있습니다. 이를 통해 문서 간의 관계를 분석할 수 있습니다.

```python
from gensim.models import Word2Vec

sentences = [["I", "love", "machine", "learning"],
             ["Artificial", "intelligence", "is", "amazing"],
             ["I", "enjoy", "coding"]]

model = Word2Vec(sentences, min_count=1)
vector = model.wv["machine"]
similar_words = model.wv.most_similar("machine")
```

### Doc2Vec
Doc2Vec은 문서의 의미를 벡터로 표현하는 방법으로, Word2Vec과 유사한 원리를 사용합니다. 각 문서를 벡터로 매핑한 후, 벡터 간의 유사도를 계산하여 문서 간의 관계를 파악할 수 있습니다.

```python
from gensim.models import Doc2Vec
from gensim.models.doc2vec import TaggedDocument

documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]
model = Doc2Vec(documents, vector_size=100, min_count=1)
vector = model.infer_vector(["I", "enjoy", "machine", "learning"])
similar_documents = model.docvecs.most_similar(0)
```

### TF-IDF
TF-IDF(Term Frequency-Inverse Document Frequency)는 단어의 중요도를 판단하기 위한 방법으로, 각 문서에서의 단어의 출현 빈도와 전체 문서에서의 단어의 출현 빈도를 고려합니다. TF-IDF를 계산하여 각 문서를 벡터로 변환한 후, 벡터 간의 유사도를 계산하여 문서 간의 관계를 분석할 수 있습니다.

```python
from gensim import corpora
from gensim.models import TfidfModel

dictionary = corpora.Dictionary(sentences)
corpus = [dictionary.doc2bow(doc) for doc in sentences]

tfidf_model = TfidfModel(corpus)
tfidf_vector = tfidf_model[corpus[0]]
similar_documents = tfidf_model[corpus[1]]
```

## 그래프 모델링

Gensim을 이용하여 문서 간의 관계 분석을 한 후, 그 결과를 그래프로 시각화해 볼 수도 있습니다. 이를 통해 문서들 사이의 관계를 더 직관적으로 이해할 수 있습니다.

```python
import networkx as nx
import matplotlib.pyplot as plt

G = nx.Graph()

# 문서 간의 유사도를 기준으로 엣지 생성
for i in range(len(similar_documents)):
    if similar_documents[i][1] > threshold:
        G.add_edge(0, i+1, weight=similar_documents[i][1])

# 그래프 그리기
pos = nx.spring_layout(G)
nx.draw(G, pos, with_labels=True)
labels = nx.get_edge_attributes(G, "weight")
nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)

plt.show()
```

## 결론

이번 포스트에서는 Gensim을 활용하여 문서 간의 관계를 분석하고, 그래프 모델링을 수행하는 방법에 대해 알아보았습니다. Gensim은 문서 처리와 관련된 다양한 기능을 제공하기 때문에, 텍스트 데이터의 특성을 자세히 파악하고 다양한 분석을 수행하는 데 유용하게 활용될 수 있습니다.

#NaturalLanguageProcessing #DocumentAnalysis