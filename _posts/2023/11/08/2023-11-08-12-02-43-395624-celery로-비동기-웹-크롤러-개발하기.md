---
layout: post
title: "Celery로 비동기 웹 크롤러 개발하기"
description: " "
date: 2023-11-08
tags: [Celery]
comments: true
share: true
---

Celery는 파이썬에서 비동기 작업을 수행하는 데 사용되는 분산 작업 큐입니다. Celery를 사용하면 웹 크롤링과 같은 오래 걸리는 작업을 비동기적으로 처리할 수 있습니다. 이제 Celery를 사용하여 비동기 웹 크롤러를 개발하는 방법에 대해 알아보겠습니다.

## Celery 설치

Celery를 사용하기 위해 먼저 설치해야 합니다. 아래 명령을 사용하여 Celery를 설치할 수 있습니다.

```shell
pip install celery
```

## Celery 앱 설정

Celery를 사용하기 위해 앱을 설정해야 합니다. `celery.py` 파일을 생성하고 아래와 같이 작성합니다.

```python
from celery import Celery

app = Celery('crawler', broker='redis://localhost:6379/0', backend='redis://localhost:6379/0')

@app.task
def crawl(url):
    # 크롤링 작업 수행
    return data
```

위 코드에서 `broker`와 `backend`는 Celery 작업을 처리하기 위한 메시지 브로커와 결과 백엔드를 정의하는 부분입니다. 이 예시에서는 Redis를 사용하였습니다.

## 크롤링 작업 정의

Celery를 사용하여 크롤링 작업을 정의할 수 있습니다. 위에서 정의한 `crawl` 작업을 사용하여 웹 페이지를 크롤링하는 함수를 만들어보겠습니다.

```python
from celery import current_app

@app.route('/crawl')
def start_crawl():
    url = request.args.get('url')

    task = current_app.send_task('crawler.crawl', args=[url])

    return "Crawling task started: {}".format(task.id)
```

위 코드에서 `start_crawl` 함수는 `/crawl` 경로로 HTTP 요청을 처리합니다. 요청 파라미터로 받은 URL을 `crawl` 작업에 전달하고, 작업 식별자를 반환합니다.

## Celery 워커 실행

Celery 워커를 실행하여 크롤링 작업을 처리할 수 있습니다. 아래 명령을 통해 Celery 워커를 실행합니다.

```shell
celery -A celery_app worker --loglevel=info
```

위 명령에서 `-A` 옵션은 Celery 앱을 지정하고, `--loglevel` 옵션은 로그 레벨을 설정합니다.

## 웹 크롤링 실행

Celery 워커가 실행 중인 상태에서 웹 크롤링 작업을 실행할 수 있습니다. 아래와 같이 HTTP 요청을 보내면 크롤링 작업이 Celery 워커에서 비동기적으로 실행됩니다.

```shell
curl http://localhost:5000/crawl?url=https://www.example.com
```

## 마무리

이제 Celery를 사용하여 비동기 웹 크롤러를 개발하는 방법에 대해 알아보았습니다. Celery를 통해 오래 걸리는 작업을 비동기적으로 처리할 수 있으며, 크롤링 작업 외에도 다양한 비동기 작업에 대해 적용할 수 있습니다.

#python #webcrawler