---
layout: post
title: "Celery와 AWS S3를 연동하여 비동기 파일 처리"
description: " "
date: 2023-11-08
tags: [Celery]
comments: true
share: true
---

이번 글에서는 Celery와 AWS S3를 함께 사용하여 비동기 파일 처리를 구현하는 방법에 대해 알아보겠습니다. Celery는 분산 작업 큐 시스템으로, 비동기 작업을 처리하는데 유용한 도구입니다. AWS S3는 클라우드 기반의 객체 스토리지 서비스로, 파일을 저장하고 관리하는 데 사용됩니다.

## 1. Celery 설정

먼저, Celery를 설정해야 합니다. 프로젝트의 settings 파일에 다음과 같이 Celery 관련 설정을 추가해주세요.

```python
CELERY_BROKER_URL = 'your-broker-url'
CELERY_RESULT_BACKEND = 'your-backend-url'
```

`CELERY_BROKER_URL`은 Celery 작업 큐의 주소를 나타내며, `CELERY_RESULT_BACKEND`은 작업 결과를 저장하는 백엔드 서비스의 주소입니다.

## 2. AWS S3 설정

다음으로, AWS S3를 설정해야 합니다. AWS 콘솔에서 S3 버킷을 생성하세요. 그리고 IAM 역할을 만들어 S3에 접근할 수 있는 권한을 부여해주세요. AWS CLI를 통해 해당 역할의 자격 증명을 설정하세요.

## 3. Celery 태스크 작성

이제 Celery 태스크를 작성해보겠습니다. 비동기로 파일 처리를 수행하는 `process_file` 태스크를 만들어봅시다. 다음은 예시 코드입니다.

```python
import boto3
from celery import shared_task

@shared_task
def process_file(file_key):
    # S3 클라이언트 생성
    s3_client = boto3.client('s3')

    # 파일 다운로드
    s3_client.download_file('my-bucket', file_key, '/tmp/file.txt')

    # 파일 처리 로직 작성
    with open('/tmp/file.txt', 'r') as f:
        # 파일 처리 코드 작성
        # ...

    # 처리 완료 후 파일 업로드
    s3_client.upload_file('/tmp/processed_file.txt', 'my-bucket', f'processed/{file_key}')

    return 'File processing completed.'
```

이 태스크는 S3에서 파일을 다운로드하고, 다운로드한 파일을 처리한 후에 다시 S3로 업로드하는 작업을 수행합니다. 또한, `@shared_task` 데코레이터를 사용하여 Celery 작업으로 등록되었습니다.

## 4. 태스크 호출하기

이제 위에서 작성한 Celery 태스크를 호출해보겠습니다. 다음은 예시 코드입니다.

```python
from myapp.tasks import process_file

# 태스크 호출
result = process_file.delay('example/file.txt')

# 태스크 실행 결과 확인
print(result.status)  # 작업 상태
print(result.result)  # 작업 결과
```

`delay` 메서드를 사용하여 태스크를 비동기적으로 실행시킬 수 있습니다. 실행 결과는 `status` 속성과 `result` 속성을 통해 확인할 수 있습니다.

## 결론

이렇게 Celery와 AWS S3를 이용하여 비동기 파일 처리를 구현할 수 있습니다. Celery를 사용하면 비동기 작업을 보다 효율적으로 처리할 수 있으며, AWS S3를 통해 안정적인 파일 저장과 관리를 할 수 있습니다. 이를 활용하여 스케일링 가능한 애플리케이션을 구축해보세요.

#hashtags: #Celery #AWS-S3