---
layout: post
title: "[python] aiohttp를 사용하여 비동기적으로 웹 크롤러 결과를 SQLite 데이터베이스에 저장하기"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

이번에는 `aiohttp` 라이브러리를 사용하여 비동기적으로 웹 크롤러 결과를 SQLite 데이터베이스에 저장하는 방법에 대해 알아보겠습니다.

## 1. 필요한 패키지 설치하기

먼저, `aiohttp`와 `aiomysql` 패키지를 설치해야 합니다. 아래의 커맨드를 사용하여 설치할 수 있습니다.

```bash
pip install aiohttp aiomysql
```

## 2. 비동기 웹 크롤러 구현하기

크롤링할 웹사이트의 URL을 입력받고, 해당 웹사이트에서 필요한 데이터를 가져오는 비동기 웹 크롤러를 구현해보겠습니다. 아래는 예시 코드입니다.

```python
import aiohttp
import asyncio

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def crawl_website(url):
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, url)
        # 필요한 데이터 추출 및 가공 로직 구현

        return result

async def main():
    url = 'https://example.com'  # 크롤링할 웹사이트 URL
    result = await crawl_website(url)
    print(result)  # 크롤링 결과 출력

if __name__ == '__main__':
    asyncio.run(main())
```

## 3. SQLite 데이터베이스에 저장하기

이제 웹 크롤러의 결과를 SQLite 데이터베이스에 저장하는 코드를 작성해보겠습니다. 아래는 예시 코드입니다.

```python
import sqlite3

def create_table():
    conn = sqlite3.connect('mydatabase.db')  # 새로운 SQLite 데이터베이스 생성
    cursor = conn.cursor()

    cursor.execute('''CREATE TABLE IF NOT EXISTS mytable
                      (id INTEGER PRIMARY KEY AUTOINCREMENT,
                       title TEXT,
                       content TEXT)''')

    conn.commit()
    conn.close()

def insert_data(title, content):
    conn = sqlite3.connect('mydatabase.db')
    cursor = conn.cursor()

    cursor.execute('''INSERT INTO mytable (title, content)
                      VALUES (?, ?)''', (title, content))

    conn.commit()
    conn.close()

async def save_to_database(result):
    create_table()
    for item in result:
        insert_data(item['title'], item['content'])

async def main():
    # ...

    result = await crawl_website(url)
    await save_to_database(result)

if __name__ == '__main__':
    asyncio.run(main())
```

위의 코드에서 `create_table` 함수는 데이터베이스에 테이블을 생성하는 역할을 하고, `insert_data` 함수는 데이터를 테이블에 삽입하는 역할을 합니다. `save_to_database` 함수에서는 크롤링한 결과를 데이터베이스에 저장하도록 구현되어 있습니다.

이제 실행하면 비동기 웹 크롤러가 동작하고, 결과는 SQLite 데이터베이스에 저장됩니다.

## 마무리

이번에는 `aiohttp`를 사용하여 비동기적으로 웹 크롤러 결과를 SQLite 데이터베이스에 저장하는 방법을 알아보았습니다. 비동기 방식을 사용하면 웹 크롤링 속도를 향상시킬 수 있으며, SQLite 데이터베이스를 활용하면 결과를 효율적으로 저장하고 관리할 수 있습니다.