---
layout: post
title: "[python] aiohttp를 사용하여 비동기적으로 웹 크롤러 키워드 분석하기"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

웹 크롤링은 인터넷에서 데이터를 수집하고 분석하는 데 사용되는 강력한 도구입니다. aiohttp는 Python에서 비동기적으로 HTTP 요청을 처리하기 위한 라이브러리로, 웹 크롤러 개발에서 많이 활용됩니다. 이번에는 aiohttp를 사용하여 비동기적으로 웹 크롤러를 작성하고 키워드 분석을 수행하는 방법에 대해 알아보겠습니다.

## aiohttp 설치하기

먼저, aiohttp를 설치해야 합니다. pip를 사용하여 아래와 같이 설치할 수 있습니다.

```python
pip install aiohttp
```

## 비동기적으로 웹 페이지 크롤링하기

aiohttp를 사용하여 비동기적으로 웹 페이지를 크롤링하는 예제를 살펴보겠습니다. 아래 코드는 aiohttp를 사용하여 "https://www.example.com"에 GET 요청을 보내고, 응답을 받아오는 예제입니다.

```python
import aiohttp
import asyncio

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, 'https://www.example.com')
        print(html)

if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
```

위 코드에서 `fetch` 함수는 aiohttp의 `session` 객체를 이용하여 비동기적으로 GET 요청을 보내고, 응답을 받아오는 역할을 합니다. `main` 함수에서는 `ClientSession`을 만들고 `fetch` 함수를 호출하여 비동기적으로 웹 페이지를 크롤링합니다. 마지막으로 이 코드를 실행하면 "https://www.example.com"의 HTML 내용을 출력할 수 있습니다.

## 키워드 분석하기

aiohttp를 사용하여 웹 페이지를 크롤링한 후, 키워드 분석을 수행할 수 있습니다. 키워드 분석을 위해서는 응답 받은 HTML 내용을 파싱하고, 단어별로 빈도를 계산해야 합니다. 이를 위해 [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)과 같은 HTML 파싱 라이브러리를 사용할 수 있습니다.

다음은 aiohttp와 BeautifulSoup를 함께 사용하여 HTML 내용을 파싱하고 키워드 분석을 수행하는 예제입니다.

```python
import aiohttp
import asyncio
from bs4 import BeautifulSoup
from collections import Counter

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, 'https://www.example.com')
        soup = BeautifulSoup(html, 'html.parser')
        text = soup.get_text()
        words = text.split()
        word_counts = Counter(words)
        print(word_counts)

if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
```

위 코드에서 `main` 함수는 크롤링한 HTML을 BeautifulSoup 객체로 파싱하고, `get_text`를 사용하여 텍스트를 추출합니다. 그 후, `split` 함수를 사용하여 단어로 분리하고, `Counter`를 사용하여 단어별 빈도를 계산합니다. 마지막으로, `word_counts`를 출력하면 각 단어의 빈도를 확인할 수 있습니다.

## 결론

aiohttp를 사용하여 비동기적으로 웹 크롤러를 작성하고 키워드 분석을 수행하는 방법에 대해 알아보았습니다. aiohttp의 강력한 비동기 기능을 활용하면 웹 크롤링 작업을 빠르고 효율적으로 처리할 수 있습니다. 키워드 분석은 수집한 데이터를 다양한 분야에서 활용할 수 있는 중요한 작업 중 하나입니다. 이를 통해 웹 상의 다양한 정보를 더욱 유용하게 활용할 수 있습니다.

**참고 자료:**
- [aiohttp 공식 문서](https://docs.aiohttp.org/)
- [BeautifulSoup 공식 문서](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)