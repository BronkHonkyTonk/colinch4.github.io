---
layout: post
title: "[python] aiohttp를 사용하여 비동기적으로 웹 크롤러 결과를 엑셀 파일로 저장하기"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

웹 크롤링을 통해 수집한 데이터를 엑셀 파일로 저장하기 위해 `aiohttp` 라이브러리를 사용하면 매우 간편하게 비동기적으로 처리할 수 있습니다. 이번 포스트에서는 `aiohttp`를 사용하여 웹 페이지를 비동기적으로 요청하고 응답을 받아와서 엑셀 파일에 저장하는 방법에 대해 알아보겠습니다.

## 필요한 라이브러리 설치하기

먼저 `aiohttp`와 `openpyxl` 라이브러리를 설치해야 합니다. 이 라이브러리들은 아래의 명령어로 설치할 수 있습니다.

```python
pip install aiohttp
pip install openpyxl
```

## 비동기 웹 요청하기

`aiohttp`를 사용하여 비동기적으로 웹 페이지에 요청을 보내기 위해서는 `aiohttp.ClientSession`을 생성하고 `async with` 구문 안에서 `session.get()` 메서드를 사용하여 웹 페이지에 접속해야 합니다. 아래의 예제 코드를 살펴보세요.

```python
import aiohttp
import asyncio

async def fetch(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()

url = "https://example.com"
html = asyncio.run(fetch(url))
print(html)
```

위 코드에서는 `fetch()` 함수를 정의하고 `fetch()` 함수에서 `aiohttp.ClientSession()`을 생성한 뒤 `session.get()` 메서드로 웹 페이지에 접속한 후, `response.text()`를 사용하여 웹 페이지의 HTML 코드를 가져옵니다. 마지막으로 `asyncio.run()` 함수를 사용하여 이 비동기 코드를 실행합니다.

## 엑셀 파일로 저장하기

`openpyxl` 라이브러리를 사용하여 웹 크롤링한 데이터를 엑셀 파일로 저장하는 방법에 대해 알아보겠습니다. `openpyxl`은 대표적인 엑셀 파일 처리 라이브러리로, 간편한 API를 제공합니다.

아래의 예제 코드는 `openpyxl`을 사용하여 엑셀 파일을 생성하고 웹 크롤링한 데이터를 시트에 저장하는 예제입니다.

```python
import openpyxl

data = [['이름', '나이', '직업'],
        ['John', 25, 'Engineer'],
        ['Emily', 30, 'Designer'],
        ['Michael', 35, 'Manager']]

wb = openpyxl.Workbook()
ws = wb.active

for row in data:
    ws.append(row)

wb.save("data.xlsx")
```

위 코드에서는 `openpyxl.Workbook()`을 사용하여 새로운 엑셀 파일 `wb`를 생성하고, 해당 워크북의 활성 시트 `ws`를 얻어옵니다. 그리고 `ws.append()` 메서드를 사용하여 데이터를 시트에 추가합니다. 마지막으로 `wb.save()` 메서드를 사용하여 엑셀 파일을 저장합니다.

## 비동기 크롤러 결과를 엑셀 파일로 저장하기

이제 `aiohttp`와 `openpyxl`을 함께 사용하여 웹 크롤러 결과를 비동기적으로 가져와서 엑셀 파일로 저장하는 예제 코드를 살펴보겠습니다.

```python
import aiohttp
import asyncio
import openpyxl

async def fetch(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()

async def crawl_and_save(url, filename):
    html = await fetch(url)
    wb = openpyxl.Workbook()
    ws = wb.active

    # 웹 크롤링한 데이터를 시트에 추가하는 로직 구현
    # ...

    wb.save(filename)

url = "https://example.com"
filename = "data.xlsx"

asyncio.run(crawl_and_save(url, filename))
```

위 코드에서는 `crawl_and_save()` 함수를 정의한 뒤, `fetch()` 함수와 `openpyxl`을 사용하여 비동기적으로 웹 페이지를 크롤링한 결과를 엑셀 파일에 저장합니다. 웹 크롤링한 데이터를 엑셀 시트에 추가하는 로직은 별도로 구현해야 합니다.

## 결론

이번 포스트에서는 `aiohttp`를 사용하여 웹 크롤러 결과를 비동기적으로 엑셀 파일로 저장하는 방법에 대해 알아보았습니다. `aiohttp`와 `openpyxl`은 간편하게 데이터를 비동기적으로 처리하고 엑셀 파일에 저장할 수 있는 라이브러리입니다. 이를 활용하여 큰 규모의 웹 크롤링 작업을 효율적으로 수행할 수 있습니다.

## 참고 자료

- [aiohttp 공식 문서](https://docs.aiohttp.org/)
- [openpyxl 공식 문서](https://openpyxl.readthedocs.io/)