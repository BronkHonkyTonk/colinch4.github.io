---
layout: post
title: "[python] Celery와 AWS S3를 함께 사용하는 방법은 어떻게 되는가?"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

이번 포스트에서는 Celery와 AWS S3를 함께 사용하는 방법에 대해 알아보겠습니다.

## 개요

Celery는 Python으로 작성된 분산 작업 큐입니다. AWS S3는 클라우드 기반 객체 스토리지 서비스로, 파일 저장 및 관리에 사용됩니다. 이 두 가지 기술을 함께 사용하면 비동기 작업을 효율적으로 처리하고 파일을 안전하게 저장할 수 있습니다.

## 단계별 가이드

아래의 단계별 가이드를 따라 Celery와 AWS S3를 함께 사용할 수 있습니다.

### 1. 필요한 패키지 설치

다음 명령어를 사용하여 필요한 패키지를 설치합니다.

```
pip install celery boto3
```

### 2. Celery 작업 정의하기

Celery 작업을 정의하기 위해 다음과 같이 코드를 작성합니다.

```python
# tasks.py 파일

from celery import Celery

app = Celery('myapp', backend='s3://<aws_access_key_id>:<aws_secret_access_key>@<region_name>/myapp')
app.conf.task_default_queue = 'default'
app.conf.task_default_exchange = 'default'
app.conf.task_default_routing_key = 'default'

@app.task
def add(x, y):
    return x + y
```

### 3. AWS S3 설정

AWS S3에 접근하기 위해 AWS 계정 및 사용자를 생성하고, [AWS IAM](https://aws.amazon.com/iam/)에 액세스 키를 만들어야 합니다. 액세스 키를 얻은 후, 다음 코드에서 `<aws_access_key_id>`, `<aws_secret_access_key>`, `<region_name>`을 실제 값을 사용하여 변경해야 합니다.

### 4. Celery 실행하기

다음 명령어를 사용하여 Celery를 실행합니다.

```
celery -A tasks worker --loglevel=info
```

### 5. 작업 예약하기

다음과 같이 Python 스크립트를 작성하여 작업을 예약할 수 있습니다.

```python
# main.py 파일

from tasks import add

result = add.delay(4, 5)
print(result.get())
```

위의 예제는 `add` 작업을 예약하고 결과를 출력하는 방법을 보여줍니다.

## 결론

이렇게 하면 Celery와 AWS S3를 함께 사용하는 방법에 대해 알아보았습니다. Celery를 사용하여 비동기 작업을 처리하고 AWS S3를 사용하여 파일을 안전하게 저장할 수 있습니다. 이를 통해 애플리케이션의 성능과 신뢰성을 향상시킬 수 있습니다.

더 자세한 내용은 [Celery 문서](https://docs.celeryproject.org/en/stable/index.html)와 [AWS S3 문서](https://aws.amazon.com/s3/)를 참조하시기 바랍니다.