---
layout: post
title: "[python] Celery로 분산 작업 실행 방법은 어떻게 되는가?"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

Celery는 파이썬으로 작성된 분산 작업 처리 프레임워크입니다. Celery를 사용하면 작업을 비동기적으로 실행하고 여러 대의 워커(worker)에서 병렬로 처리할 수 있습니다. 아래는 Celery를 사용하여 분산 작업을 실행하는 방법에 대한 예시입니다.

## Celery 설치

Celery를 사용하려면 먼저 Celery를 설치해야 합니다. 다음 명령을 사용하여 Celery를 설치할 수 있습니다.

```python
pip install celery
```
 
## Celery 프로젝트 설정

Celery를 사용하기 위해 프로젝트에 설정 파일을 작성해야 합니다. `celery.py` 또는 `tasks.py`와 같은 이름을 가진 파일을 생성하고 다음과 같이 Celery 설정을 추가합니다.

```python
from celery import Celery

app = Celery('my_app', broker='amqp://guest:guest@localhost:5672//', backend='rpc://')
```

위의 코드에서 `broker` 및 `backend`은 Celery 작업 큐와 결과를 저장할 위치를 지정하는 데 사용됩니다. 이 예시에서는 RabbitMQ를 사용하여 작업 큐를 구성하고, RPC 백엔드를 사용하여 결과를 저장합니다. 필요에 따라 이러한 값을 변경할 수 있습니다.

## 작업 정의

분산 작업을 실행하기 전에 작업을 먼저 정의해야 합니다. 작업은 별도의 모듈에 정의할 수 있으며, 해당 모듈에 작업을 작성합니다. 작업은 함수 형태로 정의되어야 하며, `@app.task` 데코레이터로 작업을 설정합니다.

```python
@app.task
def add(x, y):
    return x + y
```

위의 예시에서는 `add`라는 작업을 정의하고 있습니다. 이 작업은 주어진 두 수를 더하고 결과를 반환합니다.

## 작업 실행

이제 작업을 실행할 준비가 되었습니다. 작업은 Celery 인스턴스의 `delay` 메서드를 사용하여 실행할 수 있습니다. 다음은 작업을 실행하는 예시 코드입니다.

```python
result = add.delay(5, 10)
print(result.get())
```

위의 코드에서 `add.delay(5, 10)`는 `add` 작업을 비동기적으로 실행합니다. 작업이 완료되면 `result.get()`으로 작업의 결과를 가져올 수 있습니다.

## 워커 실행

작업을 분산 처리하려면 Celery 워커를 실행해야 합니다. 다음 명령을 사용하여 워커를 실행할 수 있습니다.

```bash
celery -A my_app worker --loglevel=info
```

위의 명령에서 `-A` 옵션은 Celery 애플리케이션을 지정하고, `worker`는 워커를 실행하는 명령입니다. `--loglevel` 옵션을 사용하여 로그 레벨을 설정할 수 있습니다.

이제 Celery를 사용하여 작업을 비동기적으로 실행하고, 워커를 통해 분산 처리할 수 있는 준비가 되었습니다.

더 자세한 내용은 [Celery 공식 문서](http://docs.celeryproject.org/)를 참조하시기 바랍니다.