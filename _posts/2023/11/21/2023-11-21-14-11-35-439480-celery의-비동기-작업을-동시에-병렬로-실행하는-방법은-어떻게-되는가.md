---
layout: post
title: "[python] Celery의 비동기 작업을 동시에 병렬로 실행하는 방법은 어떻게 되는가?"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

Celery는 Python에서 비동기 작업을 처리하기 위한 분산 작업 큐입니다. Celery를 사용하여 작업을 병렬로 실행하려면 다음과 같은 방법을 사용할 수 있습니다.

## 1. 작업 정의하기

먼저, 병렬로 실행할 작업을 정의해야 합니다. 각 작업은 별개의 함수로 구현됩니다. 예를 들어, 다음과 같이 작업을 정의할 수 있습니다.

```python
from celery import Celery

app = Celery('myapp', backend='rpc://', broker='pyamqp://guest@localhost//')

@app.task
def process_data(data):
    # 작업 수행 코드 작성
    return processed_data
```

## 2. 작업 실행하기

다음으로, 병렬로 실행할 작업을 Celery에 전달하고 실행해야 합니다. 이를 위해 Celery의 `group` 또는 `chord`를 사용할 수 있습니다.

### `group`을 사용하는 방법:

```python
from celery import group

tasks = group(process_data.s(data) for data in datas)
result = tasks.apply_async()
result.get()
```

`group` 함수는 여러 작업을 한 번에 실행하고 결과를 모읍니다. 실행 결과를 얻기 위해 `apply_async`를 호출한 후 `get`을 호출합니다.

### `chord`를 사용하는 방법:

```python
from celery import chord

header = [process_data.s(data) for data in datas]
result = chord(header)(callback.s())
result.get()
```

`chord` 함수는 특정 작업이 모두 완료된 후에 하나의 콜백 작업을 실행합니다. 콜백 작업은 여러 작업의 결과를 합칠 때 유용합니다. 실행 결과를 얻기 위해 `get`을 호출합니다.

## 3. Celery 실행하기

위의 코드를 실행하기 전에 Celery를 먼저 실행해야 합니다. 일반적으로 다음과 같이 Celery worker를 실행할 수 있습니다.

```bash
celery -A module_name worker --loglevel=info
```

`module_name`은 Celery 작업이 정의된 모듈의 이름입니다.

위의 방법을 사용하여 Celery를 통해 비동기 작업을 동시에 병렬로 실행할 수 있습니다. Celery는 많은 옵션을 제공하므로, 자세한 내용은 [Celery 공식 문서](https://docs.celeryproject.org/en/stable/)를 참조해주시기 바랍니다.