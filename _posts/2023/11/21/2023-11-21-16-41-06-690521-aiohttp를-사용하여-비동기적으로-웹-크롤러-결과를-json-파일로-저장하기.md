---
layout: post
title: "[python] aiohttp를 사용하여 비동기적으로 웹 크롤러 결과를 JSON 파일로 저장하기"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

## 개요
웹 크롤러는 인터넷 상에서 데이터를 수집하는 프로그램으로, 비동기 방식을 사용하여 성능을 향상시킬 수 있습니다. **aiohttp**는 Python의 비동기 웹 요청 라이브러리로, 웹 크롤링 작업에 적합한 기능을 제공합니다. 이번 포스트에서는 aiohttp를 사용하여 웹 크롤러 결과를 JSON 파일로 저장하는 방법에 대해 알아보겠습니다.

## 환경 설정
먼저 **aiohttp**를 설치해야 합니다. 다음 명령을 사용하여 설치할 수 있습니다:

```python
pip install aiohttp
```

추가로, JSON 파일을 다루기 위해 **json** 모듈도 필요합니다. 이 모듈은 기본적으로 설치되어 있으므로 별도의 설치가 필요하지 않습니다.

## 코드 작성
다음은 aiohttp를 사용하여 비동기적으로 웹 크롤러 결과를 JSON 파일로 저장하는 예제 코드입니다:

```python
import aiohttp
import asyncio
import json

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.json()

async def save_to_file(data):
    with open('result.json', 'w') as file:
        json.dump(data, file)

async def main():
    urls = [
        'https://example.com/page1',
        'https://example.com/page2',
        'https://example.com/page3',
        # 크롤링할 URL 목록
    ]

    async with aiohttp.ClientSession() as session:
        tasks = []
        for url in urls:
            task = asyncio.ensure_future(fetch(session, url))
            tasks.append(task)

        results = await asyncio.gather(*tasks)
        await save_to_file(results)

asyncio.run(main())
```

위 코드에서는 `fetch` 함수를 사용하여 비동기적으로 웹 요청을 보내고 응답을 JSON 형태로 반환하도록 설정합니다. 이후 `save_to_file` 함수를 사용하여 결과를 JSON 파일로 저장합니다. 

`main` 함수에서는 크롤링할 URL 목록을 정의하고, `ClientSession`을 사용하여 세션을 열어 비동기적으로 요청을 보냅니다. `asyncio.gather`를 사용하여 모든 요청이 완료될 때까지 기다린 후 결과를 JSON 파일로 저장합니다.

## 실행 및 결과
위 코드를 실행하면, 지정한 URL에서 받아온 데이터가 `result.json` 파일에 저장됩니다. 크롤링한 데이터를 확인하려면 해당 파일을 열면 됩니다.

## 결론
이번 포스트에서는 aiohttp를 사용하여 비동기적으로 웹 크롤링 결과를 JSON 파일로 저장하는 방법에 대해 알아보았습니다. aiohttp는 간편한 비동기 웹 요청을 제공하여 웹 크롤러 작업을 효율적으로 처리할 수 있도록 도와줍니다. JSON 파일은 데이터를 구조화하여 저장할 수 있으므로, 크롤링한 결과를 효과적으로 활용할 수 있습니다.

## 참고 자료
- [aiohttp 공식 문서](https://docs.aiohttp.org)
- [Python json 모듈 공식 문서](https://docs.python.org/3/library/json.html)