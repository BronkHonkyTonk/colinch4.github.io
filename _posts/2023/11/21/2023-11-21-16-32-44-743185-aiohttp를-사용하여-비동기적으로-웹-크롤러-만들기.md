---
layout: post
title: "[python] aiohttp를 사용하여 비동기적으로 웹 크롤러 만들기"
description: " "
date: 2023-11-21
tags: [python]
comments: true
share: true
---

## 소개
웹 크롤러는 인터넷에서 데이터를 수집하는 데 사용되는 프로그램입니다. 일반적으로 웹 페이지를 가져오고, 필요한 데이터를 추출하며, 다른 페이지로 이동하는 등의 작업을 수행합니다. 이 글에서는 Python의 aiohttp 라이브러리를 사용하여 비동기적으로 웹 크롤러를 만드는 방법을 알아보겠습니다.

## aiohttp란?
aiohttp는 Python의 비동기 웹 프레임워크입니다. HTTP 클라이언트 및 서버를 구축하기 위해 사용되며, 비동기식 IO 작업을 처리하는 데에 특화되어 있습니다. aiohttp를 사용하면 웹 요청과 응답을 처리하기 위해 여러 개의 웹 요청을 동시에 수행할 수 있습니다.

## 필요한 패키지 설치하기
먼저, aiohttp를 사용하기 위해서는 해당 패키지를 설치해야 합니다. 아래의 명령을 사용하여 패키지를 설치합니다.

```
pip install aiohttp
```

## 비동기적으로 웹 페이지 가져오기
다음은 aiohttp를 사용하여 비동기적으로 웹 페이지를 가져오는 예제 코드입니다.

```python
import asyncio
import aiohttp

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, 'https://www.example.com')
        print(html)

loop = asyncio.get_event_loop()
loop.run_until_complete(main())
```

위의 코드에서는 `fetch` 함수를 정의하여 주어진 URL로 GET 요청을 보냅니다. `main` 함수에서는 aiohttp의 `ClientSession`을 사용하여 웹 페이지를 가져오고, 결과를 텍스트 형식으로 출력합니다. 마지막으로 `asyncio`의 이벤트 루프를 실행하여 비동기 작업을 실행합니다.

## 링크 따라가기
웹 크롤러는 일반적으로 다른 웹 페이지로 이동해야 할 때가 있습니다. aiohttp를 사용하여 링크를 따라가는 방법을 알아보겠습니다.

```python
import asyncio
import aiohttp
from bs4 import BeautifulSoup

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def get_links(session, url):
    html = await fetch(session, url)
    soup = BeautifulSoup(html, 'html.parser')
    links = soup.find_all('a')
    return [link['href'] for link in links]

async def main():
    async with aiohttp.ClientSession() as session:
        links = await get_links(session, 'https://www.example.com')
        for link in links:
            print(link)

loop = asyncio.get_event_loop()
loop.run_until_complete(main())
```

위의 코드에서는 `get_links` 함수를 정의하여 주어진 URL에서 모든 링크를 추출합니다. `main` 함수에서도 동일한 방식으로 `ClientSession`을 사용하여 링크를 얻고 출력합니다. 이를 위해 BeautifulSoup 라이브러리를 사용하여 HTML을 파싱하고 링크를 추출합니다.

## 결론
aiohttp를 사용하여 비동기적으로 웹 크롤러를 만들 수 있습니다. 이를 통해 더 빠른 웹 페이지 수집 및 데이터 추출이 가능하며, 링크 따라가기 등 다양한 작업을 수행할 수 있습니다. aiohttp를 활용하여 다양한 웹 크롤링 프로젝트를 만들어보세요!

## 참고 자료
- [aiohttp 공식 문서](https://docs.aiohttp.org/)
- [BeautifulSoup 공식 문서](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)