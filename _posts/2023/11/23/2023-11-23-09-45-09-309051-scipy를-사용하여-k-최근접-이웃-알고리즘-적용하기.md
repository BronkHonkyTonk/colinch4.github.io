---
layout: post
title: "[python] SciPy를 사용하여 K-최근접 이웃 알고리즘 적용하기"
description: " "
date: 2023-11-23
tags: [python]
comments: true
share: true
---

안녕하세요! 이번 포스팅에서는 Python의 SciPy 라이브러리를 활용하여 K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘을 적용하는 방법에 대해 알아보겠습니다.

## 1. K-최근접 이웃 알고리즘 소개

K-최근접 이웃 알고리즘은 지도 학습(Supervised Learning) 알고리즘 중 하나로, 분류(Classification) 문제를 해결하는 데 사용됩니다. 주어진 데이터 포인트의 클래스는 기준점(이웃)들 중 가장 가까운 K개의 이웃들의 클래스로 결정됩니다.

## 2. SciPy의 KDTree 모듈

K-최근접 이웃 알고리즘을 구현하기 위해 SciPy의 KDTree 모듈을 사용할 수 있습니다. KDTree는 공간 트리(Spatial Tree)의 일종으로, 데이터를 효율적으로 저장하고 검색하기 위해 사용됩니다.

먼저, SciPy를 설치하고 KDTree 모듈을 import합니다:

```python
pip install scipy
from scipy.spatial import KDTree
```

## 3. 데이터 준비

K-최근접 이웃 알고리즘을 적용하기 전에 데이터를 준비해야 합니다. 예를 들어, 아래와 같은 데이터셋이 있다고 가정해보겠습니다:

| 특징1 | 특징2 | 클래스 |
|-------|-------|--------|
|   1   |   2   |   A    |
|   2   |   3   |   A    |
|   3   |   1   |   B    |
|   4   |   2   |   B    |

위의 데이터셋은 두 개의 특징(feature)와 클래스(class)로 구성되어 있습니다.

## 4. K-최근접 이웃 알고리즘 적용

이제 KDTree 모듈을 사용하여 K-최근접 이웃 알고리즘을 적용해보겠습니다. 먼저, 데이터를 KDTree에 넣어줍니다:

```python
data = [[1, 2], [2, 3], [3, 1], [4, 2]]
kdtree = KDTree(data)
```

그리고 새로운 데이터 포인트에 대해 알고싶은 클래스를 예측하려면, `query` 메서드를 사용하여 가장 가까운 이웃의 클래스를 가져올 수 있습니다:

```python
new_data = [[2.5, 2.5]]
distances, indices = kdtree.query(new_data, k=1)
predicted_class = data[indices[0]]
```

위의 예제에서는 새로운 데이터 포인트 `[2.5, 2.5]`에 대해서 가장 가까운 이웃을 찾아서 그 클래스를 예측하였습니다.

## 5. 결과 확인

알고리즘을 적용한 결과를 확인해보겠습니다. 예측된 클래스를 출력해보면 `B`가 나와야 합니다:

```python
print(predicted_class)
```

결과는 아래와 같이 나올 것입니다:

```
B
```

## 6. 결론

이번 포스팅에서는 Python의 SciPy 라이브러리를 사용하여 K-최근접 이웃 알고리즘을 적용하는 방법을 알아보았습니다. KDTree 모듈을 사용하여 데이터를 효율적으로 저장하고 검색할 수 있으며, 이를 활용하여 KNN 알고리즘을 구현할 수 있습니다. 실제 데이터에 적용해보고 결과를 확인해보세요!