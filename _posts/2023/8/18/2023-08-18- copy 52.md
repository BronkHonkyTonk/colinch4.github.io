---
layout: post
title: "[python] Word2Vec 개념과 예제"
description: " "
date: 2023-08-18
tags: [Python,Gensim]
comments: true
share: true
---

Word2Vec 모델은 학습을 통해 단어의 의미와 관련성을 벡터로 표현합니다. 이렇게 얻은 벡터는 단어 간 유사도를 계산하거나 문서 유사도 분석 등 다양한 자연어 처리 작업에 활용할 수 있습니다. Word2Vec은 텍스트 데이터의 단어를 의미론적으로 유의미한 숫자로 표현하는 강력한 도구입니다.픽 모델링, 워드 임베딩, 문서 유사도 계산 등 다양한 NLP 작업을 수행할 수 있도록 도와줍니다. 다음은 Gensim의 주요 내용과 기능입니다:

1.  **워드 임베딩:** Gensim은 Word2Vec, FastText 등의 워드 임베딩 알고리즘을 제공하여 텍스트 데이터의 단어를 밀집 벡터로 변환합니다. 이를 통해 단어 간 의미적 관계 및 유사도를 계산할 수 있습니다.
    
2.  **토픽 모델링:** LDA(Latent Dirichlet Allocation)와 같은 토픽 모델링 알고리즘을 사용하여 텍스트 데이터의 주제를 추출하고 문서 간의 관계를 이해합니다.
    
3.  **문서 유사도 계산:** Gensim은 문서 간의 유사도를 측정하는 기능을 제공하며, TF-IDF와 코사인 유사도 등을 사용하여 문서의 유사성을 계산할 수 있습니다.
    
4.  **텍스트 전처리:** 텍스트 데이터의 토큰화, 불용어 제거, 대소문자 변환 등의 전처리 작업을 지원합니다.
    
5.  **워드 랭킹:** 단어의 랭킹을 계산하여 중요한 단어를 식별하거나 텍스트 요약에 활용할 수 있습니다.
    
6.  **말뭉치(Corpus) 관리:** Gensim은 말뭉치 데이터를 메모리 내에서 효율적으로 관리하고 처리할 수 있는 기능을 제공합니다.
    
7.  **텍스트 유틸리티:** 다양한 텍스트 데이터 처리를 위한 유틸리티 함수를 제공합니다.
    

아래는 Gensim을 사용한 워드 임베딩 예제의 간략한 코드입니다.

```python
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess

# 텍스트 데이터 준비
corpus = [
    "I enjoy reading books",
    "Natural language processing is fun",
    "Word embeddings capture semantic meaning"
]

# 간단한 전처리와 토큰화
tokenized_corpus = [simple_preprocess(sentence) for sentence in corpus]

# Word2Vec 모델 학습
model = Word2Vec(tokenized_corpus, vector_size=10, window=3, min_count=1, sg=1)

# 단어 'reading'의 임베딩 벡터 확인
embedding = model.wv['reading']
print("Embedding vector for 'reading':", embedding)` 
```
Gensim은 자연어 처리 작업을 간단하게 수행하고 효과적으로 처리할 수 있는 강력한 도구입니다. 주요 NLP 작업을 다루는 데 유용하며, 다양한 모델과 기능을 지원하여 텍스트 데이터를 분석하고 이해하는 데 도움을 줍니다.