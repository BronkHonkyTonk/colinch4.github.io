---
layout: post
title: "[python] 하이퍼파라미터 k 개념과 예제"
description: " "
date: 2023-08-18
tags: [Python,딥러닝]
comments: true
share: true
---

하이퍼파라미터 k는 k-Nearest Neighbors (k-NN) 알고리즘에서 중요한 요소로, 주어진 데이터 포인트에 대해 몇 개의 최근접 이웃을 선택할 것인지를 결정하는 매개변수입니다. 올바른 k 값을 선택하는 것은 모델의 성능에 큰 영향을 미칩니다.

적절한 k 값을 선택하는 방법은 데이터와 문제에 따라 다르지만, 일반적으로 교차 검증을 통해 최적의 k 값을 찾는 것이 좋습니다. 작은 k 값은 데이터의 노이즈에 민감하게 작용하며 과적합의 가능성이 높습니다. 반면에 큰 k 값은 결정 경계가 부드러워지며 노이즈에 대한 영향이 줄어듭니다.

간단한 k 설정 예제로 설명해보겠습니다.

```python
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 데이터 생성
X, y = make_classification(n_samples=100, n_features=20, random_state=1)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# 다양한 k 값에 대한 분류 모델 생성 및 평가
for k in [1, 3, 5, 7]:
    knn_classifier = KNeighborsClassifier(n_neighbors=k)
    knn_classifier.fit(X_train, y_train)
    y_pred = knn_classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy with k =", k, ":", accuracy)` 
```
위의 코드에서는 make_classification 함수를 사용하여 가상의 분류 데이터를 생성하고, 다양한 k 값을 사용하여 KNeighborsClassifier를 생성하고 예측 성능을 평가합니다. for 루프를 통해 여러 개의 k 값에 대해 모델을 생성하고 평가하여 최적의 k 값을 선택할 수 있습니다.

교차 검증을 통해 여러 가지 k 값에 대해 성능을 평가하고, 그래프를 그려 최적의 k 값을 결정하는 것도 좋은 방법입니다. 이를 통해 데이터에 맞는 적절한 k 값을 찾아 모델의 예측 성능을 최대화할 수 있습니다.