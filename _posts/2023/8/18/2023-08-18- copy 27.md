---
layout: post
title: "[파이썬] 최근접 이웃 선택 개념과 예제"
description: " "
date: 2023-08-18
tags: [Python,딥러닝]
comments: true
share: true
---

최근접 이웃 선택은 k-Nearest Neighbors (k-NN) 알고리즘의 중요한 단계 중 하나입니다. 주어진 데이터 포인트에 대해 가장 가까운 이웃들을 선택하는 과정으로, 모델의 예측을 수행하기 위해 사용됩니다. 이웃의 개수 k는 사용자가 지정하는 하이퍼파라미터로, 더 작은 k 값은 더 정확한 예측을 만들 수 있지만 노이즈에 민감해질 수 있습니다.

간단한 최근접 이웃 선택 예제로 설명해보겠습니다.

```python
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

## 데이터 생성
X, y = make_classification(n_samples=100, n_features=20, random_state=1)

## 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

## 최근접 이웃 분류기 생성 (k=3)
knn_classifier = KNeighborsClassifier(n_neighbors=3)
knn_classifier.fit(X_train, y_train)

## 예측 성능 평가
y_pred = knn_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy of k-NN Classifier:", accuracy)` 
```
위의 코드에서는 make_classification 함수를 사용하여 가상의 분류 데이터를 생성하고, KNeighborsClassifier를 사용하여 최근접 이웃 분류기를 생성합니다. 이웃의 개수 `n_neighbors`는 3으로 설정하였습니다. 생성된 분류기를 학습시키고 예측 성능을 평가합니다.

최근접 이웃 선택은 주어진 데이터 포인트와 가장 가까운 k개의 이웃들을 선택하여 분류나 회귀 예측을 수행하는데 사용됩니다. k-NN 알고리즘에서는 이웃들의 클래스 비율을 통해 분류를 수행하거나, 이웃들의 값의 평균을 통해 회귀 예측을 수행합니다. 이웃의 개수 k를 조절하여 모델의 성능을 조절할 수 있습니다.