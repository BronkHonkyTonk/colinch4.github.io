---
layout: post
title: "[python] Random Forests 개념"
description: " "
date: 2023-08-18
tags: [Python,SVM]
comments: true
share: true
---


Random Forests는 머신러닝에서 사용되는 강력한 앙상블 학습 방법 중 하나입니다. 앙상블 학습은 여러 개별 모델을 결합하여 보다 강력하고 일반화된 모델을 구축하는 기법을 말합니다. Random Forests는 이러한 앙상블 학습의 한 형태로서, 의사결정트리(Decision Tree)를 기반으로 합니다.

**Random Forests의 주요 개념:**

-   **의사결정트리 (Decision Tree):** 의사결정트리는 데이터를 분할하여 결정 경로를 만들어내는 모델입니다. 하지만 단일 의사결정트리는 과적합(Overfitting) 경향이 있을 수 있습니다.
    
-   **앙상블 학습 (Ensemble Learning):** Random Forests는 여러 개의 의사결정트리를 생성하고 이를 결합하여 보다 강력한 모델을 구축합니다. 이는 개별 의사결정트리의 약점을 보완하여 더 일반화된 예측을 가능하게 합니다.
    
-   **부트스트랩 샘플링 (Bootstrap Sampling):** 각 트리를 생성하기 위해 원본 데이터에서 중복을 허용한 샘플을 무작위로 선택합니다. 이를 부트스트랩 샘플링이라고 하며, 이를 통해 각 트리가 조금씩 다른 데이터로 학습됩니다.
    
-   **랜덤 특성 선택 (Random Feature Selection):** 각 분할마다 데이터의 일부 특성들을 무작위로 선택하여 사용합니다. 이를 통해 각 트리가 다양한 특성을 사용하도록 하여 모델의 다양성을 증가시킵니다.
    

**Random Forests의 장점:**

-   과적합을 줄여 안정적인 예측을 가능하게 합니다.
-   다양한 특성을 사용하므로 다양성이 확보되며, 일반화 성능이 향상됩니다.
-   높은 차원의 데이터에서도 효과적으로 동작합니다.
-   앙상블 학습의 특성으로 인해 노이즈에 덜 민감합니다.

Random Forests는 분류와 회귀 문제 모두에 사용할 수 있으며, 다양한 분야에서 널리 활용되고 있는 알고리즘 중 하나입니다.