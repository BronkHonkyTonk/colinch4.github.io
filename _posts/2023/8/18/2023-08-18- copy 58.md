---
layout: post
title: "[python] 텍스트 데이터 개념과 예제"
description: " "
date: 2023-08-18
tags: [Python,Gensim]
comments: true
share: true
---

텍스트 데이터를 자연어 처리 작업에 사용하기 전에 전처리 과정을 거쳐야 합니다. 텍스트 전처리는 데이터를 정제하고 토큰화하며, 불필요한 정보를 제거하여 모델 학습에 적합한 형태로 가공하는 과정입니다. 아래는 간단한 텍스트 전처리 예제를 보여드리겠습니다.

```python
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

# 원본 텍스트
text = "Natural language processing is a field of artificial intelligence."

# 소문자 변환
text = text.lower()

# 문장 부호 제거
text = re.sub(r'[^\w\s]', '', text)

# 토큰화
tokens = word_tokenize(text)

# 불용어 제거
stop_words = set(stopwords.words('english'))
filtered_tokens = [word for word in tokens if word not in stop_words]

# 어간 추출 (Stemming)
stemmer = PorterStemmer()
stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]

# 전처리 결과 출력
print("Original Text:", text)
print("Preprocessed Tokens:", stemmed_tokens)` 
```
위의 코드에서는 NLTK(Natural Language Toolkit) 라이브러리를 사용하여 텍스트 전처리 과정을 보여줍니다.

1.  `lower()`: 텍스트를 소문자로 변환합니다.
2.  정규표현식을 사용하여 문장 부호를 제거합니다.
3.  `word_tokenize()`: 문장을 단어로 토큰화합니다.
4.  NLTK의 불용어(stopwords) 목록을 사용하여 불필요한 단어를 제거합니다.
5.  `PorterStemmer()`: 어간 추출을 통해 단어를 원형으로 변환합니다.

이 예제를 통해 텍스트 전처리 과정을 단계별로 이해하실 수 있을 것입니다. 실제 작업에서는 데이터의 특성에 따라 추가적인 전처리 단계가 필요할 수 있습니다.