---
layout: post
title: "[python] FastText 개념과 예제"
description: " "
date: 2023-08-18
tags: [Python,Gensim]
comments: true
share: true
---

FastText는 Word2Vec의 확장된 버전으로, 단어를 하위 단위(subword)까지 분해하여 단어의 의미를 더 잘 파악할 수 있도록 설계된 워드 임베딩 알고리즘입니다. FastText는 OOV(Out-Of-Vocabulary) 문제에 대한 대처력을 갖추고, 희귀한 단어에 대한 효과적인 임베딩을 생성할 수 있습니다.

간단한 FastText 예제로 설명해보겠습니다. Gensim 라이브러리를 사용하여 FastText 모델을 학습시키고 테스트하는 과정을 보여드리겠습니다.

```python
from gensim.models import FastText
from gensim.utils import simple_preprocess

# 텍스트 데이터 준비
corpus = [
    "I enjoy reading books",
    "Natural language processing is fun",
    "Word embeddings capture semantic meaning"
]

# 간단한 전처리와 토큰화
tokenized_corpus = [simple_preprocess(sentence) for sentence in corpus]

# FastText 모델 학습
model = FastText(tokenized_corpus, vector_size=10, window=3, min_count=1, sg=1)

# 단어 'reading'의 임베딩 벡터 확인
embedding = model.wv['reading']
print("Embedding vector for 'reading':", embedding)` 
```
위의 코드에서는 Gensim을 사용하여 간단한 텍스트 데이터를 전처리하고, FastText 모델을 학습합니다. 파라미터 설정은 Word2Vec과 유사하게 `vector_size`, `window`, `min_count`, `sg` 등을 사용합니다.

FastText는 단어를 하위 단위(subword)로 분해하여 학습하는 특징이 있습니다. 이를 통해 OOV 문제에 강건하게 대응하며, 희귀한 단어나 단어의 변형에 대한 임베딩을 생성할 수 있습니다. FastText는 단어의 subword 정보를 활용하여 보다 풍부한 의미를 표현할 수 있는 워드 임베딩 알고리즘입니다.