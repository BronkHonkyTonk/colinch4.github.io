---
layout: post
title: "[python] 배깅(Bagging, Bootstrap Aggregating) 개념 예제"
description: " "
date: 2023-08-18
tags: [Python,SVM]
comments: true
share: true
---


배깅(Bagging, Bootstrap Aggregating)은 앙상블 학습의 한 형태로, 여러 개의 모델을 생성하고 그 결과를 조합하여 보다 안정적이고 일반화된 예측을 수행하는 기법입니다. 주로 분류와 회귀 문제에서 사용되며, 과적합을 줄이고 모델의 예측 성능을 향상시키는 데 도움을 줍니다.

배깅의 핵심 아이디어는 무작위 샘플링을 통해 여러 개의 모델을 독립적으로 학습하고 그 결과를 조합하는 것입니다. 각 모델이 데이터의 서로 다른 부분집합에 대해 학습하기 때문에 다양성이 높아지고, 이는 과적합을 방지하고 모델의 안정성을 높이는 데 도움을 줍니다.

간단한 배깅 예제로 설명해보겠습니다. 아래의 데이터는 주어진 x 값에 대해 y 값을 예측하는 문제입니다.


이 데이터를 기반으로 배깅을 사용하여 회귀 모델을 구축하겠습니다.

```python
import numpy as np
from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor

# 데이터 준비
x = np.array([1, 2, 3, 4, 5, 6, 7]).reshape(-1, 1)
y = np.array([4, 7, 10, 13, 16, 19, 22])

# 배깅 회귀 모델 생성
base_model = DecisionTreeRegressor()  # 기본 모델
bagging_model = BaggingRegressor(base_model, n_estimators=5, random_state=1)  # 5개의 모델을 사용하여 배깅 모델 생성

# 모델 학습
bagging_model.fit(x, y)

# 예측
x_new = np.array([8]).reshape(-1, 1)
predicted_y = bagging_model.predict(x_new)
print("Predicted y for x =", x_new[0][0], ":", predicted_y[0])` 
```
위의 코드에서는 DecisionTreeRegressor를 기본 모델로 사용하여 BaggingRegressor를 생성하고 학습시키는 예제입니다. 이를 통해 배깅이 어떻게 여러 모델을 결합하여 예측하는지를 확인할 수 있습니다.