---
layout: post
title: "[파이썬] k-Nearest Neighbors (k-NN) 핵심 개념"
description: " "
date: 2023-08-18
tags: [python]
comments: true
share: true
---

k-Nearest Neighbors (k-NN)는 지도 학습의 분류 및 회귀 문제를 해결하기 위한 알고리즘 중 하나입니다. 주어진 데이터 포인트 주변의 k개의 최근접 이웃(neighbor)을 기반으로 예측하는 방법입니다.

k-NN의 핵심 개념은 다음과 같습니다:

1.  **거리 측정:** k-NN은 데이터 포인트 간의 거리를 측정하여 가장 가까운 이웃들을 찾습니다. 일반적으로 유클리드 거리나 맨하탄 거리 등이 사용됩니다.
    
2.  **최근접 이웃 선택:** 주어진 데이터 포인트에 대해 가장 가까운 k개의 이웃을 선택합니다. 이웃의 개수 k는 사용자가 지정합니다.
    
3.  **다수결 투표 (분류) 또는 평균 (회귀):** 분류 문제의 경우, k개의 이웃들 중에서 가장 많은 클래스를 선택하여 예측합니다. 회귀 문제의 경우, k개의 이웃들의 타겟 값의 평균을 예측 값으로 사용합니다.
    
4.  **하이퍼파라미터 k 설정:** k-NN에서 중요한 하이퍼파라미터는 k입니다. 적절한 k 값을 선택하는 것이 모델의 성능에 영향을 미칩니다. 작은 k 값은 노이즈에 민감하게 작용하며, 큰 k 값은 부드럽고 일반화된 결정 경계를 생성합니다.
    

k-NN은 간단하면서도 유용한 알고리즘이지만, 데이터셋이 크거나 고차원일 경우에는 계산 비용이 증가하고 예측 성능이 떨어질 수 있습니다. 또한 데이터의 스케일에 민감하게 작용할 수 있습니다. 따라서 데이터 전처리 및 k 값의 조절이 중요한 요소입니다.