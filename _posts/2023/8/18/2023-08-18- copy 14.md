---
layout: post
title: "[파이썬] 서브세트의 다수결 투표(Majority Voting of Subsets) 개념과 예제"
description: " "
date: 2023-08-18
tags: [SVM]
comments: true
share: true
---


서브세트의 다수결 투표(Majority Voting of Subsets)는 앙상블 학습에서 사용되는 개념 중 하나로, 각 개별 모델이 데이터의 일부를 사용하여 예측한 결과를 다수결 투표를 통해 최종 예측 결과를 결정하는 방식입니다. 이를 통해 다양한 모델의 결과를 결합하여 모델의 예측을 강화하고 안정성을 높입니다.

서브세트의 다수결 투표는 주로 보팅(Voting) 앙상블 학습에서 사용되며, 분류 문제에서 특히 효과적입니다. 이 개념은 다양한 개별 모델들의 예측 결과를 조합하여 최종 예측 클래스를 결정하거나, 각 클래스에 속할 확률들을 평균하여 최종 예측 확률을 계산합니다.

간단한 예제로 설명해보겠습니다. 아래의 세 개의 개별 모델이 데이터를 예측한 결과를 서브세트의 다수결 투표를 통해 최종 예측 결과를 결정합니다.

-   모델 A: 클래스 A로 예측
-   모델 B: 클래스 B로 예측
-   모델 C: 클래스 A로 예측

다수결 투표를 통해 최종 예측 결과는 클래스 A가 됩니다.

아래는 scikit-learn 라이브러리를 사용하여 보팅 분류기에서 서브세트의 다수결 투표를 구현하는 예제 코드입니다.

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

## 데이터 로드
iris = load_iris()
X = iris.data
y = iris.target

## 분류기 생성
clf1 = LogisticRegression(random_state=1)
clf2 = DecisionTreeClassifier(random_state=1)
clf3 = SVC(probability=True, random_state=1)

## 보팅 분류기 생성
voting_clf = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('svc', clf3)], voting='soft')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

## 보팅 분류기 학습 및 평가
voting_clf.fit(X_train, y_train)
accuracy = voting_clf.score(X_test, y_test)
print("Voting Classifier Accuracy:", accuracy)` 
```
위의 코드에서는 보팅 분류기에서 서브세트의 다수결 투표를 사용하여 붓꽃(iris) 데이터의 클래스를 예측하는 예제를 구현하고 예측 성능을 평가합니다. `voting` 매개변수를 'soft'로 설정하여 소프트 보팅 방식을 사용합니다.