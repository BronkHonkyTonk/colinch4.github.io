---
layout: post
title: "[파이썬] TF-IDF(Term Frequency-Inverse Document Frequency) 개념과 예제"
description: " "
date: 2023-08-18
tags: [gensim]
comments: true
share: true
---

TF-IDF(Term Frequency-Inverse Document Frequency)는 텍스트 데이터에서 단어의 상대적 중요성을 나타내는 통계적 척도입니다. 이는 특정 문서에서 자주 나타나는 단어가 해당 문서에서 중요하다는 가정과 동시에, 여러 문서에서 공통적으로 나타나는 단어는 전반적으로 중요하지 않다는 가정에 기반합니다. TF-IDF는 문서 검색, 정보 검색, 텍스트 마이닝 등 다양한 자연어 처리 작업에 사용됩니다.

간단한 TF-IDF 예제를 통해 개념을 설명해보겠습니다. Gensim 라이브러리를 사용하여 TF-IDF 모델을 학습하고 문서의 TF-IDF 벡터를 생성하는 방법을 보여줍니다.

```python
from gensim.models import TfidfModel
from gensim.corpora import Dictionary
from gensim.matutils import corpus2dense

## 텍스트 데이터 준비
corpus = [
    "I enjoy reading books",
    "Natural language processing is fun",
    "Word embeddings capture semantic meaning"
]

## 간단한 전처리와 토큰화
tokenized_corpus = [text.split() for text in corpus]

## 단어 사전 생성
dictionary = Dictionary(tokenized_corpus)

## 문서-단어 매트릭스 생성
corpus_bow = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]

## TF-IDF 모델 학습
tfidf_model = TfidfModel(corpus_bow)

## TF-IDF 벡터를 밀집 행렬로 변환
corpus_tfidf = tfidf_model[corpus_bow]
dense_matrix = corpus2dense(corpus_tfidf, num_terms=len(dictionary)).T

## TF-IDF 벡터 출력
for i, doc in enumerate(corpus):
    print(f"TF-IDF vector for document {i+1}:")
    for j, weight in enumerate(dense_matrix[i]):
        if weight != 0:
            print(f"  '{dictionary[j]}': {weight:.4f}")` 
```
위의 코드에서는 Gensim을 사용하여 간단한 텍스트 데이터를 전처리하고 TF-IDF 모델을 학습합니다. TF-IDF 벡터를 밀집 행렬로 변환하여 각 문서의 단어별 TF-IDF 가중치를 확인합니다.

TF-IDF는 특정 문서에서 단어의 빈도가 얼마나 높은지와 해당 단어가 다른 문서에서 얼마나 일반적인지를 고려하여 중요한 단어를 찾는 데 사용됩니다. 이를 통해 문서 간 유사도 계산이나 키워드 추출 등 다양한 텍스트 마이닝 작업에 활용할 수 있습니다.