---
layout: post
title: "[파이썬] 하드/소프 마진 개념과 예제"
description: " "
date: 2023-08-18
tags: [python]
comments: true
share: true
---


하드/소프 마진 SVM은 Support Vector Machines (SVM)에서 사용되는 개념으로, 데이터 포인트와 결정 경계 사이의 간격(마진)을 조절하는 방식을 나타냅니다. 이해를 돕기 위해 각각의 개념에 대해 설명과 예제를 제시하겠습니다.

**하드 마진 SVM:** 하드 마진 SVM은 데이터 포인트가 결정 경계와 마진 사이에 위치하도록 하는 것을 목표로 합니다. 이는 데이터가 완벽하게 선형 분리 가능한 경우에 적용됩니다. 하지만 이상치나 노이즈가 있는 데이터에서는 성능이 저하될 수 있습니다.

아래는 하드 마진 SVM의 예제 코드입니다.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.svm import SVC

## 데이터 생성
X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=0)

## 하드 마진 SVM 모델 생성
svm_model = SVC(kernel='linear', C=float('inf'))  # C 값을 무한대로 설정하여 하드 마진을 구현
svm_model.fit(X, y)

## 결정 경계 그리기
h = .02
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Hard Margin SVM Example')
plt.show()` 
```
**소프트 마진 SVM:** 소프트 마진 SVM은 데이터 포인트를 결정 경계와 마진 사이에 위치시키되, 일부는 마진 안쪽에 위치시키는 것을 허용합니다. 이는 데이터가 완벽하게 선형 분리되지 않는 경우에 적용됩니다. 이상치나 노이즈를 무시하고 더 유연한 결정 경계를 만들 수 있습니다.

아래는 소프트 마진 SVM의 예제 코드입니다.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.svm import SVC

## 데이터 생성
X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=0)

## 소프트 마진 SVM 모델 생성
svm_model = SVC(kernel='linear', C=1.0)  # C 값을 조정하여 소프트 마진을 구현
svm_model.fit(X, y)

## 결정 경계 그리기
h = .02
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Soft Margin SVM Example')
plt.show()` 
```
위의 코드에서는 하드 마진 SVM과 소프트 마진 SVM을 구현하여 데이터를 분류하는 결정 경계를 시각화합니다. 하드 마진 SVM의 경우 C 값을 무한대로 설정하여 모든 데이터를 정확히 분류하려고 하며, 소프트 마진 SVM의 경우 C 값을 조정하여 일부 오분류를 허용하고 결정 경계를 유연하게 만듭니다.