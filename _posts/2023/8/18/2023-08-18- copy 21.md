---
layout: post
title: "[파이썬] Gradient Boosting 개념과 예제"
description: " "
date: 2023-08-18
tags: [python]
comments: true
share: true
---


Gradient Boosting은 앙상블 학습의 한 형태로, 여러 개의 약한 학습기(weak learner)를 순차적으로 학습하고 이들을 조합하여 강력한 예측 모델을 만드는 기법입니다. Gradient Boosting은 오차를 보완하는 새로운 모델을 만드는 데에 그레디언트(기울기) 정보를 사용하며, 오차를 최소화하도록 모델을 조정해 나갑니다.

간단한 Gradient Boosting 예제로 설명해보겠습니다.

```python
import numpy as np
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error

## 데이터 생성
X, y = make_regression(n_samples=100, n_features=1, noise=0.3, random_state=1)

## 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

## 약한 학습기 생성
base_model = DecisionTreeRegressor(max_depth=1)

## Gradient Boosting 회귀 모델 생성
gb_regressor = GradientBoostingRegressor(base_model, n_estimators=100, learning_rate=0.1, random_state=1)
gb_regressor.fit(X_train, y_train)

## 예측 성능 평가
y_pred = gb_regressor.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)` 
```
위의 코드에서는 make_regression 함수를 사용하여 가상의 회귀 데이터를 생성하고, 약한 학습기로 의사결정트리의 "max_depth=1"인 모델을 사용합니다. 이를 GradientBoostingRegressor를 사용하여 Gradient Boosting 회귀 모델을 만들고 학습시키며, 예측 성능을 평가합니다.

Gradient Boosting은 부스팅 알고리즘 중 하나로, 이전 모델의 오차를 보완하도록 새로운 모델을 생성하고 학습하는 방식입니다. 각 모델이 예측한 결과를 합하여 최종 예측을 만들어내며, 회귀와 분류 문제에 모두 적용될 수 있는 강력한 앙상블 기법입니다.