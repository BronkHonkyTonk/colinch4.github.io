---
layout: post
title: "[python] 상블 학습에서의 결합(Combination) 예제"
description: " "
date: 2023-08-18
tags: [Python,딥러닝]
comments: true
share: true
---

앙상블 학습에서의 결합(Combination)은 다양한 약한 학습기(Weak Learner)를 조합하여 강력한 예측 모델을 생성하는 과정을 의미합니다. 앙상블의 결합은 다양한 개별 모델의 예측 결과를 조합하여 최종 예측을 수행함으로써 모델의 성능을 향상시키는 것을 목표로 합니다.

간단한 앙상블의 결합 예제로 설명해보겠습니다.

```python
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score

# 데이터 생성
X, y = make_classification(n_samples=100, n_features=20, random_state=1)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# 다양한 약한 학습기 생성
model1 = DecisionTreeClassifier(max_depth=2)
model2 = DecisionTreeClassifier(max_depth=4)
model3 = DecisionTreeClassifier(max_depth=6)

# 앙상블 분류기 생성 (VotingClassifier)
ensemble_classifier = VotingClassifier(estimators=[('model1', model1), ('model2', model2), ('model3', model3)], voting='hard')
ensemble_classifier.fit(X_train, y_train)

# 예측 성능 평가
y_pred = ensemble_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Ensemble Classifier Accuracy:", accuracy)` 
```
위의 코드에서는 make_classification 함수를 사용하여 가상의 분류 데이터를 생성하고, 세 개의 약한 학습기로 의사결정트리 모델을 사용합니다. 이를 VotingClassifier를 사용하여 다양한 모델들을 결합하여 앙상블 분류기를 생성하고 학습시키며, 예측 성능을 평가합니다.

VotingClassifier는 다양한 개별 모델들의 예측 결과를 조합하여 최종 예측을 수행하는 방식입니다. `voting` 매개변수에 'hard'를 사용하여 다수결 투표를 하여 최종 예측 클래스를 결정합니다. 이렇게 결합된 앙상블 분류기는 개별 모델보다 더 좋은 예측 성능을 보일 수 있습니다.