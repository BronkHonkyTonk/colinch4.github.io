---
layout: post
title: "[파이썬][AI Chatbot] 토큰화(Tokenization) 예제"
description: " "
date: 2023-08-18
tags: [AI챗봇]
comments: true
share: true
---


토큰화(Tokenization)는 텍스트를 작은 단위로 분할하는 과정을 말합니다. 이 작은 단위는 토큰(token)이라고 불리며, 일반적으로 단어, 구두점, 숫자 등으로 나뉩니다. 토큰화는 자연어 처리에서 중요한 전처리 단계로, 텍스트를 분석 가능한 작은 조각으로 나누어줍니다.

**토큰화의 예시:**

원본 텍스트: "I love natural language processing!"

토큰화 결과: ["I", "love", "natural", "language", "processing", "!"]

토큰화는 문장을 단어로 나누는 것이 대표적인 형태지만, 문장을 단어 뿐만 아니라 구두점, 숫자 등의 다양한 요소로 나누는 작업도 수행합니다.

**예제 코드:**

Python의 NLTK(Natural Language Toolkit) 라이브러리를 사용하여 토큰화를 수행하는 간단한 예제 코드를 보겠습니다.

```python
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize

nltk.download('punkt')

## 문장 토큰화 예제
text = "Hello, world. Natural language processing is interesting."
sentences = sent_tokenize(text)
print("Sentence tokens:", sentences)

## 단어 토큰화 예제
sentence = "I love natural language processing!"
words = word_tokenize(sentence)
print("Word tokens:", words)` 
```
위 코드에서 `sent_tokenize` 함수는 텍스트를 문장 단위로 토큰화하며, `word_tokenize` 함수는 문장을 단어 단위로 토큰화합니다. 결과는 각각 문장 또는 단어로 나뉘어진 리스트 형태로 반환됩니다.

출력 예시:

```less
Sentence tokens: ['Hello, world.', 'Natural language processing is interesting.']
Word tokens: ['I', 'love', 'natural', 'language', 'processing', '!']` 
```
이렇게 토큰화된 텍스트는 더 나은 문장 분석 및 처리를 위해 다양한 자연어 처리 작업에 활용될 수 있습니다.