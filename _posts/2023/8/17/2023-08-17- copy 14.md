---
layout: post
title: "[TensorFlow] Dropout Layer  예제"
description: " "
date: 2023-08-17
tags: [tensorflow]
comments: true
share: true
---


`tf.keras.layers.Dropout` 레이어는 과적합을 방지하기 위해 무작위로 일부 뉴런을 제거하는 역할을 합니다. 아래는 `tf.keras.layers.Dropout` 레이어를 사용한 예제입니다.

```python
import tensorflow as tf

## 더미 데이터 생성
dummy_data = tf.random.normal(shape=(4, 8))

## Dropout 레이어 정의
dropout_layer = tf.keras.layers.Dropout(rate=0.5)  # 제거할 뉴런의 비율을 50%로 설정

## Dropout 레이어 실행
dropped_data = dropout_layer(dummy_data, training=True)  # training=True는 학습 모드에서 Dropout을 활성화

print("Input data:")
print(dummy_data)
print("\nDropped data:")
print(dropped_data)` 
```
위 예제에서는 `tf.keras.layers.Dropout` 레이어를 사용하여 4x8 크기의 더미 데이터에 대한 레이어를 정의하고 실행합니다. `rate` 매개변수로 제거할 뉴런의 비율을 설정하고, `training=True`로 설정하여 학습 중에 Dropout을 활성화합니다.

실행 결과 예시:

```lua
Input data:
[[-0.41993752  0.36293575 -0.40710697 -0.5484049  -0.5559952   0.13150997  1.0876192   0.525524  ]
 [ 1.1484327  -1.2524178   1.2162354   0.02424201 -0.29441628  0.08959706 -0.20130843 -1.1253488 ]
 [-0.6327129  -1.4588693   0.20154816  1.218564    0.19527164 -0.6523673   0.7580649   0.79459155]
 [ 1.7898821  -1.434938    1.7511538   0.19450805  0.4098562  -0.7632403  -0.5385266   0.6019916 ]]

Dropped data:
[[-0.83987504  0.7258715  -0.          -1.0968097  -1.1119903   0.26301995  2.1752384   1.051048  ]
 [ 0.         -2.5048354   0.         -0.04848402 -0.58883256  0.         -0.         -2.2506976 ]
 [-0.          -2.9177387   0.40309632  2.437128    0.         -1.3047347   0.         -0.        ]
 [ 3.5797644  -0.          0.          0.3890161   0.8197124  -0.          0.          1.2039832 ]]` 
```
위에서 확인할 수 있듯이, 입력 데이터와 Dropout을 적용한 데이터가 출력됩니다. `tf.keras.layers.Dropout` 레이어를 사용하면 무작위로 일부 뉴런이 제거되어 과적합을 방지하고 모델의 일반화 능력을 향상시킬 수 있습니다.