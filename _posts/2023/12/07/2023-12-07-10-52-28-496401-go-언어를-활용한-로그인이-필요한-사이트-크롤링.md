---
layout: post
title: "[go] Go 언어를 활용한 로그인이 필요한 사이트 크롤링"
description: " "
date: 2023-12-07
tags: [go]
comments: true
share: true
---

이번 블로그 포스트에서는 Go 언어를 사용하여 로그인이 필요한 사이트를 크롤링하는 방법에 대해 알아보겠습니다. 여기서는 Go 언어의 `net/http` 패키지와 `goquery` 라이브러리를 이용하여 크롤링을 진행할 것입니다.

## 1. 필수 패키지 설치

먼저, Go 언어를 사용하여 크롤링을 하기 위해 `goquery` 패키지를 설치해야 합니다. 아래 명령어를 이용하여 패키지를 설치합니다.

```shell
go get github.com/PuerkitoBio/goquery
```

## 2. 로그인 요청 보내기

로그인이 필요한 사이트를 크롤링하기 위해서는 먼저 로그인 요청을 보내야 합니다. 일반적으로 로그인 요청은 POST 방식으로 이루어지며, 사용자의 아이디와 비밀번호를 포함하고 있습니다.

```go
package main

import (
    "fmt"
    "github.com/PuerkitoBio/goquery"
    "io/ioutil"
    "net/http"
    "net/url"
    "strings"
)

func main() {
    // 로그인 요청을 보낼 URL과 POST 데이터
    loginURL := "https://example.com/login"
    postData := url.Values{
        "username": {"your_username"},
        "password": {"your_password"},
    }

    // 로그인 요청 보내기
    client := &http.Client{}
    req, err := http.NewRequest("POST", loginURL, strings.NewReader(postData.Encode()))
    if err != nil {
        panic(err)
    }
    req.Header.Add("Content-Type", "application/x-www-form-urlencoded")
    resp, err := client.Do(req)
    if err != nil {
        panic(err)
    }
    defer resp.Body.Close()

    // 로그인이 성공했는지 확인
    if resp.StatusCode == http.StatusOK {
        fmt.Println("로그인 성공")
    }
}
```

위 코드에서는 `loginURL` 변수에 로그인 요청을 보낼 URL을, `postData` 변수에는 로그인에 필요한 아이디와 비밀번호를 포함한 POST 데이터를 저장합니다. 그리고 `http.NewRequest()` 함수를 통해 POST 요청을 생성하고, `client.Do()` 함수를 호출하여 실제로 로그인 요청을 보냅니다. 이때 요청에는 `Content-Type` 헤더를 설정해야 합니다.

## 3. 크롤링하기

로그인 요청이 성공했다면, 이제 크롤링을 진행할 수 있습니다. 아래 코드는 `goquery` 라이브러리를 이용하여 특정 페이지를 크롤링하는 예제입니다.

```go
// 크롤링할 페이지 URL
pageURL := "https://example.com/page"

// 페이지에 접근하기 위한 HTTP GET 요청 보내기
resp, err := client.Get(pageURL)
if err != nil {
    panic(err)
}
defer resp.Body.Close()

// HTTP 응답 바디 읽기
body, err := ioutil.ReadAll(resp.Body)
if err != nil {
    panic(err)
}

// 응답 바디를 파싱하여 원하는 정보 추출하기
doc, err := goquery.NewDocumentFromReader(strings.NewReader(string(body)))
if err != nil {
    panic(err)
}

// 원하는 정보 추출 예시: 링크 추출하기
doc.Find("a").Each(func(i int, s *goquery.Selection) {
    link, _ := s.Attr("href")
    fmt.Println(link)
})
```

위 코드에서는 `pageURL` 변수에 크롤링할 페이지의 URL을 저장하고, `client.Get()` 함수를 통해 해당 페이지에 HTTP GET 요청을 보냅니다. 그리고 `ioutil.ReadAll()` 함수를 사용하여 응답 바디를 읽고, `goquery.NewDocumentFromReader()` 함수를 사용하여 응답 바디를 파싱합니다. 이후 `Find()` 함수와 `Each()` 함수를 이용하여 원하는 정보를 추출합니다.

이제 Go 언어를 활용하여 로그인이 필요한 사이트를 크롤링하는 방법을 알게 되었습니다. `net/http` 패키지와 `goquery` 라이브러리를 이용하면 다양한 크롤링 작업을 쉽게 수행할 수 있습니다. 자세한 내용은 공식 문서를 참고하시기 바랍니다.

## 참고 자료
- Go 언어 공식 문서: [https://golang.org/doc/](https://golang.org/doc/)
- goquery 라이브러리: [https://github.com/PuerkitoBio/goquery](https://github.com/PuerkitoBio/goquery)