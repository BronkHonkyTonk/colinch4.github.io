---
layout: post
title: "[go] Go 언어를 이용한 웹 크롤링 성능 최적화 방법"
description: " "
date: 2023-12-07
tags: [go]
comments: true
share: true
---

## 소개
웹 크롤링은 웹페이지에서 데이터를 수집하는 프로세스를 의미하며, 이는 다양한 분야에서 매우 유용합니다. Go 언어는 웹 크롤링 작업에 뛰어난 성능과 생산성을 제공하는데, 이 글에서는 Go 언어를 이용한 웹 크롤링 성능 최적화 방법에 대해 알아보겠습니다.

## 1. 동시성 활용
Go 언어는 강력한 동시성 모델을 가지고 있어, 여러 웹페이지를 동시에 크롤링하는 것이 가능합니다. `goroutine`과 `channel`을 이용하여 병렬로 작업을 수행할 수 있으며, 이를 활용하여 크롤링 작업의 속도를 대폭 향상시킬 수 있습니다.

```go
package main

import (
	"fmt"
	"net/http"
	"sync"
)

func fetch(url string, wg *sync.WaitGroup) {
	defer wg.Done()

	resp, err := http.Get(url)
	if err != nil {
		fmt.Println(err)
		return
	}

	// 크롤링 작업 수행
}

func main() {
	urls := []string{
		"https://example.com/page1",
		"https://example.com/page2",
		"https://example.com/page3",
	}

	var wg sync.WaitGroup
	wg.Add(len(urls))

	for _, url := range urls {
		go fetch(url, &wg)
	}

	wg.Wait()
}
```

위의 예시에서 `fetch` 함수는 각각의 URL에 대해 크롤링 작업을 수행합니다. `sync.WaitGroup`을 이용하여 모든 작업이 완료될 때까지 대기하고, `goroutine`을 이용하여 각 URL에 대해 병렬로 작업을 수행합니다.

## 2. 네트워킹 최적화
Go 언어는 내장된 HTTP 클라이언트를 제공하며, 이를 활용하여 네트워킹 성능을 최적화할 수 있습니다. `http.Transport` 설정을 조정하여 TCP 커넥션 풀을 관리하고, Keep-Alive 연결을 유지할 수 있습니다. 이를 통해 네트워크 지연 시간을 최소화하고 성능을 향상시킬 수 있습니다.

```go
package main

import (
	"fmt"
	"net/http"
	"time"
)

func main() {
	client := http.Client{
		Transport: &http.Transport{
			MaxIdleConnsPerHost:   10,
			MaxIdleConns:          100,
			IdleConnTimeout:       30 * time.Second,
			TLSHandshakeTimeout:   10 * time.Second,
			ExpectContinueTimeout: 1 * time.Second,
		},
	}

	resp, err := client.Get("https://example.com")
	if err != nil {
		fmt.Println(err)
		return
	}

	// 크롤링 작업 수행

	resp.Body.Close()
}
```

위의 예시에서 `http.Client`의 `Transport` 필드에 `http.Transport` 설정을 추가하였습니다. 이를 통해 HTTP 클라이언트의 동작을 커스터마이즈할 수 있으며, 위 예시에서는 TCP 커넥션 관리와 타임아웃 설정을 조정하여 네트워크 성능을 최적화하였습니다.

## 3. 적절한 요청 간격 설정
웹 서버는 과도한 요청으로 인한 부하를 방지하기 위해 요청 간격을 제한하는 경우가 많습니다. 따라서 웹 크롤링 작업을 수행할 때는 적절한 요청 간격을 설정하는 것이 중요합니다. `time` 패키지를 활용하여 요청 간격을 지연시킬 수 있으며, 서버의 부하를 최소화하기 위해 적정한 간격을 설정하는 것이 좋습니다.

```go
package main

import (
	"fmt"
	"net/http"
	"time"
)

func main() {
	urls := []string{
		"https://example.com/page1",
		"https://example.com/page2",
		"https://example.com/page3",
	}

	for _, url := range urls {
		resp, err := http.Get(url)
		if err != nil {
			fmt.Println(err)
			continue
		}

		// 크롤링 작업 수행

		resp.Body.Close()

		time.Sleep(1 * time.Second) // 1초 지연
	}
}
```

위의 예시에서는 각 URL 요청 이후 `time.Sleep` 함수를 이용하여 1초 지연을 주었습니다. 이를 통해 서버에 대한 과도한 요청을 방지하고, 웹 크롤링 작업을 안정적으로 수행할 수 있습니다.

## 마무리
Go 언어를 이용한 웹 크롤링 작업에서 성능을 향상시키려면 동시성을 활용하고, 네트워킹을 최적화하며, 적절한 요청 간격을 설정하는 등의 방법을 고려해야 합니다. 위의 방법들을 적절히 활용하면 웹 크롤링 작업의 성능을 대폭 향상시킬 수 있습니다.

## 참고 자료
- [Go 언어 공식 문서](https://golang.org/doc/)
- [Go 언어 웹 크롤링 예제](https://github.com/gocolly/colly)