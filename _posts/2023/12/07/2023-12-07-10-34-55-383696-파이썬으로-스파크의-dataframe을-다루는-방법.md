---
layout: post
title: "[python] 파이썬으로 스파크의 DataFrame을 다루는 방법"
description: " "
date: 2023-12-07
tags: [python]
comments: true
share: true
---

## 개요
스파크(Spark)는 대규모의 배치 작업 및 실시간 스트리밍 작업을 처리하기 위한 빠르고 강력한 클러스터 컴퓨팅 프레임워크입니다. 스파크는 여러 언어로 작성된 API를 제공하며, 파이썬 역시 그 중 하나입니다. 이번 포스트에서는 파이썬을 사용하여 스파크의 DataFrame을 다루는 방법에 대해 알아보겠습니다.

## DataFrame이란?
DataFrame은 테이블 형태로 구성된 분산 데이터 컬렉션입니다. 스파크의 DataFrame은 관계형 데이터베이스의 테이블이나 R의 데이터프레임과 유사한 구조를 가지고 있습니다. DataFrame은 데이터를 읽고 변환하는 데 사용되며, 데이터 조작 및 분석 작업에 유용합니다.

## DataFrame 생성하기
먼저, 스파크의 SQL 모듈을 사용하기 위해 `pyspark.sql` 패키지를 임포트합니다.

```python
from pyspark.sql import SparkSession
```

다음으로, 로컬의 스파크 세션을 생성합니다.

```python
spark = SparkSession.builder.appName("DataFrameExample").getOrCreate()
```

DataFrame을 생성하기 위해 `createDataFrame` 메서드를 사용합니다. 인자로는 2차원 배열이나 리스트, 또는 RDD를 전달합니다.

```python
data = [("Alice", 25), ("Bob", 30), ("Charlie", 35)]
df = spark.createDataFrame(data, ["Name", "Age"])
```

위의 코드에서는 이름과 나이를 저장하는 DataFrame을 생성하였습니다. `createDataFrame`의 두 번째 인자로 컬럼 이름 리스트를 전달해야 합니다.

## DataFrame 조작하기
스파크의 DataFrame은 다양한 조작 기능을 제공합니다. 몇 가지 예시를 살펴보겠습니다.

### 데이터 필터링
DataFrame에서 특정 조건을 만족하는 데이터만 선택하여 사용할 수 있습니다. 예를 들어, 나이가 30 이상인 데이터만 선택해보겠습니다.

```python
filtered_df = df.filter(df.Age >= 30)
```

### 컬럼 선택
DataFrame에서 원하는 컬럼만 선택하여 사용할 수 있습니다. 예를 들어, 이름 컬럼만 선택해보겠습니다.

```python
name_df = df.select("Name")
```

### 그룹화 및 집계
DataFrame을 그룹화하여 집계 작업을 수행할 수 있습니다. 예를 들어, 나이별로 그룹화하여 평균 나이를 구해보겠습니다.

```python
grouped_df = df.groupBy("Age").avg()
```

### 정렬
DataFrame을 특정 컬럼을 기준으로 정렬할 수 있습니다. 예를 들어, 나이를 오름차순으로 정렬해보겠습니다.

```python
sorted_df = df.orderBy("Age")
```

## 결과 확인하기
DataFrame의 결과를 확인하기 위해 `show` 메서드를 사용할 수 있습니다.

```python
df.show()
```

위의 코드를 실행하면 DataFrame 내용이 출력됩니다.

## 결론
이번 포스트에서는 파이썬을 사용하여 스파크의 DataFrame을 다루는 방법에 대해 알아보았습니다. DataFrame을 생성하고 조작하는 기본적인 작업을 다루었으며, 이를 통해 데이터 조작 및 분석 작업의 유연성을 얻을 수 있습니다. 스파크의 DataFrame은 대용량 데이터 처리에 적합한 강력한 도구이므로, 데이터 과학이나 빅데이터 분석의 필수 도구로 사용됩니다.

## 참고자료
- [Spark DataFrame Documentation](https://spark.apache.org/docs/latest/sql-programming-guide.html#dataframes)
- [PySpark SQL API Documentation](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html)