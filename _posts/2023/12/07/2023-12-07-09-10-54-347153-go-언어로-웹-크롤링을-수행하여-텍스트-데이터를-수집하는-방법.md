---
layout: post
title: "[go] Go 언어로 웹 크롤링을 수행하여 텍스트 데이터를 수집하는 방법"
description: " "
date: 2023-12-07
tags: [go]
comments: true
share: true
---

웹 크롤링은 인터넷 상의 웹 페이지를 자동으로 탐색하고 데이터를 추출하는 프로세스입니다. 이번 글에서는 Go 언어를 사용하여 웹 크롤링을 수행하는 방법에 대해 알아보겠습니다.

## 1. 필수 패키지 설치

Go를 이용하여 웹 크롤링을 수행하려면 몇 가지 필수 패키지를 설치해야 합니다. `goquery`와 `net/http` 패키지를 사용할 예정이므로, 터미널에서 다음 명령을 실행하여 해당 패키지를 설치합니다.

```shell
go get github.com/PuerkitoBio/goquery
```

## 2. 웹 페이지 다운로드

다음은 특정 웹 페이지를 다운로드하는 예제 코드입니다.

```go
package main

import (
	"fmt"
	"io/ioutil"
	"net/http"
)

func main() {
	url := "https://example.com"
	resp, err := http.Get(url)
	if err != nil {
		panic(err)
	}
	defer resp.Body.Close()
	
	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		panic(err)
	}
	
	fmt.Println(string(body))
}
```

위의 코드는 `https://example.com` 페이지를 다운로드한 후, 해당 페이지의 HTML을 출력하는 예제입니다. `http.Get` 함수를 사용하여 웹 페이지를 요청하고, `ioutil.ReadAll` 함수를 사용하여 응답의 내용을 읽어옵니다.

## 3. 웹 페이지 파싱

크롤링한 웹 페이지의 특정 부분을 추출하기 위해선, 파싱 과정이 필요합니다. 이를 위해 `goquery` 패키지를 사용해보겠습니다.

```go
package main

import (
	"fmt"
	"log"
	"net/http"

	"github.com/PuerkitoBio/goquery"
)

func main() {
	url := "https://example.com"
	resp, err := http.Get(url)
	if err != nil {
		log.Fatal(err)
	}
	defer resp.Body.Close()

	doc, err := goquery.NewDocumentFromReader(resp.Body)
	if err != nil {
		log.Fatal(err)
	}

	// 원하는 데이터 추출
	doc.Find("h1").Each(func(i int, s *goquery.Selection) {
		fmt.Println(s.Text())
	})
}
```

위의 코드는 `goquery` 패키지를 사용하여 웹 페이지를 파싱하는 예제입니다. `goquery.NewDocumentFromReader` 함수를 사용하여 응답 내용을 파싱한 후, `Find` 함수를 사용하여 특정 HTML 요소를 선택할 수 있습니다. 위의 예제에서는 `h1` 태그를 선택하여 해당 텍스트를 출력합니다.

이제 Go 언어로 웹 크롤링을 위한 기본적인 과정을 알게 되었으니, 웹 페이지의 구조를 파악하여 필요한 데이터를 추출하고 활용하는 다양한 크롤링 작업을 시도할 수 있습니다.

## 참고 자료
- [Go 공식 웹사이트](https://golang.org/)
- [goquery 패키지](https://pkg.go.dev/github.com/PuerkitoBio/goquery)
- [net/http 패키지](https://golang.org/pkg/net/http/)