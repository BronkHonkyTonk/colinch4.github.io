---
layout: post
title: "[python] 파이썬으로 스파크 스트리밍 애플리케이션 만들기"
description: " "
date: 2023-12-07
tags: [python]
comments: true
share: true
---

## 소개
스트리밍 데이터를 처리하는 데에 있어서 아파치 스파크는 매우 강력한 도구입니다. 이번 블로그 포스트에서는 파이썬을 사용하여 스파크 스트리밍 애플리케이션을 만드는 방법을 알아보겠습니다.

## 필수 요소
1. 파이썬 환경 설치: 먼저 파이썬을 설치해야 합니다. 파이썬은 스파크 스트리밍 애플리케이션을 작성하는 데 사용될 것입니다.
2. 아파치 스파크 설치: 스파크를 설치하고 환경을 구성해야 합니다. 다음은 스파크 설치 방법입니다.

    ```bash
    $ wget https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz
    $ tar xvfz spark-3.0.1-bin-hadoop3.2.tgz
    $ cd spark-3.0.1-bin-hadoop3.2
    $ ./bin/spark-shell
    ```

## 스파크 스트리밍 애플리케이션 작성하기
이제 파이썬과 스파크가 설치되었으므로, 스트리밍 애플리케이션을 작성해보겠습니다. 다음은 간단한 예제 코드입니다.

```python
from pyspark import SparkContext
from pyspark.streaming import StreamingContext

# 스파크 컨텍스트 생성
sc = SparkContext(appName="StreamingApp")
ssc = StreamingContext(sc, 1)

# 소켓 텍스트 스트림 생성
lines = ssc.socketTextStream("localhost", 9999)

# 단어 개수 세기
words = lines.flatMap(lambda line: line.split(" "))
word_counts = words.countByValue()

# 결과 출력
word_counts.pprint()

# 스트리밍 시작
ssc.start()
ssc.awaitTermination()
```

위 코드는 로컬 호스트의 9999번 포트에서 수신된 텍스트 스트림의 단어 개수를 세는 간단한 스트리밍 애플리케이션입니다.

## 실행하기
1. 스트리밍 데이터 준비: 텍스트 스트림 데이터를 소켓으로 발송해야 합니다. 예를 들어, netcat을 사용하여 데이터를 발송할 수 있습니다.

    ```bash
    $ nc -lk 9999
    ```

2. 스파크 애플리케이션 실행: 앞서 작성한 코드를 별도의 터미널에서 실행합니다.

    ```bash
    $ spark-submit <파일이름>.py
    ```

    애플리케이션이 실행되면 로컬에서 수신된 스트리밍 데이터의 단어 개수가 출력됩니다.

## 결론
파이썬과 스파크를 사용하여 스트리밍 애플리케이션을 작성하는 방법을 살펴보았습니다. 스트리밍 데이터 처리에 있어서 스파크는 뛰어난 성능과 확장성을 제공하므로, 파이썬을 사용하여 스파크 애플리케이션을 개발하는 것은 매우 효율적입니다.