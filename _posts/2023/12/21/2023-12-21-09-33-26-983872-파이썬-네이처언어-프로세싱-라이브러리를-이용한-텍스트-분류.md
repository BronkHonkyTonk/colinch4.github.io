---
layout: post
title: "[python] 파이썬 네이처언어 프로세싱 라이브러리를 이용한 텍스트 분류"
description: " "
date: 2023-12-21
tags: [python]
comments: true
share: true
---

자연어 처리(Natural Language Processing, NLP)는 인공 지능의 한 분야로, 컴퓨터가 인간의 언어를 이해하고 처리하는 기술을 다룹니다. 텍스트 분류는 NLP의 여러 응용 중 하나로, 텍스트 데이터를 사전에 정의된 카테고리에 할당하는 작업을 말합니다. 이번 글에서는 파이썬의 네이처 언어 프로세싱 라이브러리인 `nltk`를 사용하여 간단한 텍스트 분류를 수행하는 방법을 살펴보겠습니다.

## 필요한 라이브러리 설치

먼저, `nltk` 라이브러리를 설치해야 합니다. 아래의 명령어를 사용하여 설치할 수 있습니다.

```bash
pip install nltk
```

## 텍스트 전처리

텍스트 분류를 위해선 텍스트 데이터를 전처리하는 작업이 필요합니다. 전처리 과정에는 토큰화, 불용어 제거, 표제어 추출, 벡터화 등이 포함될 수 있습니다.

```python
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
```

```python
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

## 데이터 벡터화

텍스트 데이터를 벡터화하여 머신러닝 알고리즘이 이해할 수 있는 형태로 변환합니다. TF-IDF(Term Frequency-Inverse Document Frequency)는 이 과정에서 많이 사용되는 방법 중 하나입니다.

```python
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(documents)
```

## 머신러닝 모델 학습

벡터화된 데이터를 사용하여 머신러닝 모델을 학습시킵니다. 예를 들어, `scikit-learn` 라이브러리의 분류 알고리즘을 사용할 수 있습니다.

```python
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, labels, test_size=0.2, random_state=42)

model = MultinomialNB()
model.fit(X_train, y_train)
```

## 모델 평가

학습된 모델의 성능을 평가하기 위해 테스트 데이터를 사용하여 예측을 수행하고 평가 지표를 계산합니다.

```python
from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

## 결론

이제, `nltk`를 사용하여 텍스트 데이터를 전처리하고 머신러닝 모델을 학습하여 텍스트를 분류하는 방법에 대해 알아보았습니다. 텍스트 분류 작업은 실제로는 이보다 더 복잡하고 다양한 기술을 요구하지만, 이 예제를 통해 전반적인 절차를 이해할 수 있습니다.