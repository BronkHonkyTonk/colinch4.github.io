---
layout: post
title: "[python] 파이썬 BeautifulSoup과 웹 사이트 크롤링"
description: " "
date: 2023-12-04
tags: [python]
comments: true
share: true
---

데이터 수집 및 분석을 위해 웹 사이트의 정보를 크롤링하는 것은 중요한 작업입니다. 파이썬 BeautifulSoup 라이브러리는 웹 크롤링을 간편하게 할 수 있도록 도와줍니다.

## BeautifulSoup 설치

먼저, BeautifulSoup를 설치해야 합니다. 아래의 명령어를 사용하여 설치할 수 있습니다.

```shell
pip install beautifulsoup4
```

## 웹 페이지의 HTML 가져오기

BeautifulSoup를 사용하여 웹 페이지의 HTML을 가져오기 위해서는 `requests` 라이브러리도 함께 설치되어야 합니다. 아래의 명령어로 `requests` 라이브러리를 설치합니다.

```shell
pip install requests
```

다음은 Python 코드 예시입니다.

```python
import requests
from bs4 import BeautifulSoup

url = 'https://example.com'  # 크롤링할 웹 페이지의 주소
response = requests.get(url)
html = response.text

soup = BeautifulSoup(html, 'html.parser')
```

위의 코드는 `requests` 라이브러리로 웹 페이지의 HTML을 가져온 뒤, `BeautifulSoup`를 사용하여 파싱합니다.

## 웹 페이지의 요소 찾기

BeautifulSoup를 사용하면 웹 페이지의 요소를 쉽게 찾을 수 있습니다. 다음은 BeautifulSoup의 몇 가지 사용 예시입니다.

### 태그를 이용한 요소 찾기

```python
# 원하는 태그 하나 찾기
title_tag = soup.find('title')
print(title_tag.text)

# 여러 개의 태그 찾기
p_tags = soup.find_all('p')
for p in p_tags:
    print(p.text)
```

### 클래스를 이용한 요소 찾기

```python
# 클래스 이름으로 요소 찾기
highlighted_div = soup.find('div', class_='highlighted')
print(highlighted_div.text)

# CSS 클래스로 요소 찾기
highlighted_divs = soup.find_all('div', class_='highlighted')
for div in highlighted_divs:
    print(div.text)
```

### CSS 선택자를 이용한 요소 찾기

```python
# CSS 선택자로 요소 찾기
first_div = soup.select_one('div')
print(first_div.text)

# 모든 div 요소 찾기
all_divs = soup.select('div')
for div in all_divs:
    print(div.text)
```

위의 예시는 BeautifulSoup를 사용하여 웹 페이지의 태그, 클래스, CSS 선택자를 이용하여 요소를 찾는 방법을 보여줍니다.

## 웹 사이트 크롤링의 법적 제한

웹 크롤링을 수행할 때는 웹 사이트의 로봇 배제 표준을 확인하고, 사이트의 이용 약관을 따르는 것이 중요합니다. 일부 웹 사이트는 크롤링을 제한하거나 금지할 수 있으며, 합법적인 범위 내에서만 크롤링 작업을 수행해야 합니다.

참고 자료:
- [Beautiful Soup 공식 문서](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Requests 공식 문서](https://requests.readthedocs.io/en/latest/)