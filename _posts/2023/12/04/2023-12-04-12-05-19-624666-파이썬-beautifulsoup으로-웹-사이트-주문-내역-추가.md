---
layout: post
title: "[python] 파이썬 BeautifulSoup으로 웹 사이트 주문 내역 추가"
description: " "
date: 2023-12-04
tags: [python]
comments: true
share: true
---

이번에는 파이썬과 BeautifulSoup 라이브러리를 사용하여 웹 사이트의 주문 내역을 추가하는 방법에 대해 알아보겠습니다. BeautifulSoup은 파이썬의 HTML 및 XML 파싱에 사용되는 라이브러리로, 웹 스크래핑에 유용하게 사용됩니다.

## 필요한 라이브러리 설치

BeautifulSoup을 사용하기 위해서는 먼저 BeautifulSoup 라이브러리를 설치해야 합니다. 아래의 명령어를 사용하여 설치할 수 있습니다.

```bash
pip install beautifulsoup4
```

## 웹 사이트 주문 내역 파싱

먼저, 파싱하고자 하는 웹 사이트의 HTML 소스 코드를 가져와야 합니다. 이를 위해 파이썬의 `requests` 라이브러리를 사용할 수 있습니다. 예를 들어, 아래와 같이 웹 사이트의 URL로 GET 요청을 보내고, 응답을 받아옵니다.

```python
import requests

url = "https://example.com/orders"
response = requests.get(url)
html = response.text
```

이제 `html` 변수에는 해당 웹 사이트의 HTML 소스 코드가 문자열로 저장되어 있습니다.

## BeautifulSoup을 사용하여 주문 내역 추가

BeautifulSoup을 사용하여 HTML 소스 코드를 파싱하고, 원하는 주문 내역을 추출할 수 있습니다. 예를 들어, 웹 사이트의 주문 내역은 `<table>` 태그 아래에 있는 `<tr>` 태그들로 구성되어 있다고 가정해보겠습니다.

```python
from bs4 import BeautifulSoup

soup = BeautifulSoup(html, 'html.parser')
orders_table = soup.find('table', id='orders')

orders = []
for row in orders_table.find_all('tr'):
    cells = row.find_all('td')
    if len(cells) == 3:  # 주문 내역 행인 경우
        order = {
            'product': cells[0].text,
            'quantity': int(cells[1].text),
            'price': float(cells[2].text)
        }
        orders.append(order)
```

위의 코드에서는 BeautifulSoup의 `find` 메서드를 사용하여 `<table>` 태그를 찾아냈습니다. 그리고 해당 테이블 아래에 있는 모든 `<tr>` 태그들을 찾아내어 하나씩 처리하였습니다. 각 행의 데이터는 `<td>` 태그들로 구성되어 있으므로, `find_all` 메서드를 사용하여 각 행의 데이터를 추출했습니다. 각 주문 내역은 딕셔너리 형태로 저장되고, `orders` 리스트에 추가되었습니다.

이제 `orders` 변수에는 추출한 주문 내역이 담겨 있습니다.

## 주문 내역 추가하기

추출한 주문 내역을 원하는 방식으로 활용할 수 있습니다. 예를 들어, 데이터베이스에 저장한다거나 다른 처리를 수행한다는 등의 작업을 할 수 있습니다.

```python
def save_orders(orders):
    # 주문 내역을 데이터베이스에 저장하는 로직을 여기에 작성
    pass

save_orders(orders)
```

위의 예제에서 `save_orders` 함수는 주문 내역을 데이터베이스에 저장하도록 구현되어 있습니다. 여기에는 실제 데이터베이스 연결 및 저장 로직이 들어갈 수 있습니다.

이제 웹 사이트에서 주문 내역을 가져와 파싱하는 방법에 대해 알아보았습니다. BeautifulSoup을 사용하면 간단하게 HTML 데이터를 추출하고, 필요한 작업을 수행할 수 있습니다.