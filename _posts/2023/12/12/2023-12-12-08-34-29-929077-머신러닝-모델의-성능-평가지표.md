---
layout: post
title: "[python] 머신러닝 모델의 성능 평가지표"
description: " "
date: 2023-12-12
tags: [python]
comments: true
share: true
---

머신러닝 모델을 평가할 때, 어떤 지표를 사용하는 것이 가장 좋을까요? 이번 글에서는 머신러닝 모델을 평가하기 위한 주요 성능 평가지표에 대해 알아보겠습니다.

## 1. 정확도 (Accuracy)

정확도는 전체 예측 중 실제 값과 일치하는 예측의 비율을 나타내는 지표입니다. 하지만 클래스의 불균형이 심한 경우, 정확도만으로 모델의 성능을 판단하기 어려울 수 있습니다. 

## 2. 정밀도 (Precision)와 재현율 (Recall)

정밀도는 모델이 True로 예측한 것 중 실제 True인 비율을, 재현율은 실제 True 중 모델이 True로 예측한 비율을 나타냅니다. 이 두 지표는 서로 trade-off 관계에 있기 때문에, 어떤 것을 더 중요하게 여길지는 문제의 특성에 따라 다를 수 있습니다.

## 3. F1 점수 (F1 Score)

F1 점수는 정밀도와 재현율의 조화평균으로 계산됩니다. 클래스의 불균형이 심한 경우, F1 점수를 사용하여 모델의 성능을 평가하는 것이 유용합니다.

## 4. AUC-ROC

AUC-ROC는 Receiver Operating Characteristic curve의 아래 면적을 나타내는 지표로, 이진 분류 모델의 성능을 평가하는 데 사용됩니다.

## 결론

모델의 성능을 평가할 때, 정확도 외에도 정밀도, 재현율, F1 점수, AUC-ROC 등 다양한 지표를 함께 고려하는 것이 중요합니다. 어떤 성능 평가지표를 사용할지는 주어진 문제와 데이터의 특성에 따라 다를 수 있으며, 올바른 지표를 선택하여 모델을 평가하는 것이 중요합니다.

이상으로, 머신러닝 모델의 성능 평가지표에 대해 알아보았습니다.

관련 내용으로는 ["Scikit-learn 공식 문서"](https://scikit-learn.org/stable/documentation.html)를 참고하실 수 있습니다.