---
layout: post
title: "[swift] Swift에서 카메라로 실시간 필터 적용하기"
description: " "
date: 2023-12-12
tags: [swift]
comments: true
share: true
---

이번에는 Swift를 사용하여 iOS 애플리케이션에서 카메라를 열고 실시간으로 필터를 적용하는 방법에 대해 알아보겠습니다. Core Image 프레임워크를 사용하여 이미지나 비디오에 실시간 필터를 적용할 수 있습니다. 먼저 카메라를 다루기 위해 `AVFoundation` 프레임워크를 사용하고, 이후에 `Core Image` 프레임워크를 사용하여 필터를 적용할 것입니다.

## 프로젝트 설정

먼저 Xcode에서 새로운 iOS 프로젝트를 생성합니다. 이 프로젝트에서 카메라를 사용하여 실시간 필터를 적용할 것이므로, `Info.plist` 파일에 카메라와 마이크 접근 권한을 설정해야 합니다. `Privacy - Camera Usage Description`와 `Privacy - Microphone Usage Description` 키를 추가하고, 각각 카메라와 마이크에 대한 사용 설명을 값으로 설정합니다.

## 카메라 미리보기

카메라를 사용하기 위해 먼저 `AVCaptureSession`, `AVCaptureDevice`, `AVCaptureDeviceInput`, 그리고 `AVCaptureVideoPreviewLayer`를 사용하여 카메라 미리보기를 표시해야 합니다.

```swift
import UIKit
import AVFoundation

class ViewController: UIViewController {
    let session = AVCaptureSession()
    var cameraOutput: AVCaptureVideoDataOutput!
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        setupCamera()
    }

    func setupCamera() {
        session.beginConfiguration()
        
        // 카메라 장치 찾기
        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else { return }
        
        // 카메라 입력 설정
        do {
            let deviceInput = try AVCaptureDeviceInput(device: camera)
            if session.canAddInput(deviceInput) {
                session.addInput(deviceInput)
            }
        } catch {
            print("Error setting up camera input: \(error.localizedDescription)")
            return
        }
        
        // 비디오 출력 설정
        cameraOutput = AVCaptureVideoDataOutput()
        cameraOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA]
        cameraOutput.setSampleBufferDelegate(self, queue: DispatchQueue.main)
        
        if session.canAddOutput(cameraOutput) {
            session.addOutput(cameraOutput)
        }
        
        // 미리보기 레이어 생성 및 설정
        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.frame = view.layer.bounds
        previewLayer.videoGravity = .resizeAspectFill
        view.layer.insertSublayer(previewLayer, at: 0)
        
        // 카메라 시작
        session.commitConfiguration()
        session.startRunning()
    }
}

// AVCaptureVideoDataOutputSampleBufferDelegate 채택
extension ViewController: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        // 필터 적용
        // 여기에 필터 적용 코드를 추가해주세요.
    }
}
```

## 필터 적용

카메라 미리보기가 동작하면, `captureOutput` 메서드에서 실시간으로 필터를 적용할 수 있습니다. 예를 들어, *CIFilter* 클래스를 사용하여 이미지를 날카롭게 만드는 필터를 적용할 수 있습니다.

```swift
func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
    guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
    
    // Core Image context 생성
    let ciContext = CIContext()
    
    // Core Image 이미지 생성
    let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
    
    // 필터 생성
    if let filter = CIFilter(name: "CIColorControls") {
        filter.setValue(ciImage, forKey: kCIInputImageKey)
        filter.setValue(1.1, forKey: kCIInputContrastKey)
        
        // 필터가 적용된 이미지 가져오기
        if let output = filter.outputImage,
           let cgImage = ciContext.createCGImage(output, from: output.extent) {
            let filteredImage = UIImage(cgImage: cgImage)
            // 필터가 적용된 이미지를 여기에서 보여주세요.
        }
    }
}
```

위의 예제에서는 `CIColorControls` 필터를 사용하여 대비를 높이는 작업을 수행했습니다. 원하는 필터를 적용하여 실시간으로 카메라 미리보기에 효과를 적용할 수 있습니다.

이렇게 Swift를 사용하여 카메라로 실시간으로 필터를 적용하는 방법에 대해 알아보았습니다. 이를 활용하여 다양한 이미지 처리 및 비디오 효과 기능을 개발할 수 있습니다.

참고: 
- [Apple Developer Documentation - Core Image](https://developer.apple.com/documentation/coreimage)
- [Apple Developer Documentation - AVFoundation](https://developer.apple.com/av-foundation/)