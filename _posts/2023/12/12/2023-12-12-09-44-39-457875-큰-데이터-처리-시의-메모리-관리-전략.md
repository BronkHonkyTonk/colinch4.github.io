---
layout: post
title: "[python] 큰 데이터 처리 시의 메모리 관리 전략"
description: " "
date: 2023-12-12
tags: [python]
comments: true
share: true
---

데이터 처리 작업을 할 때, 많은 양의 데이터를 다루는 경우에는 메모리 관리가 중요합니다. 특히 파이썬에서 큰 데이터를 처리할 때는 더욱 신경을 써야 합니다. 이번 포스트에서는 **큰 데이터 처리 시의 메모리 관리 전략**에 대해 알아보겠습니다.

## 1. 데이터 스트리밍

큰 데이터를 메모리에 모두 올리지 않고, **데이터 스트리밍**을 통해 작은 조각 단위로 처리할 수 있습니다. 파이썬에서는 `yield` 키워드를 사용하여 **제너레이터**를 만들어 데이터를 스트리밍할 수 있습니다.

```python
def stream_data(file_path):
    with open(file_path, 'r') as file:
        for line in file:
            yield process_line(line)
```

## 2. 메모리 맵 파일

**메모리 맵 파일**은 파일을 가상 메모리에 매핑하여 파일을 마치 메모리처럼 사용할 수 있는 기술입니다. 파이썬에서는 `mmap` 모듈을 사용하여 메모리 맵 파일을 다룰 수 있습니다.

```python
import mmap

with open('large_file.txt', 'r') as file:
    with mmap.mmap(file.fileno(), length=0, access=mmap.ACCESS_READ) as mmap_obj:
        data = mmap_obj.read(100)
```

## 3. 병렬 처리

**병렬 처리**를 통해 데이터 처리 시간을 단축하고 메모리를 효율적으로 사용할 수 있습니다. 파이썬에서는 `concurrent.futures`나 `multiprocessing`과 같은 모듈을 사용하여 병렬 처리를 구현할 수 있습니다.

```python
import concurrent.futures

def process_data(data):
    # 데이터 처리 작업 수행

with concurrent.futures.ProcessPoolExecutor() as executor:
    results = executor.map(process_data, large_data)
```

## 결론

큰 데이터를 처리할 때는 메모리를 효율적으로 관리하는 것이 중요합니다. **데이터 스트리밍, 메모리 맵 파일, 그리고 병렬 처리**를 통해 메모리를 효율적으로 활용하고 성능을 향상시킬 수 있습니다.

이상으로 **큰 데이터 처리 시의 메모리 관리 전략**에 대해 알아보았습니다.

참고문헌: 
- https://realpython.com/
- https://docs.python.org/3/library/mmap.html