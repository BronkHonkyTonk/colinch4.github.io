---
layout: post
title: "[python] Selenium 라이브러리를 이용한 동적 웹 페이지 크롤링"
description: " "
date: 2023-12-15
tags: [python]
comments: true
share: true
---

인터넷에서 정보를 수집하는 과정 중, 정적인 웹 페이지는 크롤링하는 데 용이하지만 **동적인** 웹 페이지의 경우, 데이터를 수집하기 위해서는 자바스크립트를 실행하여 페이지를 렌더링해야 합니다. 이러한 경우 **Selenium** 라이브러리를 사용하여 크롤링하는 것이 도움이 됩니다.

## Selenium 이란?

Selenium 은 웹 애플리케이션을 위한 자동화 도구로, 웹 브라우저를 제어하여 테스트나 스크레이핑 등을 수행할 수 있습니다.

## Selenium 설치 방법

Selenium을 설치하려면 아래의 명령을 사용합니다.

```bash
pip install selenium
```

## Selenium을 활용한 크롤링 예제

다음은 Python과 Selenium을 사용하여 동적 웹 페이지에서 데이터를 크롤링하는 간단한 예제입니다.

```python
from selenium import webdriver

url = "https://example.com"
driver = webdriver.Chrome('path_to_chromedriver')
driver.get(url)

# 웹 페이지가 로드될 때까지 잠시 대기
driver.implicitly_wait(3)

# 페이지 소스 가져오기
page_source = driver.page_source
print(page_source)

driver.quit()
```

위의 예제에서, `webdriver.Chrome()` 메서드를 사용하여 Chrome 웹 브라우저를 제어하고, `implicitly_wait()` 메서드를 사용하여 웹 페이지가 로드될 때까지 대기합니다. 마지막으로, `page_source` 속성을 사용하여 페이지 소스를 가져옵니다. 코드 실행 후에는 `driver.quit()` 메서드를 사용하여 웹 드라이버를 종료합니다.

이제는 동적 웹 페이지에서 데이터를 크롤링하는 과정을 더욱 쉽게 이해할 수 있겠죠?

## 결론

Selenium 라이브러리는 동적 웹 페이지에서 데이터를 수집하는 데 아주 유용합니다. 이를 통해 웹 스크레이핑 작업을 더욱 효율적으로 수행할 수 있습니다.

## 참고 자료

- Selenium 공식 문서: [https://www.selenium.dev/documentation/en/](https://www.selenium.dev/documentation/en/)
- Selenium with Python 문서: [https://selenium-python.readthedocs.io/](https://selenium-python.readthedocs.io/)