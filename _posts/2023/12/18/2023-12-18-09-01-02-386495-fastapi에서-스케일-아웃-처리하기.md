---
layout: post
title: "[python] FastAPI에서 스케일 아웃 처리하기"
description: " "
date: 2023-12-18
tags: [python]
comments: true
share: true
---

FastAPI는 높은 성능과 빠른 실행 속도를 제공하는 강력한 웹 프레임워크입니다. 이러한 특성으로 FastAPI를 사용하여 구축된 애플리케이션은 높은 트래픽을 처리할 수 있는데, 단일 서버에서는 성능 한계에 도달할 수 있습니다. 이때는 여러 대의 서버 인스턴스로 애플리케이션을 확장하여 부하를 분산해야 합니다. 이 글에서는 FastAPI 애플리케이션을 스케일 아웃하여 부하를 분산하는 방법에 대해 알아보겠습니다.

## 멀티프로세스로 스케일 아웃

FastAPI 애플리케이션을 스케일 아웃하기 위한 한 가지 방법은 *멀티프로세싱*을 사용하는 것입니다. 이 방법은 여러 프로세스에서 FastAPI 애플리케이션을 실행하여 부하를 분산합니다. 이를 위해서는 다음과 같은 코드를 사용할 수 있습니다:

```python
from fastapi import FastAPI
import uvicorn

app = FastAPI()

@app.get("/")
def read_root():
    return {"Hello": "World"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000, workers=4)
```

위의 코드에서 `workers` 매개변수는 FastAPI 애플리케이션을 실행할 프로세스 수를 정의합니다. 이렇게 하면 FastAPI 애플리케이션이 멀티프로세스로 실행되어 부하를 분산할 수 있습니다.

## 멀티서버로 스케일 아웃

또 다른 방법은 FastAPI 애플리케이션을 멀티서버로 실행하는 것입니다. 이를 위해서는 **로드 밸런서**를 사용하여 들어오는 요청을 여러 서버로 분산시킵니다. 예를 들어, **NGINX**나 **HAProxy**와 같은 로드 밸런서를 사용하여 이 작업을 수행할 수 있습니다. 로드 밸런서는 들어오는 요청을 다수의 FastAPI 서버로 분산시켜 부하를 분산합니다.

이러한 방식은 확장성과 신뢰성을 높일 수 있으며, 장애를 조치하고 부하를 분산시키는 데 도움이 됩니다. 

FastAPI 애플리케이션을 스케일 아웃하여 더 많은 트래픽을 처리하도록 하는 방법 중, 멀티프로세스 또는 멀티서버를 사용하는 방법을 사용할 수 있습니다.

## 요약

FastAPI 애플리케이션을 스케일 아웃하여 부하를 분산하는 방법에 대해 알아보았습니다. 멀티프로세스나 멀티서버를 사용하여 FastAPI 애플리케이션을 확장하고, **로드 밸런서**를 이용해 요청을 분산시키는 방법 등을 살펴보았습니다. 이러한 방법을 통해 FastAPI 애플리케이션은 높은 성능과 확장성을 보장할 수 있게 됩니다.