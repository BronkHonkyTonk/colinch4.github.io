---
layout: post
title: "[스프링] 스프링과 하둡을 이용한 대규모 파일 처리"
description: " "
date: 2023-12-18
tags: [스프링]
comments: true
share: true
---

**스프링(Spring)** 및 **하둡(Hadoop)**은 각각 대규모 애플리케이션 개발 및 대규모 데이터 처리에 탁월한 기술이다. 이들을 결합하여 대규모 파일을 처리하는 애플리케이션을 개발할 수 있다. 이번 블로그에서는 **스프링 프레임워크**와 **하둡**을 이용하여 대규모 CSV 파일을 처리하는 방법에 대해 살펴보겠다.

## 1. 환경 설정

먼저, 개발 환경에 **스프링**과 **하둡**을 설치해야 한다. 각각의 환경에 맞게 필수 소프트웨어를 설치하는 것은 별도의 설명이 필요하므로 이를 더 자세히 다루지는 않겠다.

## 2. 스프링 배치를 이용한 파일 읽기

```java
public class CsvItemReader<T> extends FlatFileItemReader<T> {
    
    public CsvItemReader(Path filePath) {
        setResource(new FileSystemResource(filePath.toFile()));
        DelimitedLineTokenizer lineTokenizer = new DelimitedLineTokenizer();
        lineTokenizer.setNames("column1", "column2", "column3"); // CSV 컬럼 매핑
        DefaultLineMapper<T> lineMapper = new DefaultLineMapper<>();
        lineMapper.setLineTokenizer(lineTokenizer);
        lineMapper.setFieldSetMapper(new BeanWrapperFieldSetMapper<>() {
            {
                setTargetType(CsvItem.class);
            }
        });
        setLineMapper(lineMapper);
    }
}
```

위의 예제는 **스프링 배치(Spring Batch)**를 이용하여 CSV 파일을 읽는 방법을 보여준다. **CsvItemReader** 클래스는 **FlatFileItemReader**를 확장하고, CSV 파일을 읽어오며 매핑을 수행한다.

## 3. 하둡을 이용한 대규모 데이터 처리

```java
public class CsvMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    
    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String line = value.toString(); // CSV 파일의 한 행 읽기
        String[] columns = line.split(","); // 쉼표로 구분된 CSV 컬럼 파싱
        // 데이터 처리 로직
        for (String column : columns) {
            context.write(new Text(column), new IntWritable(1)); // Key-Value 데이터 생성
        }
    }
}
```

위의 예제는 **하둡 맵리듀스(Hadoop MapReduce)**를 이용하여 CSV 파일의 각 열을 카운트하는 방법을 보여준다. **CsvMapper** 클래스는 **Mapper**를 확장하고, 입력 키-값을 받아서 처리한 뒤 중간 결과를 생성한다.

## 4. 스프링과 하둡 통합

스프링과 하둡을 통합하여 대규모 파일을 처리하려면 스프링의 **Hadoop FileSystem API**를 이용하여 하둡 클러스터에 접근하고, **Hadoop MapReduce** 작업을 수행해야 한다. 

## 5. 마치며

이렇게 하둡을 이용하여 대규모 파일을 처리하는 방법을 스프링과 결합하여 사용할 수 있다. 이를 통해 대용량 데이터를 처리하는 고성능 애플리케이션을 구축할 수 있다.

더 자세한 내용은 아래의 레퍼런스를 참고하도록 하자.

- [스프링 공식 문서](https://spring.io/)
- [하둡 공식 홈페이지](https://hadoop.apache.org/)

위의 내용은 개략적인 설명이며, 실제로는 각 기술의 상세한 사용법과 설정 등이 필요하다.