---
layout: post
title: "[python] Jupyter Notebook에서 웹 크롤링/스크레이핑 실습 예제"
description: " "
date: 2023-12-18
tags: [python]
comments: true
share: true
---

이번 게시물에서는 Python과 Jupyter Notebook을 사용하여 간단한 웹 크롤링 및 스크레이핑을 실습할 것입니다. 웹 크롤링은 웹 페이지를 자동으로 탐색하고 데이터를 수집하는 것을 의미하며, 스크레이핑은 웹 페이지에서 원하는 정보를 추출하는 것을 말합니다.

## 필요한 도구 설치

먼저, 웹 크롤링 및 스크레이핑을 위해 필요한 라이브러리를 설치합니다. 아래의 명령을 사용하여 `requests`와 `beautifulsoup4` 라이브러리를 설치합니다.

```bash
pip install requests beautifulsoup4
```

## 웹 페이지에서 데이터 가져오기

다음으로, Python의 `requests` 라이브러리를 사용하여 웹 페이지에서 데이터를 가져올 것입니다. 아래의 코드는 특정 웹 페이지에서 데이터를 가져오는 간단한 예제입니다.

```python
import requests

url = 'https://example.com'
response = requests.get(url)

print(response.text)
```

## 데이터 스크레이핑

이제, `beautifulsoup4` 라이브러리를 사용하여 웹 페이지에서 원하는 정보를 추출하는 방법을 살펴봅시다. 아래의 코드는 웹 페이지에서 제목 태그를 추출하는 예제입니다.

```python
from bs4 import BeautifulSoup

html = response.text
soup = BeautifulSoup(html, 'html.parser')

title = soup.find('h1').text
print(title)
```

위의 예제 코드를 Jupyter Notebook에서 실행하면 해당 웹 페이지의 제목을 출력할 수 있습니다.

이상으로, 간단한 웹 크롤링 및 스크레이핑 실습 예제를 마치도록 하겠습니다.

## 참고 자료

- [Requests: HTTP for Humans](https://docs.python-requests.org/)
- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)