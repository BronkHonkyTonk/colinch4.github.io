---
layout: post
title: "[python] 주피터 노트북에서 웹 크롤링하기"
description: " "
date: 2023-12-14
tags: [python]
comments: true
share: true
---

웹 크롤링은 인터넷 상의 정보를 수집하거나 분석하기 위해 웹 페이지를 탐색하는 과정입니다. 주피터 노트북은 웹 크롤링을 수행하고 결과를 시각화하거나 분석하는 데 매우 유용한 환경을 제공합니다. 이번 포스트에서는 파이썬과 주피터 노트북을 이용하여 웹 크롤링을 하는 방법을 알아보겠습니다.

## 라이브러리 설치

먼저 필요한 라이브러리들을 설치해야 합니다. 웹 크롤링을 위해 `requests`와 `BeautifulSoup` 라이브러리를 사용할 것입니다. 주피터 노트북에서 다음 명령으로 라이브러리를 설치할 수 있습니다.

```bash
!pip install requests
!pip install beautifulsoup4
```

## 웹 페이지 가져오기

먼저 `requests` 라이브러리를 사용하여 웹 페이지의 HTML 코드를 가져올 수 있습니다. 다음은 구글 웹 페이지에서 HTML을 가져오는 간단한 예제입니다.

```python
import requests

url = 'https://www.google.com'
response = requests.get(url)

html = response.text
print(html)
```

## 웹 페이지 파싱

가져온 HTML 코드를 파싱하여 필요한 정보를 추출하기 위해 `BeautifulSoup` 라이브러리를 사용할 수 있습니다. 다음은 HTML에서 특정 태그의 내용을 가져오는 예제입니다.

```python
from bs4 import BeautifulSoup

soup = BeautifulSoup(html, 'html.parser')
title = soup.find('title').text
print(title)
```

이 외에도 다양한 방법으로 웹 크롤링을 할 수 있고, 주피터 노트북을 이용하면 크롤링한 데이터를 바로 시각화하거나 분석하는 과정을 쉽게 수행할 수 있습니다. 이제 주피터 노트북에서 웹 크롤링을 시작해보세요!

## 참고 자료
- [Requests 라이브러리 공식 문서](https://docs.python-requests.org/)
- [BeautifulSoup 라이브러리 공식 문서](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)