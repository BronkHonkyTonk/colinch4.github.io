---
layout: post
title: "[python] Tornado를 활용한 웹 크롤러 개발 방법"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

이번 글에서는 Tornado 프레임워크를 활용하여 웹 크롤러를 개발하는 방법에 대해 알아보겠습니다. Tornado는 비동기 웹 서버와 네트워크 라이브러리로써, 높은 처리량과 확장성을 가지고 있어 웹 크롤링에 적합한 프레임워크입니다.

## 필요한 패키지 설치

Tornado를 사용하기 위해 우선 필요한 패키지를 설치해야 합니다. `pip`를 사용하여 아래 명령을 실행해주세요.

```python
pip install tornado
```

## Tornado 웹 크롤러 개발

1. Tornado 앱 생성

Tornado로 웹 크롤러를 개발하기 위해 먼저 Tornado 앱을 생성해야 합니다. 아래의 코드를 참고하여 앱을 생성해주세요.

```python
import tornado.ioloop
import tornado.web

class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write("Hello, World!")

def make_app():
    return tornado.web.Application([
        (r"/", MainHandler),
    ])

if __name__ == "__main__":
    app = make_app()
    app.listen(8888)
    tornado.ioloop.IOLoop.current().start()
```

2. 크롤링 로직 추가

Tornado 앱을 생성한 후, 크롤링 로직을 추가해야 합니다. 예를 들어, Beautiful Soup 라이브러리를 사용하여 HTML 페이지를 파싱하고 원하는 데이터를 추출하는 코드를 작성해보겠습니다.

```python
import tornado.ioloop
import tornado.web
from bs4 import BeautifulSoup
import requests

class MainHandler(tornado.web.RequestHandler):
    def get(self):
        # 크롤링 로직 작성
        url = "https://example.com"
        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")
        title = soup.title.text
        
        self.write(title)

def make_app():
    return tornado.web.Application([
        (r"/", MainHandler),
    ])

if __name__ == "__main__":
    app = make_app()
    app.listen(8888)
    tornado.ioloop.IOLoop.current().start()
```

위의 코드에서 `get()` 메서드에서 크롤링 로직을 추가하였습니다. `requests` 라이브러리로 웹 페이지를 요청하고, `BeautifulSoup` 라이브러리를 사용하여 HTML을 파싱하고 원하는 데이터를 추출한 후, 해당 데이터를 웹 페이지에 출력하는 예시입니다.

3. 크롤링 결과 확인

위의 코드에서 Tornado 앱을 실행하고 웹 브라우저에서 `http://localhost:8888`에 접속하면 크롤링 결과를 확인할 수 있습니다. 해당 페이지에서는 `https://example.com`의 타이틀을 출력합니다.

## 결론

이렇게 Tornado를 활용하여 웹 크롤러를 개발하는 방법에 대해 알아보았습니다. Tornado의 비동기 처리와 간편한 네트워크 기능을 활용하면 빠르고 효율적인 웹 크롤러를 개발할 수 있습니다.