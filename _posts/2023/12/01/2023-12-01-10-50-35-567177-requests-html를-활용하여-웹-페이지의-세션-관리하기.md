---
layout: post
title: "[python] Requests-HTML를 활용하여 웹 페이지의 세션 관리하기"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

## 소개

웹 스크래핑이나 웹 자동화 프로젝트를 진행하다 보면 웹 사이트에 로그인이 필요한 경우가 있습니다. 웹 페이지의 세션을 관리하여 로그인 상태를 유지하고 세션을 사용하여 다른 페이지로 이동하고 데이터를 가져오는 것이 중요합니다.

이번 포스트에서는 Python의 Requests-HTML 라이브러리를 사용하여 웹 페이지의 세션을 관리하는 방법을 알아보겠습니다. Requests-HTML은 Requests와 HTML parsing을 결합한 간편한 인터페이스를 제공하는 동적 웹 페이지 크롤링 라이브러리입니다.

## 세션 만들기

먼저, 세션을 만들어 로그인을 처리할 웹 사이트에 접속합니다. 다음은 Requests-HTML을 사용하여 세션을 만드는 예시 코드입니다.

```python
from requests_html import HTMLSession

session = HTMLSession()

# 로그인 페이지에 접속
login_url = "https://example.com/login"
response = session.get(login_url)

# 로그인 데이터 설정
username = "your_username"
password = "your_password"
data = {
    "username": username,
    "password": password
}

# 로그인 요청
login_request = session.post(login_url, data=data)

# 로그인 성공 여부 확인
if login_request.status_code == 200:
    print("로그인 성공!")
else:
    print("로그인 실패!")
```

위 코드에서는 `HTMLSession` 객체를 사용하여 세션을 생성하고, `get` 메소드를 사용하여 로그인 페이지로 접속합니다. 그리고 로그인할 사용자명과 비밀번호를 설정하고 `post` 메소드를 사용하여 로그인 요청을 전송합니다. 마지막으로, 요청의 상태 코드를 확인하여 로그인이 성공했는지를 판단합니다.

## 세션 유지하기

세션을 만들었다면 이후의 모든 요청에서는 해당 세션을 사용하여 로그인 상태를 유지할 수 있습니다. 세션을 사용하여 웹 페이지에 접속하는 예시 코드는 다음과 같습니다.

```python
# 데이터를 가져올 페이지에 접속
data_url = "https://example.com/data"
response = session.get(data_url)

# 페이지 정보 가져오기
if response.status_code == 200:
    page_content = response.text
    # 페이지 파싱 및 데이터 추출
    # ...
```

위 코드에서는 이전에 만들어진 `session` 객체를 사용하여 데이터를 가져올 웹 페이지에 접속합니다. 세션을 사용하는 것으로 로그인 상태가 유지되며, 데이터를 가져올 수 있습니다.

## 요약

이번 포스트에서는 Python의 Requests-HTML 라이브러리를 사용하여 웹 페이지의 세션을 관리하는 방법에 대해 알아보았습니다. 세션을 만들고 유지함으로써 로그인 상태를 유지하고, 웹 페이지의 데이터를 가져올 수 있습니다.

특히, Requests-HTML는 간편한 인터페이스와 기능적인 라이브러리로 웹 페이지 크롤링 작업을 수행하기에 매우 유용합니다. 해당 라이브러리의 공식 문서를 참고하여 다양한 기능을 활용해보세요.

## 참고 자료
- Requests-HTML 공식 문서: [https://requests-html.kennethreitz.org/](https://requests-html.kennethreitz.org/)
- Requests 공식 문서: [https://requests.readthedocs.io/](https://requests.readthedocs.io/)