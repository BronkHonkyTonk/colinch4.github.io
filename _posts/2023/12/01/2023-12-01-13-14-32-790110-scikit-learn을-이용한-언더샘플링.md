---
layout: post
title: "[python] scikit-learn을 이용한 언더샘플링"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

머신 러닝 모델을 구축할 때, 불균형한 데이터셋을 다루는 것은 일반적인 문제입니다. 특히, 대부분의 예측 변수가 하나의 클래스에 치우쳐 있는 경우에 문제가 발생할 수 있습니다. 이러한 문제를 해결하기 위해 언더샘플링이라는 기법이 사용됩니다.

언더샘플링은 다수 클래스의 데이터 포인트를 제거하여 데이터셋의 균형을 맞추는 방법입니다. 이를 통해 모델이 전체 데이터셋을 더 잘 학습할 수 있습니다. scikit-learn은 이러한 언더샘플링을 수행하는 여러 가지 방법을 제공합니다.

## 1. RandomUnderSampler 사용하기

scikit-learn의 `imbalanced-learn` 패키지에는 `RandomUnderSampler`라는 클래스가 포함되어 있습니다. 이 클래스는 랜덤하게 다수 클래스의 데이터 포인트를 제거하여 균형을 맞춥니다.

아래는 `RandomUnderSampler`를 사용하여 언더샘플링하는 예제입니다:

```python
from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=0)
X_resampled, y_resampled = rus.fit_resample(X, y)
```

위의 예제에서 `X`는 예측 변수의 배열이고 `y`는 대상 변수의 배열입니다. `fit_resample` 메서드는 언더샘플링을 수행하고, 새로운 언더샘플링된 데이터셋 `X_resampled`와 `y_resampled`를 반환합니다.

## 2. TomekLinks 사용하기

또 다른 언더샘플링의 방법은 `TomekLinks`를 사용하는 것입니다. `TomekLinks`는 다수 클래스와 소수 클래스 사이의 경계에 위치한 데이터 포인트를 제거하여 균형을 맞춥니다.

아래는 `TomekLinks`를 사용하여 언더샘플링하는 예제입니다:

```python
from imblearn.under_sampling import TomekLinks

tl = TomekLinks()
X_resampled, y_resampled = tl.fit_resample(X, y)
```

위의 예제에서도 `fit_resample` 메서드를 사용하여 언더샘플링을 수행하고 새로운 데이터셋을 반환합니다.

## 결론

언더샘플링은 머신 러닝 모델에서 불균형한 데이터셋을 처리하는 강력한 기술입니다. scikit-learn의 `imbalanced-learn` 패키지는 `RandomUnderSampler`, `TomekLinks` 등 다양한 언더샘플링 방법을 제공하여 이를 손쉽게 수행할 수 있습니다. 이러한 기법을 사용하여 모델의 성능을 향상시킬 수 있습니다.

---

참고문서:
- scikit-learn: [RandomUnderSampler](https://imbalanced-learn.org/stable/under_sampling.html#random-under-sampler)
- scikit-learn: [TomekLinks](https://imbalanced-learn.org/stable/under_sampling.html#tomek-s-links)
- imbalanced-learn: [Undersampling](https://imbalanced-learn.org/stable/under_sampling.html)