---
layout: post
title: "[python] scikit-learn을 활용한 차원 축소 기법 선택 기준"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

차원 축소는 고차원 데이터의 특성을 유지하면서 낮은 차원으로 데이터를 변환하는 기법입니다. scikit-learn은 Python에서 많이 사용되는 머신러닝 라이브러리로, 다양한 차원 축소 기법을 제공합니다. 하지만 어떤 차원 축소 기법을 선택해야 할지는 데이터의 특성과 목적에 따라 다릅니다.

여기에서는 scikit-learn의 주요한 차원 축소 기법과 각 기법을 선택할 때 고려해야 할 기준을 알아보겠습니다.

## 1. 주성분 분석 (Principal Component Analysis, PCA)
PCA는 가장 널리 사용되는 차원 축소 기법 중 하나로, 주요한 특성을 추출하는데 주로 사용됩니다. PCA는 데이터의 분산을 최대한 보존하는 주성분을 추출하고, 데이터를 이 주성분으로 투영하는 방식으로 동작합니다. PCA는 계산 속도가 빠르고, 데이터의 구조를 잘 보존하는 경향이 있어 다양한 데이터에 적용할 수 있습니다. 하지만 PCA는 선형 변환에 기반하고 있어서 비선형 데이터의 특성을 잘 표현하지 못할 수 있습니다.

## 2. t-SNE (t-Distributed Stochastic Neighbor Embedding)
t-SNE는 고차원 데이터를 저차원으로 투영하는 비선형 차원 축소 기법입니다. 주로 시각화를 위해 사용되며, 데이터 간의 유사성을 최대한 보존하면서 저차원 공간에서의 거리를 최소화하는 방식으로 동작합니다. t-SNE는 비선형 데이터의 구조를 잘 표현할 수 있어 시각화에 적합하지만, 계산 속도가 느리고, 데이터의 분산을 보존하지 않는 경향이 있기 때문에 대용량 데이터에는 적합하지 않을 수 있습니다.

## 3. LLE (Locally Linear Embedding)
LLE는 비선형 차원 축소 기법으로, 이웃 데이터들의 선형 조합으로 원본 데이터를 표현하는 방식으로 동작합니다. LLE는 데이터의 지역 구조를 잘 보존하며, 비선형 데이터를 잘 표현할 수 있는 경향이 있습니다. 하지만 LLE는 모델 특성에 민감하며, 이상치에 민감하게 반응할 수 있기 때문에 데이터에 잘 맞는 하이퍼파라미터를 설정해야 합니다.

## 4. 적합한 차원 축소 기법 선택 기준
적합한 차원 축소 기법을 선택하기 위해서는 다음과 같은 요소들을 고려해야 합니다.

- 데이터의 특성: 데이터의 선형 또는 비선형적인 특성을 확인해야 합니다. 선형 데이터에서는 PCA가 적합하고, 비선형 데이터에서는 t-SNE 또는 LLE가 적합할 수 있습니다.
- 목적: 어떤 목적으로 차원 축소를 수행하느냐에 따라 다른 기법이 선택될 수 있습니다. 시각화를 위해 차원 축소를 수행한다면 t-SNE가 적합하며, 데이터의 구조를 보존하면서 차원을 축소한다면 PCA 또는 LLE이 적합할 수 있습니다.

차원 축소는 데이터의 특성과 목적에 따라 다양한 기법을 적용할 수 있습니다. 이 글을 통해 scikit-learn을 활용한 주요한 차원 축소 기법과 선택 기준에 대해 알아보았습니다.

[참고자료]
- [scikit-learn documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)
- [PCA, t-SNE, LLE](https://www.researchgate.net/figure/Comparison-of-PCA-t-SNE-and-LLE-dimensionality-reduction-methods-on-fashion-MNIST_fig2_337012399)