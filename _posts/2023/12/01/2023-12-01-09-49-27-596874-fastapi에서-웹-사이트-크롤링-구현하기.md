---
layout: post
title: "[python] FastAPI에서 웹 사이트 크롤링 구현하기"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

이번 포스트에서는 FastAPI를 사용하여 간단한 웹 사이트 크롤링을 구현하는 방법에 대해 알아보겠습니다. 크롤링은 웹사이트에 있는 정보를 수집하고 분석하는 작업으로, 파이썬의 `requests`와 `beautifulsoup` 라이브러리를 활용하여 구현할 것입니다.

## 필수 패키지 설치

먼저 FastAPI, requests, beautifulsoup 패키지를 설치해야 합니다. 아래 명령어를 사용하여 설치해주세요.

```bash
pip install fastapi requests beautifulsoup4
```

## FastAPI 애플리케이션 생성

이제 FastAPI 애플리케이션을 생성하고 기본적인 설정을 해보겠습니다.

```python
from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}
```

위 코드에서는 `/` 경로로 요청이 들어오면 "Hello World"를 반환하는 간단한 API를 정의하였습니다.

## 웹사이트 크롤링 기능 추가

이제 웹사이트 크롤링 기능을 추가해보겠습니다. 아래 코드를 참고하여 애플리케이션에 크롤링 기능을 추가할 수 있습니다.

```python
from fastapi import FastAPI
import requests
from bs4 import BeautifulSoup

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/crawl")
def crawl_website(url: str):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")
    # 크롤링 작업 수행
    # 원하는 정보를 추출하여 반환 또는 저장하는 작업을 수행할 수 있습니다.
```

`/crawl` 경로로 GET 요청이 들어오면 `url` 파라미터를 받아 해당 URL에 대한 크롤링 작업을 수행하는 함수를 정의하였습니다. `requests` 라이브러리를 사용하여 웹페이지의 HTML 소스를 가져오고, `beautifulsoup` 라이브러리를 사용하여 HTML을 파싱한 후 원하는 정보를 추출하거나 저장할 수 있습니다.

## 실행 및 테스트

위 코드를 저장한 후에 `uvicorn` 명령어로 FastAPI 애플리케이션을 실행할 수 있습니다.

```bash
uvicorn main:app --reload
```

서버가 정상적으로 실행된 후에 [http://127.0.0.1:8000](http://127.0.0.1:8000)에 접속하면 "Hello World"가 표시됩니다. 크롤링을 테스트하기 위해 [http://127.0.0.1:8000/crawl?url=https://www.example.com](http://127.0.0.1:8000/crawl?url=https://www.example.com)에 접속하여 원하는 웹사이트의 URL을 파라미터로 넘겨줍니다.

## 마치며

간단한 FastAPI 애플리케이션에서 웹사이트 크롤링을 구현하는 방법에 대해 알아보았습니다. 이를 응용하여 다양한 웹사이트에서 정보를 수집하고 활용할 수 있습니다. 크롤링 작업을 수행할 때는 해당 웹사이트의 이용 약관을 준수하고, 크롤링에 대한 제약사항을 확인하는 것이 중요합니다.