---
layout: post
title: "[python] Requests-HTML를 이용하여 웹 페이지의 멀티스레딩 처리하기"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

이번에는 `Requests-HTML` 라이브러리를 사용하여 멀티스레딩으로 웹 페이지를 다운로드하는 방법에 대해 알아보겠습니다.

`Requests-HTML`은 파이썬의 `Requests` 라이브러리를 기반으로 한 HTML 웹 페이지 다운로드 및 파싱 라이브러리입니다. 이 라이브러리를 사용하면 간단하게 웹 페이지의 내용을 가져올 수 있습니다.

먼저, `Requests-HTML`을 설치해야 합니다. 다음 명령어를 사용하여 설치할 수 있습니다:

```python
pip install requests-html
```

다음은 `Requests-HTML`과 멀티스레딩을 함께 사용하여 웹 페이지를 다운로드하는 예제 코드입니다:

```python
from requests_html import HTMLSession
import concurrent.futures

# 작업할 URL 목록
urls = ['https://www.example.com', 'https://www.google.com', 'https://www.python.org']

# 각 URL을 다운로드하는 함수
def download_page(url):
    session = HTMLSession()
    response = session.get(url)
    return response.text

# 멀티스레딩으로 다운로드 실행
with concurrent.futures.ThreadPoolExecutor() as executor:
    # 각 URL에 대해 다운로드 함수를 실행하고 결과를 리스트에 저장
    results = executor.map(download_page, urls)

    # 결과 출력
    for result in results:
        print(result)
```

위 코드에서 `urls` 리스트에 원하는 웹 페이지의 URL을 추가하고, `download_page` 함수에서 해당 URL을 다운로드하여 내용을 반환합니다. `concurrent.futures.ThreadPoolExecutor`를 사용하여 멀티스레딩 작업을 생성하고, `executor.map`을 호출하여 각 URL에 대해 `download_page` 함수를 실행합니다. 실행 결과는 `results` 변수에 저장되며, 이를 순회하면서 각 페이지의 내용을 출력할 수 있습니다.

이렇게 멀티스레딩을 이용하여 `Requests-HTML`을 활용하여 웹 페이지를 다운로드할 수 있습니다.

## 참고 자료
- [Requests-HTML 공식 문서](https://requests-html.kennethreitz.org/)
- [Python concurrent.futures 공식 문서](https://docs.python.org/3/library/concurrent.futures.html)