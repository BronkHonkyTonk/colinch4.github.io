---
layout: post
title: "[python] scikit-learn을 사용한 클래스 불균형 처리"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

머신 러닝 모델을 구축하거나 분류 작업을 수행할 때, 클래스 불균형 문제는 일반적으로 해결해야 하는 중요한 문제입니다. 클래스 불균형은 다른 클래스에 비해 하나 이상의 클래스가 훨씬 많은 경우를 의미합니다. 이러한 경우에 모델은 주로 다수 클래스만을 학습하고, 소수 클래스에 대한 성능이 저하될 수 있습니다.

scikit-learn은 클래스 불균형 문제를 해결하기 위한 여러 가지 기능을 제공합니다. 이번 포스트에서는 scikit-learn에서 제공하는 클래스 불균형 처리 방법 중 일부를 살펴보겠습니다.

## 1. 언더샘플링

언더샘플링은 다수 클래스의 샘플을 제거하여 데이터셋의 클래스 비율을 균형있게 만드는 방법입니다. 이를 위해 imbalanced-learn 패키지를 사용할 수 있습니다. 예를 들어, RandomUnderSampler 클래스를 사용하여 데이터셋의 클래스 비율을 균형있게 조정할 수 있습니다.

```python
from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=42)
X_res, y_res = rus.fit_resample(X, y)
```

## 2. 오버샘플링

오버샘플링은 소수 클래스의 샘플을 복제하여 데이터셋의 클래스 비율을 균형있게 만드는 방법입니다. 이를 위해 imbalanced-learn 패키지의 RandomOverSampler나 SMOTE와 같은 클래스를 사용할 수 있습니다. 예를 들어, RandomOverSampler 클래스를 사용하여 데이터셋의 클래스 비율을 균형있게 조정할 수 있습니다.

```python
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_res, y_res = ros.fit_resample(X, y)
```

## 3. 가중치 부여

가중치 부여는 소수 클래스의 샘플에 더 높은 가중치를 부여하여 모델이 소수 클래스에 더 많은 관심을 기울일 수 있도록 하는 방법입니다. 이를 위해 scikit-learn의 모델링 클래스 중 일부에서 `class_weight` 매개변수를 사용할 수 있습니다. 예를 들어, 로지스틱 회귀 모델에서 클래스 가중치를 설정하는 방법은 다음과 같습니다.

```python
from sklearn.linear_model import LogisticRegression

weights = {0: 1, 1: 10}  # 소수 클래스에 높은 가중치
lr = LogisticRegression(class_weight=weights)
```

## 4. 조정된 평가 지표 사용

클래스 불균형 문제의 경우 정확도만을 평가 지표로 사용하는 것은 부적절할 수 있습니다. 대신 조정된 평가 지표를 사용하여 모델의 성능을 측정하는 것이 중요합니다. scikit-learn에서 제공하는 많은 평가 지표 중에서 조정된 정밀도, 조정된 재현율, F1 스코어 등을 사용할 수 있습니다.

```python
from sklearn.metrics import classification_report

y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
print(report)
```

## 결론

이 포스트에서는 scikit-learn에서 클래스 불균형 문제를 해결하기 위한 몇 가지 방법을 살펴보았습니다. 언더샘플링, 오버샘플링, 가중치 부여, 그리고 조정된 평가 지표를 사용하여 클래스 불균형 문제를 처리할 수 있습니다. 데이터셋의 특성과 모델의 요구에 맞는 방법을 선택하여 클래스 불균형 문제를 효과적으로 해결해야 합니다.