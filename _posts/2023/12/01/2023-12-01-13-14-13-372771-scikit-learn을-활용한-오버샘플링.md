---
layout: post
title: "[python] scikit-learn을 활용한 오버샘플링"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

scikit-learn은 Python에서 머신러닝 모델을 구축하고 평가하는데 유용한 라이브러리입니다. 이번 포스트에서는 scikit-learn을 사용하여 데이터의 불균형 문제를 해결하기 위한 오버샘플링에 대해 알아보겠습니다.

## 오버샘플링이란?

오버샘플링은 매우 드물게 발생하는 이벤트를 더 잘 학습 시키기 위해 소수 클래스의 샘플을 증가시키는 기술입니다. 이를 통해 모델은 소수 클래스의 패턴을 더 잘 파악할 수 있습니다.

## scikit-learn의 imbalanced-learn 라이브러리

scikit-learn은 imbalanced-learn라는 라이브러리를 통해 오버샘플링을 손쉽게 수행할 수 있습니다. imbalanced-learn은 다양한 오버샘플링 알고리즘을 지원하며, 샘플링 비율을 자동으로 조정해주는 기능도 제공합니다.

## 예제 코드

아래는 scikit-learn을 사용하여 오버샘플링을 수행하는 예제 코드입니다. 이 예제에서는 Random Over Sampler 알고리즘을 사용하고 있습니다.

```python
from imblearn.over_sampling import RandomOverSampler
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# 데이터 생성
X, y = make_classification(n_samples=1000, n_features=20, n_informative=2,
                           n_redundant=10, n_classes=2, random_state=42)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 오버샘플링 수행
oversampler = RandomOverSampler()
X_train_res, y_train_res = oversampler.fit_resample(X_train, y_train)

# 모델 학습 및 평가
model = DecisionTreeClassifier()
model.fit(X_train_res, y_train_res)
accuracy = model.score(X_test, y_test)
print(f"Accuracy: {accuracy}")
```

이 코드는 먼저 make_classification 함수를 사용하여 가상의 분류 데이터를 생성합니다. 그런 다음 train_test_split 함수를 사용하여 데이터를 학습 및 테스트 세트로 분할합니다.

Random Over Sampler 알고리즘을 사용하여 오버샘플링을 수행하고, 학습된 모델의 정확도를 평가합니다.

## 결론

이번 포스트에서는 scikit-learn의 imbalanced-learn 라이브러리를 사용하여 오버샘플링을 수행하는 방법을 알아보았습니다. 오버샘플링은 데이터의 불균형 문제를 해결하기 위한 강력한 도구이며, 적절한 오버샘플링 알고리즘을 선택하고 사용하는 것이 중요합니다.