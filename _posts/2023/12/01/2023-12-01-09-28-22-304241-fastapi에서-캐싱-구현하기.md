---
layout: post
title: "[python] FastAPI에서 캐싱 구현하기"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

이번 글에서는 FastAPI에서 캐싱을 구현하는 방법에 대해 알아보겠습니다. FastAPI는 빠른 속도와 간편한 사용법으로 인해 인기 있는 웹 프레임워크이며, 캐싱을 적용하여 성능을 향상시킬 수 있습니다.

## 캐싱이란?

캐싱은 이전에 계산된 결과를 저장하여 동일한 요청이 들어왔을 때, 다시 계산하지 않고 저장된 결과를 사용하는 기법입니다. 이를 통해 시간과 자원을 절약할 수 있습니다.

## FastAPI에서의 캐싱 구현하기

FastAPI에서 캐싱을 구현하기 위해서는 `cachetools` 패키지를 사용할 수 있습니다. 해당 패키지는 다양한 캐싱 알고리즘을 제공하며, 간단한 인터페이스를 통해 캐싱 기능을 쉽게 사용할 수 있습니다.

먼저, `cachetools`를 설치합니다.

```shell
pip install cachetools
```

다음으로, FastAPI 서버에서 캐싱을 적용하고자 하는 API 핸들러 함수에 `@cached` 데코레이터를 적용합니다. 이 데코레이터는 함수의 결과를 캐싱하고, 같은 요청이 들어왔을 때에는 캐시된 결과를 사용합니다.

```python
from fastapi import FastAPI
from fastapi_caching import cached

app = FastAPI()

@cached()
def expensive_operation():
    # 복잡한 계산이나 DB 조회 등의 작업
    return result

@app.get("/data")
def get_data():
    result = expensive_operation()
    return {"data": result}
```

위의 코드에서 `expensive_operation()` 함수는 복잡한 계산이나 DB 조회와 같은 비용이 많이 드는 작업을 수행합니다. 이 함수의 결과를 캐싱하기 위해 `@cached()` 데코레이터를 적용했습니다. 이제 `/data` 엔드포인트를 호출할 때마다 `expensive_operation()` 함수가 호출되는 것이 아니라, 캐시된 결과가 사용됩니다.

## 주의사항

- 캐싱은 결과가 불변(immutable)해야 제대로 동작합니다. 캐싱되는 결과가 변경될 수 있는 경우 캐시를 사용하지 않는 것이 좋습니다.
- 캐싱은 메모리를 사용하기 때문에, 캐시되는 데이터의 크기와 수명을 고려해야 합니다. 캐시가 너무 많은 메모리를 사용하는 경우, 캐시를 제한하거나 LRU(Least Recently Used) 같은 캐시 알고리즘을 사용할 수 있습니다.

## 결론

FastAPI에서는 `cachetools` 패키지를 활용하여 간편하게 캐싱 기능을 구현할 수 있습니다. 캐싱을 활용하여 API의 성능을 최적화하고, 사용자 경험을 향상시킬 수 있습니다. 추가적인 캐싱 관련 설정과 기능을 사용하려면 `cachetools` 문서를 참고해보시길 바랍니다.

참고:
- [FastAPI 공식 문서](https://fastapi.tiangolo.com/)
- [cachetools 패키지 문서](https://cachetools.readthedocs.io/)