---
layout: post
title: "[python] Requests-HTML를 활용한 웹 크롤링 예제"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

이번 예제에서는 Python의 Requests-HTML 라이브러리를 사용하여 간단한 웹 크롤링을 수행하는 방법을 알아보겠습니다.

## 1. Requests-HTML 라이브러리 설치하기

먼저, Requests-HTML 라이브러리를 설치해야 합니다. 다음 명령을 사용하여 라이브러리를 설치하세요:

```bash
pip install requests-html
```

## 2. 웹 페이지 접속하기

Requests-HTML를 사용하여 웹 페이지에 접속하는 방법은 간단합니다. 아래 코드를 참고하세요:

```python
from requests_html import HTMLSession

# 세션 생성
session = HTMLSession()

# 웹 페이지 접속
url = 'https://example.com'
r = session.get(url)

# 페이지 HTML 내용 출력
print(r.html)
```

## 3. 요소 선택하기

웹 페이지에서 특정 요소를 선택하기 위해서는 CSS 선택자를 사용합니다. 아래 코드는 웹 페이지에서 모든 링크를 선택하는 예제입니다:

```python
from requests_html import HTMLSession

# 세션 생성
session = HTMLSession()

# 웹 페이지 접속
url = 'https://example.com'
r = session.get(url)

# 모든 링크 선택하기
links = r.html.find('a')

# 링크 출력
for link in links:
    print(link.text)
    print(link.attrs['href'])
```

## 4. 데이터 추출하기

선택한 요소에서 데이터를 추출하는 방법은 다양합니다. 예를 들어, 웹 페이지의 제목을 추출하는 방법은 아래와 같습니다:

```python
from requests_html import HTMLSession

# 세션 생성
session = HTMLSession()

# 웹 페이지 접속
url = 'https://example.com'
r = session.get(url)

# 제목 추출
title = r.html.find('title', first=True).text
print(title)
```

## 5. 실행결과

위 예제를 실행하면 다음과 같은 결과를 얻을 수 있습니다:

```
Example Domain
http://www.iana.org/domains/example
```

이와 같이, Requests-HTML 라이브러리를 사용하면 간단하게 웹 크롤링을 수행할 수 있습니다. 물론, 크롤링을 수행할 때는 해당 웹 사이트의 이용 약관과 로봇 배제 표준을 준수해야 합니다.

## 참고 자료

- Requests-HTML GitHub 저장소: [https://github.com/psf/requests-html](https://github.com/psf/requests-html)
- Requests-HTML 공식 문서: [https://docs.python-requests.org/projects/requests-html/](https://docs.python-requests.org/projects/requests-html/)