---
layout: post
title: "[python] scikit-learn을 활용한 그라디언트 부스팅 시각화"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

그라디언트 부스팅(Gradient Boosting)은 머신러닝 알고리즘 중 하나로, 여러 개의 약한 학습기(weak learner)를 순차적으로 학습하여 강력한 학습기(strong learner)를 만드는 앙상블 기법입니다. scikit-learn은 그라디언트 부스팅 알고리즘을 제공하는데, 이를 활용하여 데이터셋을 학습 및 시각화할 수 있습니다.

## 필요 패키지 설치

먼저, scikit-learn 패키지를 설치해야 합니다. 아래 명령어를 터미널 또는 콘솔에서 실행하여 설치합니다.

```
pip install scikit-learn
```

## 데이터셋 준비

그라디언트 부스팅을 시각화하기 위해 사용할 예시 데이터셋을 준비해야 합니다. scikit-learn에 기본으로 제공되는 붓꽃(iris) 데이터셋을 활용하겠습니다.

```python
from sklearn.datasets import load_iris

iris = load_iris()
X = iris.data
y = iris.target
```

## 그라디언트 부스팅 모델 학습

데이터셋을 준비했으므로, scikit-learn의 `GradientBoostingClassifier`를 사용하여 그라디언트 부스팅 모델을 학습합니다.

```python
from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier()
gb.fit(X, y)
```

## 결정 경계 시각화

그라디언트 부스팅 모델을 학습한 후, 결정 경계를 시각화할 수 있습니다. 이를 위해 matplotlib 패키지를 설치해야 합니다. 아래 명령어를 터미널 또는 콘솔에서 실행하여 설치합니다.

```
pip install matplotlib
```

```python
import numpy as np
import matplotlib.pyplot as plt

# 그래프의 해상도 설정
h = .02

# 그래프 범위 설정
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# 예측 함수 적용
Z = gb.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# 그래프 그리기
plt.figure()
plt.contourf(xx, yy, Z, alpha=0.8)
plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.title('Gradient Boosting Decision Boundary')
plt.show()
```

위 코드를 실행하면, 결정 경계가 시각화된 그래프를 확인할 수 있습니다.

## 결론

scikit-learn의 그라디언트 부스팅 알고리즘을 활용하여 데이터셋을 학습하고 시각화하는 방법을 알아보았습니다. 그라디언트 부스팅은 강력한 앙상블 기법 중 하나로, 다양한 데이터셋에 적용하여 성능을 향상시킬 수 있습니다.

## 참고 자료

- [scikit-learn documentation](https://scikit-learn.org/stable/)
- [Python documentation](https://www.python.org/)
- [matplotlib documentation](https://matplotlib.org/)