---
layout: post
title: "[python] FastAPI에서 머신러닝 모델 서빙하기"
description: " "
date: 2023-12-01
tags: [python]
comments: true
share: true
---

FastAPI는 Python에서 빠르게 API를 개발할 수 있는 고성능 웹 프레임워크입니다. 이번 포스트에서는 FastAPI를 사용하여 머신러닝 모델을 서빙하는 방법에 대해 알아보겠습니다.

## 1. FastAPI 설치

FastAPI를 사용하기 위해 먼저 FastAPI를 설치해야 합니다. 아래의 커맨드를 실행하여 FastAPI를 설치합니다.

```
pip install fastapi
```

## 2. 머신러닝 모델 준비

FastAPI에서 머신러닝 모델을 서빙하기 위해서는 먼저 머신러닝 모델을 준비해야 합니다. 예를 들어, scikit-learn을 사용하여 작성된 분류 모델을 사용해보겠습니다.

```python
import joblib

model = joblib.load('model.pkl')
```

위의 코드는 `model.pkl` 파일에서 미리 학습된 모델을 로드하는 예시입니다.

## 3. FastAPI 앱 생성

FastAPI 앱을 생성하기 위해 다음과 같이 코드를 작성합니다.

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def root():
    return {"message": "Hello, FastAPI!"}
```

위 코드는 `/` 엔드포인트에 접속하면 "Hello, FastAPI!" 메세지를 반환하는 간단한 앱입니다.

## 4. 머신러닝 모델 서빙하기

FastAPI 앱에서 머신러닝 모델을 서빙하기 위해 다음과 같이 코드를 작성합니다.

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def root():
    return {"message": "Hello, FastAPI!"}

@app.post("/predict")
def predict(data: dict):
    features = data['features']
    prediction = model.predict([features])
    return {"prediction": prediction[0]}
```

위의 코드는 `/predict` 엔드포인트에 POST 요청을 보내면 입력 데이터의 특성을 모델에 입력하여 예측 결과를 반환하는 앱입니다.

## 5. FastAPI 서버 실행

FastAPI 서버를 실행하기 위해 다음과 같이 코드를 작성합니다.

```python
from fastapi import FastAPI

app = FastAPI()

# 머신러닝 모델 로드 및 서빙 코드 생략

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

위의 코드에서 `uvicorn`은 FastAPI 서버를 실행하는 도구입니다. `uvicorn`을 사용하여 서버를 실행하면 머신러닝 모델을 서빙할 수 있습니다.

## 결론

FastAPI를 사용하여 머신러닝 모델을 서빙하는 방법에 대해 알아보았습니다. FastAPI는 간편하게 API를 개발할 수 있으면서도 높은 성능을 제공하는 웹 프레임워크로, 머신러닝 모델 서빙에도 매우 유용하게 사용될 수 있습니다.

참고: [FastAPI 공식 문서](https://fastapi.tiangolo.com/)