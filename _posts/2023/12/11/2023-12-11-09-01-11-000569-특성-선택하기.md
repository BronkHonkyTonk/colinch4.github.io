---
layout: post
title: "[python] 특성 선택하기"
description: " "
date: 2023-12-11
tags: [python]
comments: true
share: true
---

특성 선택은 머신러닝과 데이터 분석에서 매우 중요한 단계 중 하나입니다. 모든 특성을 사용하는 것보다 특정 특성들을 선택하여 모델 훈련에 사용하는 것이 모델의 성능을 향상시킬 수 있습니다. 특성 선택은 **과적합을 줄이고 모델의 해석력을 높이는 데 도움을 줄 수 있습니다**.

## 특성 선택의 유형

1. **필터 방식 (Filter Method)**: 통계적 속성을 기반으로 특성을 평가하고 선택합니다. 예를 들어, 상호 정보량, 분산, 상관 관계 등의 통계적 기준을 사용할 수 있습니다.

2. **래퍼 방식 (Wrapper Method)**: 모델의 성능을 평가하여 특성의 부분 집합을 선택합니다. 예를 들어, 전진 선택, 후진 소거, 재귀적 특성 소거 등의 방법이 있습니다.

3. **임베디드 방식 (Embedded Method)**: 모델 훈련 과정에서 특성 선택을 포함합니다. 예를 들어, LASSO나 Elastic Net 같은 정규화 모델을 사용하여 특성을 선택할 수 있습니다.

## 특성 선택을 위한 Python 라이브러리

**Scikit-learn**은 `SelectKBest`, `SelectPercentile`, `RFE`, `RFECV` 등의 클래스를 제공하여 간단하고 효과적인 특성 선택을 수행할 수 있습니다.

아래는 Scikit-learn을 사용하여 특성 선택을 수행하는 간단한 예제입니다.
```python
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

X_new = SelectKBest(chi2, k=2).fit_transform(X, y)
```

위의 코드에서는 카이 제곱 통계량을 사용하여 특성 중 상위 2개를 선택하는 방법을 보여줍니다.

특성 선택은 데이터의 품질을 향상시키고 머신러닝 모델의 성능을 최적화하는 데 중요한 과정입니다.

## 참고 자료

- [Scikit-learn feature selection](https://scikit-learn.org/stable/modules/feature_selection.html)
- Guyon, I., & Elisseeff, A. (2003). An introduction to variable and feature selection. Journal of machine learning research, 3(Mar), 1157-1182.
- Kuhn, M., & Johnson, K. (2013). Applied predictive modeling. Springer.

특성 선택에 대한 더 자세한 정보는 위의 참고 자료를 참고해 주시기 바랍니다.