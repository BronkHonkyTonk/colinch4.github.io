---
layout: post
title: "[swift] Swift Core ML을 사용하여 이미지 분류를 수행하는 방법은 무엇인가요?"
description: " "
date: 2023-12-11
tags: [swift]
comments: true
share: true
---

## 학습된 모델 가져오기
Swift에서 Core ML을 사용하여 이미지 분류를 수행하려면 먼저 학습된 Core ML 모델을 가져와야 합니다. 이 모델은 .mlmodel 형식이어야 합니다.

```swift
import CoreML

guard let model = try? VNCoreMLModel(for: YourModel().model) else {
    fatalError("모델을 가져올 수 없습니다.")
}
```

여기서 YourModel은 Xcode에 추가된 Core ML 모델의 이름을 나타냅니다.

## 이미지 분류 수행
이제 가져온 Core ML 모델을 사용하여 이미지 분류를 수행할 수 있습니다. 아래는 이미지를 분류하는 간단한 예제 코드입니다.

```swift
import Vision

let request = VNCoreMLRequest(model: model) { request, error in
    guard let results = request.results as? [VNClassificationObservation],
          let topResult = results.first else {
        fatalError("이미지를 분류할 수 없습니다.")
    }
    print("분류 결과: \(topResult.identifier) - 신뢰도: \(topResult.confidence)")
}

let handler = VNImageRequestHandler(ciImage: yourCIImage)
do {
    try handler.perform([request])
} catch {
    print(error)
}
```

위 코드에서 `yourCIImage`는 분류하고자 하는 CIImage 객체를 나타냅니다.

이제 위의 코드를 사용하여 Swift에서 Core ML을 활용하여 이미지 분류를 수행할 수 있습니다.

이 코드는 Swift 5와 iOS 11 이상에서 작동합니다.

참고 문헌:
- [Apple 개발자 문서 - Core ML](https://developer.apple.com/documentation/coreml)
- [Apple 개발자 문서 - Vision](https://developer.apple.com/documentation/vision)
- [Apple 개발자 문서 - VNCoreMLRequest](https://developer.apple.com/documentation/vision/vncoremlrequest)
- [Apple 개발자 문서 - VNImageRequestHandler](https://developer.apple.com/documentation/vision/vnimagerequesthandler)
- [Apple 개발자 문서 - VNClassificationObservation](https://developer.apple.com/documentation/vision/vnclassificationobservation)