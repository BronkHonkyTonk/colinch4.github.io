---
layout: post
title: "[python] 특성 스케일링하기"
description: " "
date: 2023-12-11
tags: [python]
comments: true
share: true
---

이번 포스트에서는 데이터 전처리 과정 중 하나인 **특성 스케일링**에 대해 알아보겠습니다.

## 특성 스케일링이란?

특성 스케일링은 **데이터의 다른 특성들 간에 적절한 척도(scale)가 유지되도록 조정하는 과정**을 말합니다. 

일반적으로 데이터의 특성이 서로 다른 척도를 가지고 있을 때, 이를 동일한 척도로 맞추는 작업을 의미합니다. 

## 왜 특성 스케일링이 필요할까?

머신러닝 알고리즘들은 대부분 데이터의 스케일에 민감합니다. 하나의 특성이 다른 특성보다 훨씬 큰 값을 가지면, 머신러닝 알고리즘이 큰 값의 특성을 중요하게 생각할 수 있습니다. 이는 모델의 성능을 저하시킬 수 있습니다.

## 주요한 특성 스케일링 기법

**1. 표준화(Standardization):** 
   - 특성의 평균을 0, 분산을 1로 만들어 스케일링합니다.
   - `z = (x - mean) / std`

**2. 정규화(Normalization):**
   - 특성 값을 [0, 1] 범위 안으로 스케일링합니다.
   - `x_scaled = (x - x_min) / (x_max - x_min)`

## Python에서의 특성 스케일링

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import pandas as pd

# 데이터 불러오기
data = pd.read_csv('data.csv')

# 표준화
scaler = StandardScaler()
standardized_data = scaler.fit_transform(data[['feature1', 'feature2']])

# 정규화
scaler = MinMaxScaler()
normalized_data = scaler.fit_transform(data[['feature1', 'feature2']])
```

위 코드는 Python의 `scikit-learn` 라이브러리를 사용하여 표준화와 정규화를 하는 방법을 보여줍니다.

특성 스케일링은 데이터를 머신러닝 모델에 투입하기 전에 반드시 고려해야 하는 중요한 과정입니다. 적절한 특성 스케일링을 통해 모델의 성능을 향상시킬 수 있습니다.

## 참고 자료

- [Scikit-learn preprocessing documentation](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)