---
layout: post
title: "[python] 모델 평가하기"
description: " "
date: 2023-12-11
tags: [python]
comments: true
share: true
---

모델을 훈련시킨 후에는 해당 모델의 성능을 평가해야 합니다. 모델을 평가하는 여러 가지 방법이 있지만, 일반적으로 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 스코어(F1 Score) 등을 사용합니다. 이러한 지표들은 모델의 예측 결과를 종합적으로 평가하여 모델의 성능을 이해하는 데 도움이 됩니다.

## 1. 정확도(Accuracy)

**정확도**는 모델이 정확하게 예측한 데이터의 비율을 나타내는 지표입니다. 정확도는 다음과 같이 계산됩니다.

\[ Accuracy = \frac{올바르게 분류된 샘플 수}{전체 샘플 수} \]

## 2. 정밀도(Precision)와 재현율(Recall)

**정밀도**는 양성(Positive)으로 예측한 샘플 중 실제로 양성인 비율을 나타내고, **재현율**은 실제 양성인 샘플 중 모델이 양성이라고 예측한 샘플의 비율을 나타냅니다. 

\[ Precision = \frac{TP}{TP+FP} \]

\[ Recall = \frac{TP}{TP+FN} \]

여기서 TP는 True Positive(실제 양성을 올바르게 예측한 샘플 수), FP는 False Positive(실제 음성을 양성으로 잘못 예측한 샘플 수), FN은 False Negative(실제 양성을 음성으로 잘못 예측한 샘플 수)를 나타냅니다.

## 3. F1 스코어(F1 Score)

**F1 스코어**는 정밀도와 재현율의 조화평균으로 계산됩니다. F1 스코어는 모델의 성능을 평가하는 데 있어서 유용한 지표 중 하나입니다.

\[ F1 Score = 2 \times \frac{Precision \times Recall}{Precision + Recall} \]

## 모델 성능평가 방법 선택

모델의 성능을 평가할 때에는 해당 모델의 목적과 데이터 특성을 고려하여 적절한 평가 지표를 선택해야 합니다. 예를 들어, **이진 분류** 문제의 경우 정밀도와 재현율을 함께 고려할 때 F1 스코어를 주로 사용합니다. 또한, **다중 클래스 분류**의 경우에는 정확도를 주로 사용하며, 추가적으로 정밀도와 재현율도 함께 살펴볼 필요가 있습니다.

이러한 평가 지표들을 통해 모델의 성능을 정량적으로 평가하고, 필요에 따라 모델을 개선하는 방향으로 전략을 수립할 수 있습니다.

## 참고 자료
- [Understanding the Confusion Matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)
- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)