---
layout: post
title: "[go] 반복문을 사용하여 여러 페이지 스크래핑하기"
description: " "
date: 2023-12-08
tags: [go]
comments: true
share: true
---

이번에는 Go 언어를 사용하여 여러 웹 페이지를 스크래핑하는 방법에 대해 알아보겠습니다. Go 언어의 강력한 동시성 기능과 내장된 HTTP 라이브러리를 활용하여 이 작업을 손쉽게 수행할 수 있습니다.

## 필요한 패키지 가져오기

먼저, 다음과 같이 `net/http`와 `golang.org/x/net/html` 패키지를 가져와야 합니다.

```go
import (
	"net/http"
	"golang.org/x/net/html"
)
```

## 페이지 스크래핑 함수 작성

다음으로, 여러 페이지를 스크래핑하는 함수를 작성해야 합니다. 아래의 예제는 `GetLinks` 함수를 사용하여 주어진 URL에서 모든 링크를 스크래핑하는 것을 보여줍니다.

```go
func GetLinks(url string) ([]string, error) {
	resp, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	doc, err := html.Parse(resp.Body)
	if err != nil {
		return nil, err
	}

	var links []string
	var f func(*html.Node)
	f = func(n *html.Node) {
		if n.Type == html.ElementNode && n.Data == "a" {
			for _, a := range n.Attr {
				if a.Key == "href" {
					links = append(links, a.Val)
				}
			}
		}
		for c := n.FirstChild; c != nil; c = c.NextSibling {
			f(c)
		}
	}
	f(doc)
	return links, nil
}
```

## 여러 페이지 스크래핑하기

이제 `GetLinks` 함수를 사용하여 여러 페이지를 스크래핑할 수 있습니다. 아래의 예제는 여러 URL에서 링크를 스크래핑하는 방법을 보여줍니다.

```go
func ScrapeMultiplePages(urls []string) {
	for _, url := range urls {
		links, err := GetLinks(url)
		if err != nil {
			fmt.Println("Error scraping", url, ":", err)
		} else {
			fmt.Println("Links from", url, ":", links)
		}
	}
}
```

## 마무리

이제 여러 페이지를 스크래핑하는 간단한 Go 프로그램을 작성하는 방법을 알아보았습니다. Go 언어를 사용하면 동시성을 활용하여 빠르고 효율적으로 웹 페이지를 스크래핑할 수 있습니다.

이제 여러 페이지를 스크래핑하는 간단한 Go 프로그램을 작성하는 방법을 알아보았습니다. Go 언어를 사용하면 동시성을 활용하여 빠르고 효율적으로 웹 페이지를 스크래핑할 수 있습니다.