---
layout: post
title: "[swift] AudioUnit의 오디오 시간 싱크"
description: " "
date: 2023-12-26
tags: [swift]
comments: true
share: true
---

오디오 애플리케이션을 개발할 때 **오디오 시간 싱크**는 매우 중요합니다. 오디오 시간 싱크는 여러 소스에서 오디오를 동기화하는 데 사용되며, 사용자에게 일관된 오디오 경험을 제공하는 데 필수적입니다.

## AudioUnit

Apple의 Core Audio 프레임워크는 오디오 시간 싱크를 구현하는 데 사용할 수 있는 다양한 기능을 제공합니다. 그 중에서도 **AudioUnit**은 유연하고 강력한 도구로 오디오 시간 싱크를 구현하는 데 사용됩니다. 

```swift
// AudioUnit 설정
let audioComponentDescription = AudioComponentDescription(componentType: kAudioUnitType_Output,
                                                          componentSubType: kAudioUnitSubType_RemoteIO,
                                                          componentManufacturer: kAudioUnitManufacturer_Apple,
                                                          componentFlags: 0,
                                                          componentFlagsMask: 0)

let remoteIOComponent = AudioComponentFindNext(nil, &audioComponentDescription)
var remoteIOUnit: AudioComponentInstance?

AudioComponentInstanceNew(remoteIOComponent!, &remoteIOUnit)
```

위 예시 코드는 `AudioUnit`을 설정하는 간단한 예시입니다.

## 오디오 시간 싱크 구현

오디오 시간 싱크를 구현하려면 `AudioUnit`을 생성하고 적절한 샘플 레이트와 버퍼 사이즈를 설정해야 합니다. 그 후 애플리케이션의 다른 요소들과 시간을 맞추기 위해 오디오 데이터의 패킷을 보내야 합니다.

```swift
// AudioUnit의 시간과 샘플 레이트, 버퍼 사이즈 설정
let session = AVAudioSession.sharedInstance()

do {
    try session.setPreferredSampleRate(44100)
    try session.setPreferredIOBufferDuration(256)
    try session.setCategory(.playAndRecord, mode: .default, options: [.mixWithOthers, .allowBluetooth])
    try session.setActive(true)
} catch {
    print("Error setting up audio session")
}

// 오디오 패킷 보내기
let audioData: [Float] = getAudioData()  // 오디오 데이터를 가져오는 함수
let sampleCount = audioData.count

var audioBufferList = AudioBufferList()
audioBufferList.mNumberBuffers = 1
audioBufferList.mBuffers.mNumberChannels = 1
audioBufferList.mBuffers.mDataByteSize = UInt32(sampleCount * MemoryLayout.size(ofValue: audioData[0]))
audioBufferList.mBuffers.mData = UnsafeMutableRawPointer(mutating: audioData)

let audioTime = AudioTimeStamp(mSampleTime: 0, mHostTime: 0, mRateScalar: 0, mWordClockTime: 0, mSMPTETime: SMPTETime(), mFlags: .sampleTimeValid, mReserved: 0)

var ioActionFlags: AudioUnitRenderActionFlags = 0
let status = AudioUnitRender(remoteIOUnit!, &ioActionFlags, &audioTime, 0, sampleCount, &audioBufferList)
```

위 코드는 적절한 샘플 레이트와 버퍼 사이즈를 설정하고, 오디오 데이터를 `AudioUnit`으로 보내는 간단한 예시입니다.

## 결론

오디오 애플리케이션을 개발하면서 오디오 시간 싱크는 항상 신경써야 하는 중요한 부분입니다. `AudioUnit`을 사용하여 오디오 시간 싱크를 구현하면 사용자에게 일관된 오디오 경험을 제공할 수 있습니다. 따라서 오디오 시간 싱크를 정확하게 구현하는 데 주의를 기울여야 합니다.