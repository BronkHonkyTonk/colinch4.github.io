---
layout: post
title: "[shell] 딥 러닝 모델 평가 지표"
description: " "
date: 2023-12-26
tags: [shell]
comments: true
share: true
---

딥 러닝 모델의 성능을 평가하는 데는 여러 가지 지표가 사용됩니다. 이러한 지표들은 모델의 정확성, 일반화 능력 및 안정성 등을 평가하는 데 도움이 됩니다. 아래에서는 주요한 딥 러닝 모델 평가 지표에 대해 간략히 설명하겠습니다.

## 1. 정확도 (Accuracy)
정확도는 모델이 올바르게 분류한 샘플의 비율을 나타냅니다. 전체 예측 중 올바르게 분류된 샘플의 비율을 계산하여 나타내며, 가장 기본적인 평가 지표 중 하나입니다.

## 2. 정밀도 (Precision) 및 재현율 (Recall)
정밀도는 양성으로 예측한 샘플 중 실제 양성인 샘플의 비율을, 재현율은 실제 양성인 샘플 중 모델이 올바르게 감지한 샘플의 비율을 나타냅니다. 두 지표는 모델이 양성으로 예측한 결과의 신뢰성과 실제 양성을 정확히 감지하는 능력을 평가하는 데 사용됩니다.

## 3. F1 점수 (F1 Score)
F1 점수는 정밀도와 재현율의 조화 평균으로, 불균형한 클래스 분포에서 모델의 성능을 정확히 평가하는 데 도움이 됩니다.

## 4. AUC-ROC
수신자 판단 곡선 아래 영역(Area Under the Receiver Operating Characteristic curve)은 분류 모델의 성능을 나타내는 지표로, 분류 모델의 감지 능력을 평가하는 데 사용됩니다.

## 5. 손실 함수 (Loss function)
모델의 손실 함수는 예측값과 실제값 사이의 오차를 계산하는 데 사용됩니다. 모델 학습 중에 최소화되는 목표 함수이며, 모델이 얼마나 정확한 예측을 하는지를 평가하는 데 중요한 역할을 합니다.

딥 러닝 모델을 평가할 때, 위와 같은 다양한 평가 지표를 함께 고려하여 종합적인 모델 성능을 평가하는 것이 중요합니다.

## 참고 문헌
- https://en.wikipedia.org/wiki/Precision_and_recall
- https://en.wikipedia.org/wiki/F1_score
- https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5