---
layout: post
title: "[ios] Core Audio 오디오 입출력 장치 모니터링"
description: " "
date: 2023-12-26
tags: [ios]
comments: true
share: true
---

Core Audio는 iOS 앱에서 오디오 입력 및 출력을 관리하기 위한 강력한 프레임워크입니다. 앱에서 마이크 입력 및 스피커 출력을 모니터링하고 싶다면 Core Audio를 사용하여 손쉽게 구현할 수 있습니다.

## 오디오 세션 설정

먼저, Core Audio를 사용하여 오디오를 다루기 전에 오디오 세션을 설정해야 합니다. 오디오 세션 설정은 앱의 오디오 동작 및 동작 방식을 결정하는 중요한 단계입니다. `AVAudioSession` 클래스를 사용하여 오디오 세션을 구성하고 오디오 입력 및 출력을 활성화할 수 있습니다.

```swift
import AVFoundation

let audioSession = AVAudioSession.sharedInstance()
do {
    try audioSession.setCategory(.playAndRecord, mode: .default)
    try audioSession.setActive(true)
} catch {
    print("Error setting up audio session: \(error.localizedDescription)")
}
```

위의 코드에서는 `playAndRecord` 카테고리로 오디오 세션을 설정하고, 활성화될 때 앱이 오디오를 동시에 입력 및 출력할 수 있도록 설정합니다.

## 오디오 입력 모니터링

오디오 입력을 모니터링하려면, `AVAudioEngine`을 사용하여 입력 노드와 출력 노드를 연결해야 합니다. 또한, 입력 노드에서 오디오를 가져와서 출력 노드로 전달해야 합니다.

```swift
import AVFoundation

let audioEngine = AVAudioEngine()
let inputNode = audioEngine.inputNode
let outputNode = audioEngine.outputNode

// 입력 노드에서 오디오를 출력 노드로 전달
inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputNode.inputFormat(forBus: 0)) { (buffer, time) in
    self.outputNode?.render(buffer, when: time)
}

do {
    try audioEngine.start()
} catch {
    print("Error starting audio engine: \(error.localizedDescription)")
}
```

위의 코드는 입력 노드에서 오디오를 가져와서 출력 노드로 전달하는 방법을 보여줍니다. 이를 통해 입력된 오디오를 실시간으로 모니터링할 수 있습니다.

이제 iOS 앱에서 오디오 입력 및 출력 장치를 모니터링하는 방법에 대해 기본적인 이해를 할 수 있었습니다. Core Audio를 통해 오디오 처리를 한 단계 더 나아가고 싶다면, Core Audio의 다양한 기능 및 설정 옵션을 자세히 살펴보시기 바랍니다.

더 많은 정보를 원하시면 [Apple의 Core Audio 프레임워크 문서](https://developer.apple.com/documentation/coreaudio)를 참조하시기 바랍니다.