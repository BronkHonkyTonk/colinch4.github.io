---
layout: post
title: "[swift] AudioUnit 프로그래밍 기초"
description: " "
date: 2023-12-26
tags: [swift]
comments: true
share: true
---

이번에는 Swift를 사용하여 AudioUnit을 프로그래밍하는 기초적인 방법에 대해 알아보겠습니다.

## 1. 소개

AudioUnit은 디지털 신호 처리를 위해 사용되는 소프트웨어 컴포넌트입니다. 주로 오디오 이펙트나 신호 프로세싱을 위해 사용됩니다. Swift를 사용하여 AudioUnit을 제어하고 처리하는 방법을 살펴보겠습니다.

## 2. 초기 설정

먼저, AudioUnit을 프로그래밍하기 위해서는 Core Audio 프레임워크를 프로젝트에 추가해야 합니다. Xcode의 프로젝트 설정에서 "Linked Frameworks and Libraries"에 Core Audio 프레임워크를 추가합니다.

```swift
import CoreAudio
import AudioToolbox
```

## 3. AudioUnit 생성

다음으로는 AudioUnit 인스턴스를 생성해야 합니다. 먼저 AudioComponentDescription을 설정하고 AudioComponentFindNext를 사용하여 AudioComponent를 찾은 후에 AudioComponentInstanceNew를 사용하여 인스턴스를 생성합니다.

```swift
var ioUnit: AudioComponentInstance = nil
var ioUnitDesc = AudioComponentDescription(componentType: kAudioUnitType_Output,
                                           componentSubType: kAudioUnitSubType_RemoteIO,
                                           componentManufacturer: kAudioUnitManufacturer_Apple,
                                           componentFlags: 0,
                                           componentFlagsMask: 0)

let comp = AudioComponentFindNext(nil, &ioUnitDesc)
AudioComponentInstanceNew(comp!, &ioUnit)
```

## 4. AudioUnit 설정

AudioUnit의 입력과 출력을 설정하고, 콜백을 등록하여 오디오 데이터를 처리하는 방법을 살펴봅니다.

```swift
var enableIO: UInt32 = 1
AudioUnitSetProperty(ioUnit,
                     kAudioOutputUnitProperty_EnableIO,
                     kAudioUnitScope_Input,
                     1,
                     &enableIO,
                     UInt32(MemoryLayout<UInt32>.size))

var format = AudioStreamBasicDescription(mSampleRate: 44100.0,
                                        mFormatID: kAudioFormatLinearPCM,
                                        mFormatFlags: kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked,
                                        mFramesPerPacket: 1,
                                        mChannelsPerFrame: 1,
                                        mBitsPerChannel: 16,
                                        mBytesPerPacket: 2,
                                        mBytesPerFrame: 2)

AudioUnitSetProperty(ioUnit,
                     kAudioUnitProperty_StreamFormat,
                     kAudioUnitScope_Output,
                     1,
                     &format,
                     UInt32(MemoryLayout<AudioStreamBasicDescription>.size))
```

## 5. AudioUnit 실행

마지막으로 생성한 AudioUnit을 실행하여 오디오를 처리하고 재생합니다.

```swift
AudioUnitInitialize(ioUnit)
AudioOutputUnitStart(ioUnit)
```

## 마치며

이제 Swift를 사용하여 기본적인 AudioUnit을 프로그래밍하는 방법에 대해 알아보았습니다. 보다 복잡한 오디오 처리를 위해서는 더 많은 설정과 처리가 필요하지만, 이를 기초로 활용하여 오디오 신호를 처리하고 응용프로그램을 개발할 수 있습니다.

더 많은 정보는 [Apple Developer 사이트](https://developer.apple.com/documentation/coreaudio)에서 확인할 수 있습니다.