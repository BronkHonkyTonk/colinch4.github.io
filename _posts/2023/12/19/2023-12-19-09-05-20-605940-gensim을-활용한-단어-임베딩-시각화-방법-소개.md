---
layout: post
title: "[python] gensim을 활용한 단어 임베딩 시각화 방법 소개"
description: " "
date: 2023-12-19
tags: [python]
comments: true
share: true
---

단어 임베딩은 자연어 처리에서 중요한 기법 중 하나입니다. 임베딩을 시각화하여 단어들 간의 의미적 유사성을 파악할 수 있습니다. 이번 포스팅에서는 Gensim을 사용하여 단어 임베딩을 학습하고 시각화하는 방법에 대해 알아보겠습니다.

## Gensim이란?

[Gensim](https://radimrehurek.com/gensim/)은 Python으로 작성된 자연어 처리를 위한 라이브러리입니다. 주로 토픽 모델링, 문서 유사도 분석, 텍스트 요약, 단어 임베딩 등의 작업을 수행할 때 사용됩니다.

## 단어 임베딩 시각화

단어 임베딩을 시각화하는 방법은 여러 가지가 있지만, **t-SNE**(t-distributed stochastic neighbor embedding)를 활용하는 것이 일반적입니다. t-SNE는 고차원의 데이터를 저차원으로 투영하여 시각화하는 기법으로, 비슷한 벡터를 가진 아이템들이 가깝게, 유사하지 않은 아이템들이 멀리 표현되도록 만듭니다.

## Gensim을 이용한 단어 임베딩 시각화

Gensim을 사용하여 단어 임베딩 시각화를 진행하려면, 먼저 임베딩 모델을 학습시켜야 합니다. 다음은 Gensim을 사용하여 Word2Vec 모델을 학습시키고, t-SNE를 이용하여 시각화하는 예제 코드입니다.

```python
from gensim.models import Word2Vec
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# 단어 임베딩 모델 학습
sentences = [["I", "love", "natural", "language", "processing"],
             ["Gensim", "is", "great", "for", "word", "embedding"],
             ...]
model = Word2Vec(sentences, min_count=1)

# t-SNE를 통한 시각화
vocab = list(model.wv.vocab)
X = model[vocab]
tsne = TSNE(n_components=2)
X_tsne = tsne.fit_transform(X)
plt.figure(figsize=(10, 6))
plt.scatter(X_tsne[:, 0], X_tsne[:, 1])
for label, x, y in zip(vocab, X_tsne[:, 0], X_tsne[:, 1]):
    plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords="offset points")
plt.show()
```

위 코드는 먼저 문장을 단어로 분할하고, Word2Vec 모델을 학습시킨 후 임베딩된 단어들을 t-SNE를 이용하여 2차원 공간에 시각화합니다.

이렇게 시각화된 결과를 통해 단어들 간의 의미적 거리, 관계를 파악할 수 있습니다.

## 마치며

이번 포스팅에서는 Gensim을 사용하여 단어 임베딩 모델을 학습하고 시각화하는 방법에 대해 알아보았습니다. 단어 임베딩 시각화를 통해 자연어 처리 작업에 도움이 될 수 있는 유용한 정보를 얻을 수 있습니다. Gensim을 이용하여 다양한 자연어 처리 작업을 수행하고, 시각화를 통해 결과를 분석하는 등 다양한 활용 방안이 있을 것입니다.

참고문헌: [Gensim Documentation](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html)