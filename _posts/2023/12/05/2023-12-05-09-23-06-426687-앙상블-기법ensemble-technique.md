---
layout: post
title: "[python] 앙상블 기법(Ensemble Technique)"
description: " "
date: 2023-12-05
tags: [python]
comments: true
share: true
---

앙상블 기법은 여러 개의 예측 모델을 조합하여 더 강력한 예측 모델을 만드는 머신러닝 기법입니다. 이는 단일 모델을 사용하는 것보다 예측 성능을 향상시킬 수 있습니다. 앙상블 기법은 주로 분류(classification) 또는 회귀(regression) 문제에 적용되며, 다양한 방법이 존재합니다.

가장 대표적인 앙상블 기법은 배깅(Bagging)과 부스팅(Boosting)입니다. 

## 배깅(Bagging)

배깅은 여러 개의 독립적인 모델을 생성하고 그들의 예측 결과를 평균 또는 다수결 등의 방법으로 결합하는 방식입니다. 대표적인 배깅 알고리즘은 랜덤 포레스트(Random Forest)입니다. 랜덤 포레스트는 결정 트리(Decision Tree)를 사용하는 앙상블 기법으로, 다수의 결정 트리를 생성하고 각 결정 트리의 예측값을 이용하여 최종 예측을 수행합니다.

```python
from sklearn.ensemble import RandomForestClassifier

# 랜덤 포레스트 분류 모델 생성
model = RandomForestClassifier(n_estimators=100)

# 모델 학습
model.fit(X_train, y_train)

# 모델 예측
y_pred = model.predict(X_test)
```

## 부스팅(Boosting)

부스팅은 약한 학습기(Weak Learner)를 순차적으로 학습시켜 강한 예측 모델을 만드는 방식입니다. 부스팅 알고리즘은 이전 학습기의 예측 결과를 토대로 다음 학습기의 학습에 반영하는 방식으로 작동합니다. 대표적인 부스팅 알고리즘으로는 그래디언트 부스팅(Gradient Boosting)과 에이다부스트(AdaBoost)가 있습니다.

```python
from sklearn.ensemble import GradientBoostingClassifier

# 그래디언트 부스팅 분류 모델 생성
model = GradientBoostingClassifier()

# 모델 학습
model.fit(X_train, y_train)

# 모델 예측
y_pred = model.predict(X_test)
```

앙상블 기법은 데이터의 다양성을 활용하여 예측 성능을 향상시킬 수 있습니다. 하지만 모델의 복잡성이 증가하는 단점도 있으므로, 적절한 모델 선택과 파라미터 튜닝이 필요합니다.

## 참고 자료
- [Scikit-learn - Ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html)
- [Introduction to Ensemble Learning in Python](https://towardsdatascience.com/introduction-to-ensemble-learning-in-python-98d5c444f6ec)