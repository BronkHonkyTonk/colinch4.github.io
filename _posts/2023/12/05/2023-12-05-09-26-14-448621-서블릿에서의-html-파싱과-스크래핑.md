---
layout: post
title: "[java] 서블릿에서의 HTML 파싱과 스크래핑"
description: " "
date: 2023-12-05
tags: [java]
comments: true
share: true
---

많은 웹 애플리케이션은 다른 웹 사이트의 데이터를 스크래핑하거나 HTML 문서를 파싱하여 정보를 추출해야 할 때가 있습니다. 이러한 작업을 Java 서블릿에서 수행할 수 있습니다. 이 글에서는 Java 서블릿에서 HTML 파싱과 스크래핑을 수행하는 방법에 대해 알아보겠습니다.

## 1. Jsoup 라이브러리 활용하기
Jsoup은 HTML 문서를 파싱하고 원하는 정보를 추출하는 데 사용되는 Java 라이브러리입니다. 이를 사용하면 HTML의 태그, 속성 등을 손쉽게 조작할 수 있습니다.

먼저, 프로젝트의 빌드 파일에 Jsoup 의존성을 추가해야 합니다. Maven을 사용하는 경우, `pom.xml` 파일에 다음 의존성을 추가하세요.

```xml
<dependency>
    <groupId>org.jsoup</groupId>
    <artifactId>jsoup</artifactId>
    <version>1.14.1</version>
</dependency>
```

의존성을 추가한 후, Jsoup을 사용하여 HTML 문서를 파싱하고 원하는 정보를 추출할 수 있습니다. 아래 코드는 웹 사이트에서 특정 HTML 요소를 추출하는 예시입니다.

```java
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class HtmlParserExample {
    public static void main(String[] args) {
        try {
            // HTML 문서를 가져옴
            Document doc = Jsoup.connect("http://example.com").get();

            // 특정 CSS 선택자로 요소 추출
            Elements elements = doc.select("h1");
            for (Element element : elements) {
                System.out.println(element.text());
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

위 코드에서는 `Jsoup.connect()` 메서드를 사용하여 웹 사이트의 HTML 문서를 가져옵니다. 그리고 `doc.select()` 메서드를 사용하여 특정 CSS 선택자에 해당하는 요소들을 추출한 후, 원하는 정보를 출력하고 있습니다.

## 2. HttpClient 라이브러리로 웹 페이지 가져오기
위 예시에서는 Jsoup의 `connect()` 메서드를 사용하여 HTML 문서를 가져왔지만, 때로는 더 복잡한 요건이 필요할 수 있습니다. 이때는 Apache HttpClient 라이브러리를 사용하여 HTTP 요청을 보내 HTML 문서를 가져올 수 있습니다.

Apache HttpClient 의존성을 추가하려면 Maven 프로젝트의 `pom.xml` 파일에 다음 의존성을 추가하세요.

```xml
<dependency>
    <groupId>org.apache.httpcomponents</groupId>
    <artifactId>httpclient</artifactId>
    <version>4.5.13</version>
</dependency>
```

아래 코드는 Apache HttpClient를 사용하여 웹 사이트에서 HTML 문서를 가져오고 Jsoup을 사용하여 파싱하는 예시입니다.

```java
import org.apache.http.HttpEntity;
import org.apache.http.HttpResponse;
import org.apache.http.client.HttpClient;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.impl.client.HttpClientBuilder;
import org.apache.http.util.EntityUtils;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

import java.io.IOException;

public class HtmlScraperExample {
    public static void main(String[] args) {
        HttpClient httpClient = HttpClientBuilder.create().build();
        HttpGet request = new HttpGet("http://example.com");

        try {
            // HTTP 요청을 보내고 응답을 받음
            HttpResponse response = httpClient.execute(request);
            HttpEntity entity = response.getEntity();

            if (entity != null) {
                // HTML 문서를 문자열로 변환
                String html = EntityUtils.toString(entity);

                // HTML 문서를 파싱
                Document doc = Jsoup.parse(html);

                // 특정 CSS 선택자로 요소 추출
                Elements elements = doc.select("h1");
                for (Element element : elements) {
                    System.out.println(element.text());
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

위 예시에서는 Apache HttpClient를 사용하여 HTTP 요청을 보내고 응답을 받습니다. 응답으로 받은 HTML 문서를 `EntityUtils.toString()` 메서드를 사용하여 문자열로 변환한 후, Jsoup을 사용하여 파싱하고 원하는 정보를 추출합니다.

## 3. 결론
Java 서블릿에서 HTML 문서를 파싱하고 데이터를 스크래핑하는 작업은 웹 애플리케이션 개발 시 매우 유용합니다. Jsoup과 Apache HttpClient 라이브러리를 활용하여 이 작업을 효과적으로 수행할 수 있습니다. 이러한 기술을 사용하여 다른 웹 사이트의 데이터를 활용하거나 웹 크롤러를 개발할 수 있습니다.

## 참고 자료
- [Jsoup 공식 홈페이지](https://jsoup.org/)
- [Apache HttpClient 공식 홈페이지](https://hc.apache.org/httpcomponents-client-ga/)