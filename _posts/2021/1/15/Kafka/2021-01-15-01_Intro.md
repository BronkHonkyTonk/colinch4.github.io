---
layout: post
title: "[Kafka] 1. 카프카 훑어보기"
description: " "
date: 2021-01-15
tags: [kafka]
comments: true
share: true
---

## Kafka 기초 다지기

 **출처 : [카프카 핵심 가이드 (O'Reilly)](https://book.naver.com/bookdb/book_detail.nhn?bid=14093855)**

#### 목차

1. **카프카 훑어보기**
   - [**메시지 발행과 구독하기**](#1-메시지-발행과-구독하기)
   - [**카프카 살펴보기**](#2-카프카-살펴보기)
   - [**카프카를 사용하는 이유**](#3-카프카를-사용하는-이유)
2. [범용 메시지 큐와 비교하기](https://colinch4.github.io/2021-01-15/402_compare/)
3. [카프카 프로듀서 : 카프카에 메시지 쓰기](https://colinch4.github.io/2021-01-15/403_producer/) 
4. [카프카 컨슈머 : 중요 개념](https://colinch4.github.io/2021-01-15/404_consumer_core/)
5. [카프카 컨슈머 : 카프카에서 데이터 읽기](https://colinch4.github.io/2021-01-15/405_consumer_use/)
6. [스키마 레지스트리](https://colinch4.github.io/2021-01-15/406_schema_registry/)
7. [카프카 내부 메커니즘](https://colinch4.github.io/2021-01-15/407_inside/)
8. [신뢰성 있는 데이터 전달](https://colinch4.github.io/2021-01-15/408_reliability/)
9. [데이터 파이프라인 구축하기](https://colinch4.github.io/2021-01-15/409_data_pipeline/)

- [confluent 예제](https://github.com/colinch4/colinch4.github.io/blob/master/_posts/2021/1/15/Kafka/2021-01-15-99_confluent_example)
- [schema registry 예제](https://github.com/colinch4/colinch4.github.io/blob/master/_posts/2021/1/15/Kafka/2021-01-15-99_schema_registry_example)



___

## 카프카 훑어보기

### 1. 메시지 발행과 구독하기

#### 1) 메시지 발행/구독 시스템

- 데이터(메시지)를 발행자(전송자)가 직접 구독자(수신자)에게 보내지 않는다.
- 발행자가 어떤 형태로는 메시지를 구분해 전송하면, 구독자가 특정 부류의 메시지를 구독할 수 있게 해준다.
- 발행된 메시지를 저장하고 중계하는 역할은 **브로커**가 한다.

  

#### 2) 개별적인 메시지 큐 시스템

- 정보의 발행자와 구독자를 분리하자!
- 일반화된 유형의 메시지 데이터를 발행/구독하는 **하나의 집중 처리 시스템**으로 만든다.
  - 유연성과 확장성이 좋아진다.



___

### 2. 카프카 살펴보기

#### 1) 메시지와 배치

- **메시지** : 데이터의 기본 단위 (= 데이터베이스의 row)
  - 카프카는 메시지를 **바이트 배열**의 데이터로 간주해 특정 형식이나 의미를 갖지 않는다!
  - 효율성을 위해 여러 개의 메시지를 모아 **배치** 형태로 **파티션**에 수록한다.
    \> 네트워크로부터 매번 메시지를 받아 처리하는 것보다 부담이 적다.

- **스키마** : 내용을 이해하기 쉽도록 메시지의 구조를 나타내준다.



#### 2) 토픽과 파티션

- **토픽** : 카프카의 메시지를 분류한다. (= 데이터 베이스의 table)

- **파티션** : 하나의 토픽은 여러 파티션으로 구성된다.
  - 메시지는 파티션에 추가되는 형태로 수록되고, 맨 앞에서 제일 끝까지의 순서로 읽힌다.
  - **[주의]** 하나의 토픽은 여러 개의 파티션을 갖지만, 메시지 처리 순서는 **파티션별로** 유지 관리된다.
  
- **스트림** : 파티션의 개수와 상관없는 하나의 토픽 데이터. 
  - 데이터를 쓰는 프로듀서로부터 데이터를 읽는 컨슈머로 **이동되는 연속적인 데이터**
  - **실시간**으로 메시지를 처리할 때 주로 사용한다.



#### 3) 프로듀서와 컨슈머

- **프로듀서** : 새로운 메시지를 생성한다. (= 발행자, 작성자)
  - 기본적으로는 메시지가 어떤 파티션에 수록되는지 관여하지 않는다.
  - 특정 파티션에 메시지를 직접 쓸 수도 있다.
  
- **컨슈머** : 생성된 메시지를 읽는다. (= 구독자, 독자)
  - 하나 이상의 토픽을 **구독**해 메시지가 **생성된 순서**로 읽는다.
  - 메시지의 **오프셋**을 유지해 읽는 메시지의 위치를 알 수 있다.



#### 4) 브로커와 클러스터

- **브로커** : 하나의 카프카 서버.
  - 프로듀서로부터 메시지를 수신하고, 오프셋을 지정한 후, 해당 메시지를 디스크에 저장한다.
  - 컨슈머의 파티션 읽기 요청에 응답하고, 수록된 메시지를 전송한다.
  
- **클러스터** : 카프카의 브로커는 클러스터의 일부로 동작한다.
  - 여러 개의 브로커가 **하나의 클러스터에 포함**될 수 있다.
  - 그 중 하나는 자동으로 선정되는 클러스터의 **컨트롤러**가 된다.
  - **다중 클러스터** : 카프카가 많이 설치되어 사용될 때 고려한다.



___

### 3. 카프카를 사용하는 이유

#### 1) 카프카의 장점

- **다중 프로듀서** : 여러 클라이언트가 많은 토픽을 사용하거나, 같은 토픽을 같이 사용해도 카프카는 무리 없이 많은 프로듀서의 메시지를 처리할 수 있다.
- **다중 컨슈머** : 많은 컨슈머가 **상호 간섭 없이** 어떤 메시지 스트림도 읽을 수 있다.  
- **디스크 기반의 보존** : **지속해서** 메시지를 보존할 수 있고, 데이터가 유실될 위험이 없다. 컨슈머가 항상 실시간으로 실행되지 않아도 된다.
- **확장성**: 확장성이 좋아 **어떤 크기의 데이터도 쉽게 처리**할 수 있다.
- **고성능** : 지금까지의 모든 기능들이 합쳐져 아파치 카프카를 고성능의 메시지 발행/구독 시스템으로 만들어준다.

  

#### 2) 데이터 생태계

1. 데이터를 생성하는 애플리케이션에 맞춰 **입력 형식이 정의**된다.
2. **시스템의 데이터를 읽어들인다**
3. 다른 소스에서 받은 데이터를 사용해 **변환**시킨다.
4. 어디서든 사용될 수 있도록 최종 데이터를 **데이터 기반 구조에 전달**한다.
